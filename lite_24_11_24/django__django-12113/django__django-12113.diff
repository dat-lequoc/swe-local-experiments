diff --git a/django/db/backends/sqlite3/base.py b/django/db/backends/sqlite3/base.py
index a3ae1f048e..ad78cb9519 100644
--- a/django/db/backends/sqlite3/base.py
+++ b/django/db/backends/sqlite3/base.py
@@ -202,6 +202,9 @@ class DatabaseWrapper(BaseDatabaseWrapper):
     @async_unsafe
     def get_new_connection(self, conn_params):
         conn = Database.connect(**conn_params)
+        # Configure SQLite for better concurrent access
+        conn.execute('PRAGMA journal_mode=WAL')  # Use Write-Ahead Logging
+        conn.execute('PRAGMA busy_timeout=10000')  # Wait up to 10 seconds when database is locked
         conn.create_function("django_date_extract", 2, _sqlite_datetime_extract)
         conn.create_function("django_date_trunc", 2, _sqlite_date_trunc)
         conn.create_function('django_datetime_cast_date', 3, _sqlite_datetime_cast_date)
diff --git a/edge_cases.py b/edge_cases.py
new file mode 100644
index 0000000000..94f5f65b1d
--- /dev/null
+++ b/edge_cases.py
@@ -0,0 +1,128 @@
+import os
+import sqlite3
+import threading
+import time
+from concurrent.futures import ThreadPoolExecutor, as_completed
+
+def setup_db(db_path):
+    conn = sqlite3.connect(db_path)
+    conn.execute('CREATE TABLE IF NOT EXISTS test_table (id INTEGER PRIMARY KEY, data TEXT)')
+    conn.commit()
+    conn.close()
+
+def test_large_transaction(db_path):
+    """Test with a large number of operations in a single transaction"""
+    try:
+        conn = sqlite3.connect(db_path)
+        conn.execute('PRAGMA journal_mode=WAL')
+        conn.execute('PRAGMA busy_timeout=10000')
+        
+        # Large transaction
+        conn.execute('BEGIN TRANSACTION')
+        for i in range(1000):
+            conn.execute('INSERT INTO test_table (data) VALUES (?)', [f'large_trans_{i}'])
+        conn.commit()
+        
+        count = conn.execute('SELECT COUNT(*) FROM test_table').fetchone()[0]
+        conn.close()
+        print(f'Large transaction test: Successfully inserted {count} records')
+        return True
+    except sqlite3.OperationalError as e:
+        print(f'Large transaction test failed: {e}')
+        return False
+
+def test_rapid_connections(db_path):
+    """Test rapidly opening and closing connections"""
+    try:
+        for i in range(50):
+            conn = sqlite3.connect(db_path)
+            conn.execute('PRAGMA journal_mode=WAL')
+            conn.execute('PRAGMA busy_timeout=10000')
+            conn.execute('INSERT INTO test_table (data) VALUES (?)', [f'rapid_{i}'])
+            conn.commit()
+            conn.close()
+        print('Rapid connections test: Success')
+        return True
+    except sqlite3.OperationalError as e:
+        print(f'Rapid connections test failed: {e}')
+        return False
+
+def test_concurrent_reads_writes(db_path):
+    """Test concurrent reads and writes"""
+    def reader():
+        try:
+            conn = sqlite3.connect(db_path)
+            conn.execute('PRAGMA journal_mode=WAL')
+            conn.execute('PRAGMA busy_timeout=10000')
+            for _ in range(10):
+                conn.execute('SELECT COUNT(*) FROM test_table').fetchone()
+                time.sleep(0.01)
+            conn.close()
+            return True
+        except sqlite3.OperationalError as e:
+            print(f'Reader failed: {e}')
+            return False
+
+    def writer():
+        try:
+            conn = sqlite3.connect(db_path)
+            conn.execute('PRAGMA journal_mode=WAL')
+            conn.execute('PRAGMA busy_timeout=10000')
+            for i in range(10):
+                conn.execute('INSERT INTO test_table (data) VALUES (?)', [f'concurrent_{i}'])
+                conn.commit()
+                time.sleep(0.01)
+            conn.close()
+            return True
+        except sqlite3.OperationalError as e:
+            print(f'Writer failed: {e}')
+            return False
+
+    with ThreadPoolExecutor(max_workers=10) as executor:
+        futures = []
+        for _ in range(5):
+            futures.append(executor.submit(reader))
+            futures.append(executor.submit(writer))
+        
+        results = [f.result() for f in as_completed(futures)]
+        success = all(results)
+        print('Concurrent reads/writes test:', 'Success' if success else 'Failed')
+        return success
+
+def main():
+    print('Running edge case tests...')
+    db_path = 'edge_case_test.sqlite3'
+    
+    # Clean up any existing test database
+    if os.path.exists(db_path):
+        os.remove(db_path)
+    
+    # Setup fresh database
+    setup_db(db_path)
+    
+    # Run tests
+    tests = [
+        ('Large Transaction Test', lambda: test_large_transaction(db_path)),
+        ('Rapid Connections Test', lambda: test_rapid_connections(db_path)),
+        ('Concurrent Reads/Writes Test', lambda: test_concurrent_reads_writes(db_path))
+    ]
+    
+    all_passed = True
+    for test_name, test_func in tests:
+        print(f'\nRunning {test_name}...')
+        try:
+            if not test_func():
+                all_passed = False
+                print(f'{test_name} failed!')
+        except Exception as e:
+            all_passed = False
+            print(f'{test_name} failed with exception: {e}')
+    
+    # Cleanup
+    if os.path.exists(db_path):
+        os.remove(db_path)
+    
+    print('\nFinal Result:', 'All tests passed!' if all_passed else 'Some tests failed!')
+
+if __name__ == '__main__':
+    main()
\ No newline at end of file
diff --git a/reproduce_error.py b/reproduce_error.py
new file mode 100644
index 0000000000..f69da42955
--- /dev/null
+++ b/reproduce_error.py
@@ -0,0 +1,66 @@
+import os
+import sqlite3
+import threading
+import time
+
+def setup_db(db_path):
+    conn = sqlite3.connect(db_path)
+    conn.execute('CREATE TABLE IF NOT EXISTS users (id INTEGER PRIMARY KEY, username TEXT)')
+    conn.commit()
+    conn.close()
+
+def write_to_db(db_path, thread_id):
+    try:
+        conn = sqlite3.connect(db_path)
+        # Configure SQLite for better concurrent access
+        conn.execute('PRAGMA journal_mode=WAL')
+        conn.execute('PRAGMA busy_timeout=10000')
+        
+        # Simulate multiple writes
+        for i in range(5):
+            conn.execute('INSERT INTO users (username) VALUES (?)', [f'user_{thread_id}_{i}'])
+            conn.commit()
+            time.sleep(0.1)  # Small delay to increase chance of concurrent access
+        
+        conn.close()
+        print(f'Thread {thread_id}: Successfully completed all writes')
+        return True
+    except sqlite3.OperationalError as e:
+        print(f'Thread {thread_id}: Error - {e}')
+        return False
+
+def main():
+    print('Testing SQLite concurrent access...')
+    
+    # Create test databases
+    db_paths = ['test_default.sqlite3', 'test_other.sqlite3']
+    for db_path in db_paths:
+        if os.path.exists(db_path):
+            os.remove(db_path)
+        setup_db(db_path)
+    
+    # Create threads to simulate concurrent access
+    threads = []
+    success = True
+    
+    for i in range(4):  # Create 4 threads
+        for db_path in db_paths:
+            thread = threading.Thread(target=lambda: success and write_to_db(db_path, i))
+            threads.append(thread)
+            thread.start()
+    
+    # Wait for all threads to complete
+    for thread in threads:
+        thread.join()
+    
+    # Verify the results
+    for db_path in db_paths:
+        conn = sqlite3.connect(db_path)
+        count = conn.execute('SELECT COUNT(*) FROM users').fetchone()[0]
+        print(f'\nDatabase {db_path}: {count} records written')
+        conn.close()
+    
+    print('\nTest completed successfully!' if success else '\nTest failed!')
+
+if __name__ == '__main__':
+    main()
\ No newline at end of file
diff --git a/test_default.sqlite3 b/test_default.sqlite3
new file mode 100644
index 0000000000..8b357f2e69
Binary files /dev/null and b/test_default.sqlite3 differ
diff --git a/test_other.sqlite3 b/test_other.sqlite3
new file mode 100644
index 0000000000..b0c48ba675
Binary files /dev/null and b/test_other.sqlite3 differ
