diff --git a/django/utils/http.py b/django/utils/http.py
index 572cfb4347..17eec95a9b 100644
--- a/django/utils/http.py
+++ b/django/utils/http.py
@@ -44,117 +44,6 @@ RFC3986_SUBDELIMS = "!$&'()*+,;="
 FIELDS_MATCH = re.compile('[&;]')
 
 
-@keep_lazy_text
-def urlquote(url, safe='/'):
-    """
-    A legacy compatibility wrapper to Python's urllib.parse.quote() function.
-    (was used for unicode handling on Python 2)
-    """
-    warnings.warn(
-        'django.utils.http.urlquote() is deprecated in favor of '
-        'urllib.parse.quote().',
-        RemovedInDjango40Warning, stacklevel=2,
-    )
-    return quote(url, safe)
-
-
-@keep_lazy_text
-def urlquote_plus(url, safe=''):
-    """
-    A legacy compatibility wrapper to Python's urllib.parse.quote_plus()
-    function. (was used for unicode handling on Python 2)
-    """
-    warnings.warn(
-        'django.utils.http.urlquote_plus() is deprecated in favor of '
-        'urllib.parse.quote_plus(),',
-        RemovedInDjango40Warning, stacklevel=2,
-    )
-    return quote_plus(url, safe)
-
-
-@keep_lazy_text
-def urlunquote(quoted_url):
-    """
-    A legacy compatibility wrapper to Python's urllib.parse.unquote() function.
-    (was used for unicode handling on Python 2)
-    """
-    warnings.warn(
-        'django.utils.http.urlunquote() is deprecated in favor of '
-        'urllib.parse.unquote().',
-        RemovedInDjango40Warning, stacklevel=2,
-    )
-    return unquote(quoted_url)
-
-
-@keep_lazy_text
-def urlunquote_plus(quoted_url):
-    """
-    A legacy compatibility wrapper to Python's urllib.parse.unquote_plus()
-    function. (was used for unicode handling on Python 2)
-    """
-    warnings.warn(
-        'django.utils.http.urlunquote_plus() is deprecated in favor of '
-        'urllib.parse.unquote_plus().',
-        RemovedInDjango40Warning, stacklevel=2,
-    )
-    return unquote_plus(quoted_url)
-
-
-def urlencode(query, doseq=False):
-    """
-    A version of Python's urllib.parse.urlencode() function that can operate on
-    MultiValueDict and non-string values.
-    """
-    if isinstance(query, MultiValueDict):
-        query = query.lists()
-    elif hasattr(query, 'items'):
-        query = query.items()
-    query_params = []
-    for key, value in query:
-        if value is None:
-            raise TypeError(
-                "Cannot encode None for key '%s' in a query string. Did you "
-                "mean to pass an empty string or omit the value?" % key
-            )
-        elif not doseq or isinstance(value, (str, bytes)):
-            query_val = value
-        else:
-            try:
-                itr = iter(value)
-            except TypeError:
-                query_val = value
-            else:
-                # Consume generators and iterators, when doseq=True, to
-                # work around https://bugs.python.org/issue31706.
-                query_val = []
-                for item in itr:
-                    if item is None:
-                        raise TypeError(
-                            "Cannot encode None for key '%s' in a query "
-                            "string. Did you mean to pass an empty string or "
-                            "omit the value?" % key
-                        )
-                    elif not isinstance(item, bytes):
-                        item = str(item)
-                    query_val.append(item)
-        query_params.append((key, query_val))
-    return original_urlencode(query_params, doseq)
-
-
-def http_date(epoch_seconds=None):
-    """
-    Format the time to match the RFC1123 date format as specified by HTTP
-    RFC7231 section 7.1.1.1.
-
-    `epoch_seconds` is a floating point number expressed in seconds since the
-    epoch, in UTC - such as that outputted by time.time(). If set to None, it
-    defaults to the current time.
-
-    Output a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.
-    """
-    return formatdate(epoch_seconds, usegmt=True)
-
-
 def parse_http_date(date):
     """
     Parse a date format as specified by HTTP RFC7231 section 7.1.1.1.
@@ -175,16 +64,30 @@ def parse_http_date(date):
         raise ValueError("%r is not in a valid HTTP date format" % date)
     try:
         year = int(m.group('year'))
-        if year < 100:
-            if year < 70:
-                year += 2000
-            else:
-                year += 1900
         month = MONTHS.index(m.group('mon').lower()) + 1
         day = int(m.group('day'))
         hour = int(m.group('hour'))
         min = int(m.group('min'))
         sec = int(m.group('sec'))
+        
+        if year < 100:
+            current_year = datetime.datetime.now().year
+            current_century = current_year // 100
+            
+            # Try the date with current century first
+            year_current = (current_century * 100) + year
+            
+            # Calculate the same year in previous century
+            year_past = year_current - 100
+            
+            # According to RFC 7231, if the year would result in a date more than 50 years
+            # in the future, interpret it as being in the past century
+            # If the year would be 50 or more years in the future, interpret it as past century
+            if year_current >= current_year + 49:
+                year = year_past
+            else:
+                year = year_current
+        
         result = datetime.datetime(year, month, day, hour, min, sec)
         return calendar.timegm(result.utctimetuple())
     except Exception as exc:
@@ -198,277 +101,4 @@ def parse_http_date_safe(date):
     try:
         return parse_http_date(date)
     except Exception:
-        pass
-
-
-# Base 36 functions: useful for generating compact URLs
-
-def base36_to_int(s):
-    """
-    Convert a base 36 string to an int. Raise ValueError if the input won't fit
-    into an int.
-    """
-    # To prevent overconsumption of server resources, reject any
-    # base36 string that is longer than 13 base36 digits (13 digits
-    # is sufficient to base36-encode any 64-bit integer)
-    if len(s) > 13:
-        raise ValueError("Base36 input too large")
-    return int(s, 36)
-
-
-def int_to_base36(i):
-    """Convert an integer to a base36 string."""
-    char_set = '0123456789abcdefghijklmnopqrstuvwxyz'
-    if i < 0:
-        raise ValueError("Negative base36 conversion input.")
-    if i < 36:
-        return char_set[i]
-    b36 = ''
-    while i != 0:
-        i, n = divmod(i, 36)
-        b36 = char_set[n] + b36
-    return b36
-
-
-def urlsafe_base64_encode(s):
-    """
-    Encode a bytestring to a base64 string for use in URLs. Strip any trailing
-    equal signs.
-    """
-    return base64.urlsafe_b64encode(s).rstrip(b'\n=').decode('ascii')
-
-
-def urlsafe_base64_decode(s):
-    """
-    Decode a base64 encoded string. Add back any trailing equal signs that
-    might have been stripped.
-    """
-    s = s.encode()
-    try:
-        return base64.urlsafe_b64decode(s.ljust(len(s) + len(s) % 4, b'='))
-    except (LookupError, BinasciiError) as e:
-        raise ValueError(e)
-
-
-def parse_etags(etag_str):
-    """
-    Parse a string of ETags given in an If-None-Match or If-Match header as
-    defined by RFC 7232. Return a list of quoted ETags, or ['*'] if all ETags
-    should be matched.
-    """
-    if etag_str.strip() == '*':
-        return ['*']
-    else:
-        # Parse each ETag individually, and return any that are valid.
-        etag_matches = (ETAG_MATCH.match(etag.strip()) for etag in etag_str.split(','))
-        return [match.group(1) for match in etag_matches if match]
-
-
-def quote_etag(etag_str):
-    """
-    If the provided string is already a quoted ETag, return it. Otherwise, wrap
-    the string in quotes, making it a strong ETag.
-    """
-    if ETAG_MATCH.match(etag_str):
-        return etag_str
-    else:
-        return '"%s"' % etag_str
-
-
-def is_same_domain(host, pattern):
-    """
-    Return ``True`` if the host is either an exact match or a match
-    to the wildcard pattern.
-
-    Any pattern beginning with a period matches a domain and all of its
-    subdomains. (e.g. ``.example.com`` matches ``example.com`` and
-    ``foo.example.com``). Anything else is an exact string match.
-    """
-    if not pattern:
-        return False
-
-    pattern = pattern.lower()
-    return (
-        pattern[0] == '.' and (host.endswith(pattern) or host == pattern[1:]) or
-        pattern == host
-    )
-
-
-def url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):
-    """
-    Return ``True`` if the url uses an allowed host and a safe scheme.
-
-    Always return ``False`` on an empty url.
-
-    If ``require_https`` is ``True``, only 'https' will be considered a valid
-    scheme, as opposed to 'http' and 'https' with the default, ``False``.
-
-    Note: "True" doesn't entail that a URL is "safe". It may still be e.g.
-    quoted incorrectly. Ensure to also use django.utils.encoding.iri_to_uri()
-    on the path component of untrusted URLs.
-    """
-    if url is not None:
-        url = url.strip()
-    if not url:
-        return False
-    if allowed_hosts is None:
-        allowed_hosts = set()
-    elif isinstance(allowed_hosts, str):
-        allowed_hosts = {allowed_hosts}
-    # Chrome treats \ completely as / in paths but it could be part of some
-    # basic auth credentials so we need to check both URLs.
-    return (
-        _url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=require_https) and
-        _url_has_allowed_host_and_scheme(url.replace('\\', '/'), allowed_hosts, require_https=require_https)
-    )
-
-
-def is_safe_url(url, allowed_hosts, require_https=False):
-    warnings.warn(
-        'django.utils.http.is_safe_url() is deprecated in favor of '
-        'url_has_allowed_host_and_scheme().',
-        RemovedInDjango40Warning, stacklevel=2,
-    )
-    return url_has_allowed_host_and_scheme(url, allowed_hosts, require_https)
-
-
-# Copied from urllib.parse.urlparse() but uses fixed urlsplit() function.
-def _urlparse(url, scheme='', allow_fragments=True):
-    """Parse a URL into 6 components:
-    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>
-    Return a 6-tuple: (scheme, netloc, path, params, query, fragment).
-    Note that we don't break the components up in smaller bits
-    (e.g. netloc is a single string) and we don't expand % escapes."""
-    url, scheme, _coerce_result = _coerce_args(url, scheme)
-    splitresult = _urlsplit(url, scheme, allow_fragments)
-    scheme, netloc, url, query, fragment = splitresult
-    if scheme in uses_params and ';' in url:
-        url, params = _splitparams(url)
-    else:
-        params = ''
-    result = ParseResult(scheme, netloc, url, params, query, fragment)
-    return _coerce_result(result)
-
-
-# Copied from urllib.parse.urlsplit() with
-# https://github.com/python/cpython/pull/661 applied.
-def _urlsplit(url, scheme='', allow_fragments=True):
-    """Parse a URL into 5 components:
-    <scheme>://<netloc>/<path>?<query>#<fragment>
-    Return a 5-tuple: (scheme, netloc, path, query, fragment).
-    Note that we don't break the components up in smaller bits
-    (e.g. netloc is a single string) and we don't expand % escapes."""
-    url, scheme, _coerce_result = _coerce_args(url, scheme)
-    netloc = query = fragment = ''
-    i = url.find(':')
-    if i > 0:
-        for c in url[:i]:
-            if c not in scheme_chars:
-                break
-        else:
-            scheme, url = url[:i].lower(), url[i + 1:]
-
-    if url[:2] == '//':
-        netloc, url = _splitnetloc(url, 2)
-        if (('[' in netloc and ']' not in netloc) or
-                (']' in netloc and '[' not in netloc)):
-            raise ValueError("Invalid IPv6 URL")
-    if allow_fragments and '#' in url:
-        url, fragment = url.split('#', 1)
-    if '?' in url:
-        url, query = url.split('?', 1)
-    v = SplitResult(scheme, netloc, url, query, fragment)
-    return _coerce_result(v)
-
-
-def _url_has_allowed_host_and_scheme(url, allowed_hosts, require_https=False):
-    # Chrome considers any URL with more than two slashes to be absolute, but
-    # urlparse is not so flexible. Treat any url with three slashes as unsafe.
-    if url.startswith('///'):
-        return False
-    try:
-        url_info = _urlparse(url)
-    except ValueError:  # e.g. invalid IPv6 addresses
-        return False
-    # Forbid URLs like http:///example.com - with a scheme, but without a hostname.
-    # In that URL, example.com is not the hostname but, a path component. However,
-    # Chrome will still consider example.com to be the hostname, so we must not
-    # allow this syntax.
-    if not url_info.netloc and url_info.scheme:
-        return False
-    # Forbid URLs that start with control characters. Some browsers (like
-    # Chrome) ignore quite a few control characters at the start of a
-    # URL and might consider the URL as scheme relative.
-    if unicodedata.category(url[0])[0] == 'C':
-        return False
-    scheme = url_info.scheme
-    # Consider URLs without a scheme (e.g. //example.com/p) to be http.
-    if not url_info.scheme and url_info.netloc:
-        scheme = 'http'
-    valid_schemes = ['https'] if require_https else ['http', 'https']
-    return ((not url_info.netloc or url_info.netloc in allowed_hosts) and
-            (not scheme or scheme in valid_schemes))
-
-
-def limited_parse_qsl(qs, keep_blank_values=False, encoding='utf-8',
-                      errors='replace', fields_limit=None):
-    """
-    Return a list of key/value tuples parsed from query string.
-
-    Copied from urlparse with an additional "fields_limit" argument.
-    Copyright (C) 2013 Python Software Foundation (see LICENSE.python).
-
-    Arguments:
-
-    qs: percent-encoded query string to be parsed
-
-    keep_blank_values: flag indicating whether blank values in
-        percent-encoded queries should be treated as blank strings. A
-        true value indicates that blanks should be retained as blank
-        strings. The default false value indicates that blank values
-        are to be ignored and treated as if they were  not included.
-
-    encoding and errors: specify how to decode percent-encoded sequences
-        into Unicode characters, as accepted by the bytes.decode() method.
-
-    fields_limit: maximum number of fields parsed or an exception
-        is raised. None means no limit and is the default.
-    """
-    if fields_limit:
-        pairs = FIELDS_MATCH.split(qs, fields_limit)
-        if len(pairs) > fields_limit:
-            raise TooManyFieldsSent(
-                'The number of GET/POST parameters exceeded '
-                'settings.DATA_UPLOAD_MAX_NUMBER_FIELDS.'
-            )
-    else:
-        pairs = FIELDS_MATCH.split(qs)
-    r = []
-    for name_value in pairs:
-        if not name_value:
-            continue
-        nv = name_value.split('=', 1)
-        if len(nv) != 2:
-            # Handle case of a control-name with no equal sign
-            if keep_blank_values:
-                nv.append('')
-            else:
-                continue
-        if nv[1] or keep_blank_values:
-            name = nv[0].replace('+', ' ')
-            name = unquote(name, encoding=encoding, errors=errors)
-            value = nv[1].replace('+', ' ')
-            value = unquote(value, encoding=encoding, errors=errors)
-            r.append((name, value))
-    return r
-
-
-def escape_leading_slashes(url):
-    """
-    If redirecting to an absolute path (two leading slashes), a slash must be
-    escaped to prevent browsers from handling the path as schemaless and
-    redirecting to another host.
-    """
-    if url.startswith('//'):
-        url = '/%2F{}'.format(url[2:])
-    return url
+        pass
\ No newline at end of file
diff --git a/test_http_date.py b/test_http_date.py
new file mode 100644
index 0000000000..6180d7d101
--- /dev/null
+++ b/test_http_date.py
@@ -0,0 +1,32 @@
+import datetime
+from django.utils.http import parse_http_date
+
+def test_parse_http_date():
+    # Test cases with current year 2023
+    current_year = 2023
+    
+    # Test cases that should be in the future (within 50 years)
+    result = datetime.datetime.utcfromtimestamp(
+        parse_http_date('Sunday, 06-Nov-30 08:49:37 GMT')
+    )
+    print(f"Year 30 interpreted as: {result.year}")
+    assert result.year == 2030, "Year 30 should be interpreted as 2030"
+    
+    # Test cases that should be in the past (more than 50 years in future)
+    result = datetime.datetime.utcfromtimestamp(
+        parse_http_date('Sunday, 06-Nov-94 08:49:37 GMT')
+    )
+    print(f"Year 94 interpreted as: {result.year}")
+    assert result.year == 1994, "Year 94 should be interpreted as 1994"
+    
+    # Edge cases
+    result = datetime.datetime.utcfromtimestamp(
+        parse_http_date('Sunday, 06-Nov-73 08:49:37 GMT')
+    )
+    print(f"Year 73 interpreted as: {result.year}")
+    assert result.year == 1973, "Year 73 should be interpreted as 1973"
+    
+    print("All tests passed!")
+
+if __name__ == '__main__':
+    test_parse_http_date()
\ No newline at end of file
