diff --git a/requests/utils.py b/requests/utils.py
index 8d17b6b2..0dbcdbd9 100644
--- a/requests/utils.py
+++ b/requests/utils.py
@@ -357,21 +357,66 @@ def get_encoding_from_headers(headers):
 
 
 def stream_decode_response_unicode(iterator, r):
-    """Stream decodes a iterator."""
-
-    if r.encoding is None:
-        for item in iterator:
-            yield item
+    """Stream decodes an iterator.
+    
+    This function provides streaming unicode decoding that matches the behavior
+    of Response.text, including proper encoding detection and error handling.
+    """
+    # Get the encoding - use the same logic as Response.text
+    encoding = r.encoding
+    
+    # Only attempt encoding detection if we don't have an encoding
+    # and haven't consumed the content yet
+    if encoding is None and not r._content_consumed:
+        try:
+            # Read just enough content to detect encoding
+            chunk = next(iterator)
+            encoding = chardet.detect(chunk)['encoding']
+            
+            # Start iteration with our first chunk
+            if encoding is None:
+                yield chunk
+            else:
+                decoder = codecs.getincrementaldecoder(encoding)(errors='replace')
+                rv = decoder.decode(chunk)
+                if rv:
+                    yield rv
+        except StopIteration:
+            return
+        except (UnicodeDecodeError, LookupError):
+            # If detection or decoding fails, yield raw bytes
+            yield chunk
+            encoding = None
+    
+    # If we still don't have an encoding, yield raw bytes
+    if encoding is None:
+        for chunk in iterator:
+            yield chunk
         return
 
-    decoder = codecs.getincrementaldecoder(r.encoding)(errors='replace')
+    # Create decoder if we haven't already
+    if 'decoder' not in locals():
+        decoder = codecs.getincrementaldecoder(encoding)(errors='replace')
+    
+    # Process remaining chunks
     for chunk in iterator:
-        rv = decoder.decode(chunk)
+        try:
+            rv = decoder.decode(chunk)
+            if rv:
+                yield rv
+        except (UnicodeDecodeError, LookupError):
+            # Fall back to chunked replace on decode errors
+            rv = chunk.decode(encoding, 'replace')
+            if rv:
+                yield rv
+    
+    # Handle final bytes
+    try:
+        rv = decoder.decode(b'', final=True)
         if rv:
             yield rv
-    rv = decoder.decode(b'', final=True)
-    if rv:
-        yield rv
+    except (UnicodeDecodeError, LookupError):
+        pass
 
 
 def iter_slices(string, slice_length):
@@ -738,4 +783,4 @@ def urldefragauth(url):
 
     netloc = netloc.rsplit('@', 1)[-1]
 
-    return urlunparse((scheme, netloc, path, params, query, ''))
+    return urlunparse((scheme, netloc, path, params, query, ''))
\ No newline at end of file
