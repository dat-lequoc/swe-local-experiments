{
  "instance_id": "scikit-learn__scikit-learn-15512",
  "model_patch": "diff --git a/sklearn/cluster/_affinity_propagation.py b/sklearn/cluster/_affinity_propagation.py\nindex 4806afee9..2a314d030 100644\n--- a/sklearn/cluster/_affinity_propagation.py\n+++ b/sklearn/cluster/_affinity_propagation.py\n@@ -152,6 +152,7 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n \n     ind = np.arange(n_samples)\n \n+    converged = False\n     for it in range(max_iter):\n         # tmp = A + S; compute responsibilities\n         np.add(A, S, tmp)\n@@ -193,18 +194,28 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n             se = np.sum(e, axis=1)\n             unconverged = (np.sum((se == convergence_iter) + (se == 0))\n                            != n_samples)\n-            if (not unconverged and (K > 0)) or (it == max_iter):\n+            if (not unconverged and (K > 0)):\n                 if verbose:\n                     print(\"Converged after %d iterations.\" % it)\n+                converged = True\n                 break\n-    else:\n-        if verbose:\n-            print(\"Did not converge\")\n+            elif it == max_iter - 1:\n+                warnings.warn(\"Affinity propagation did not converge, this model \"\n+                          \"will not have any cluster centers.\", ConvergenceWarning)\n+                break\n+    \n+    if verbose and not converged:\n+        print(\"Did not converge\")\n \n     I = np.flatnonzero(E)\n     K = I.size  # Identify exemplars\n \n-    if K > 0:\n+    if not converged or K == 0:\n+        warnings.warn(\"Affinity propagation did not converge, this model \"\n+                      \"will not have any cluster centers.\", ConvergenceWarning)\n+        labels = np.array([-1] * n_samples)\n+        cluster_centers_indices = []\n+    else:\n         c = np.argmax(S[:, I], axis=1)\n         c[I] = np.arange(K)  # Identify clusters\n         # Refine the final set of exemplars and clusters and return results\n@@ -219,11 +230,6 @@ def affinity_propagation(S, preference=None, convergence_iter=15, max_iter=200,\n         # Reduce labels to a sorted, gapless, list\n         cluster_centers_indices = np.unique(labels)\n         labels = np.searchsorted(cluster_centers_indices, labels)\n-    else:\n-        warnings.warn(\"Affinity propagation did not converge, this model \"\n-                      \"will not have any cluster centers.\", ConvergenceWarning)\n-        labels = np.array([-1] * n_samples)\n-        cluster_centers_indices = []\n \n     if return_n_iter:\n         return cluster_centers_indices, labels, it + 1\n@@ -336,7 +342,28 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n     def __init__(self, damping=.5, max_iter=200, convergence_iter=15,\n                  copy=True, preference=None, affinity='euclidean',\n                  verbose=False):\n+        \"\"\"Initialize AffinityPropagation object.\n \n+        Parameters\n+        ----------\n+        damping : float, optional, default: 0.5\n+            Damping factor between 0.5 and 1.\n+        max_iter : int, optional, default: 200\n+            Maximum number of iterations.\n+        convergence_iter : int, optional, default: 15\n+            Number of iterations with no change in the number\n+            of estimated clusters that stops the convergence.\n+        copy : boolean, optional, default: True\n+            Make a copy of input data.\n+        preference : array-like, shape (n_samples,) or float, optional\n+            Preferences for each point - points with larger values of\n+            preferences are more likely to be chosen as exemplars.\n+        affinity : string, optional, default='euclidean'\n+            Which affinity to use. At the moment 'precomputed' and\n+            'euclidean' are supported.\n+        verbose : boolean, optional, default: False\n+            Whether to be verbose.\n+        \"\"\"\n         self.damping = damping\n         self.max_iter = max_iter\n         self.convergence_iter = convergence_iter\n@@ -387,6 +414,9 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n                 self.affinity_matrix_, self.preference, max_iter=self.max_iter,\n                 convergence_iter=self.convergence_iter, damping=self.damping,\n                 copy=self.copy, verbose=self.verbose, return_n_iter=True)\n+        \n+        # Set converged_ attribute based on whether we found any centers\n+        self.converged_ = len(self.cluster_centers_indices_) > 0\n \n         if self.affinity != \"precomputed\":\n             self.cluster_centers_ = X[self.cluster_centers_indices_].copy()\n@@ -440,4 +470,4 @@ class AffinityPropagation(ClusterMixin, BaseEstimator):\n         labels : ndarray, shape (n_samples,)\n             Cluster labels.\n         \"\"\"\n-        return super().fit_predict(X, y)\n+        return super().fit_predict(X, y)\n\\ No newline at end of file\ndiff --git a/sklearn/cluster/tests/test_affinity_propagation.py b/sklearn/cluster/tests/test_affinity_propagation.py\nindex 98f0f79ee..d20c87d4f 100644\n--- a/sklearn/cluster/tests/test_affinity_propagation.py\n+++ b/sklearn/cluster/tests/test_affinity_propagation.py\n@@ -151,6 +151,20 @@ def test_affinity_propagation_predict_non_convergence():\n     y = assert_warns(ConvergenceWarning, af.predict, to_predict)\n     assert_array_equal(np.array([-1, -1, -1]), y)\n \n+def test_affinity_propagation_non_convergence_behavior():\n+    # Test that non-convergence returns empty centers and -1 labels\n+    X = np.array([[1, 0, 0, 0, 0, 0],\n+                  [0, 1, 1, 1, 0, 0],\n+                  [0, 0, 1, 0, 0, 1]])\n+    \n+    # Force non-convergence with max_iter=2\n+    af = AffinityPropagation(max_iter=2)\n+    assert_warns(ConvergenceWarning, af.fit, X)\n+    \n+    # Verify empty centers and -1 labels\n+    assert_array_equal([], af.cluster_centers_indices_)\n+    assert_array_equal(np.array([-1, -1, -1]), af.labels_)\n+\n \n def test_equal_similarities_and_preferences():\n     # Unequal distances\n@@ -186,4 +200,4 @@ def test_affinity_propagation_convergence_warning_dense_sparse(centers):\n     with pytest.warns(None) as record:\n         assert_array_equal(ap.predict(X),\n                            np.zeros(X.shape[0], dtype=int))\n-    assert len(record) == 0\n+    assert len(record) == 0\n\\ No newline at end of file\n",
  "model_name_or_path": "KortixAI"
}