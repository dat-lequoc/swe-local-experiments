{"messages": [{"role": "user", "content": "First, examine the current state of the workspace:\n<workspace>\n<directory path=\"/testbed\">\n/testbed/AUTHORS\n/testbed/Django.egg-info\n/testbed/Gruntfile.js\n/testbed/INSTALL\n/testbed/LICENSE\n/testbed/LICENSE.python\n/testbed/MANIFEST.in\n/testbed/django\n/testbed/docs\n/testbed/extras\n/testbed/js_tests\n/testbed/package.json\n/testbed/pyproject.toml\n/testbed/scripts\n/testbed/setup.cfg\n/testbed/setup.py\n/testbed/tests\n/testbed/tox.ini\n</directory>\n<directory path=\"/testbed/django/\">\n/testbed/django/__init__.py\n/testbed/django/__main__.py\n/testbed/django/__pycache__\n/testbed/django/apps\n/testbed/django/apps/__init__.py\n/testbed/django/apps/__pycache__\n/testbed/django/apps/config.py\n/testbed/django/apps/registry.py\n/testbed/django/conf\n/testbed/django/conf/__init__.py\n/testbed/django/conf/__pycache__\n/testbed/django/conf/app_template\n/testbed/django/conf/global_settings.py\n/testbed/django/conf/locale\n/testbed/django/conf/project_template\n/testbed/django/conf/urls\n/testbed/django/contrib\n/testbed/django/contrib/__init__.py\n/testbed/django/contrib/__pycache__\n/testbed/django/contrib/admin\n/testbed/django/contrib/admindocs\n/testbed/django/contrib/auth\n/testbed/django/contrib/contenttypes\n/testbed/django/contrib/flatpages\n/testbed/django/contrib/gis\n/testbed/django/contrib/humanize\n/testbed/django/contrib/messages\n/testbed/django/contrib/postgres\n/testbed/django/contrib/redirects\n/testbed/django/contrib/sessions\n/testbed/django/contrib/sitemaps\n/testbed/django/contrib/sites\n/testbed/django/contrib/staticfiles\n/testbed/django/contrib/syndication\n/testbed/django/core\n/testbed/django/core/__init__.py\n/testbed/django/core/__pycache__\n/testbed/django/core/asgi.py\n/testbed/django/core/cache\n/testbed/django/core/checks\n/testbed/django/core/exceptions.py\n/testbed/django/core/files\n/testbed/django/core/handlers\n/testbed/django/core/mail\n/testbed/django/core/management\n/testbed/django/core/paginator.py\n/testbed/django/core/serializers\n/testbed/django/core/servers\n/testbed/django/core/signals.py\n/testbed/django/core/signing.py\n/testbed/django/core/validators.py\n/testbed/django/core/wsgi.py\n/testbed/django/db\n/testbed/django/db/__init__.py\n/testbed/django/db/__pycache__\n/testbed/django/db/backends\n/testbed/django/db/migrations\n/testbed/django/db/models\n/testbed/django/db/transaction.py\n/testbed/django/db/utils.py\n/testbed/django/dispatch\n/testbed/django/dispatch/__init__.py\n/testbed/django/dispatch/__pycache__\n/testbed/django/dispatch/dispatcher.py\n/testbed/django/dispatch/license.txt\n/testbed/django/forms\n/testbed/django/forms/__init__.py\n/testbed/django/forms/__pycache__\n/testbed/django/forms/boundfield.py\n/testbed/django/forms/fields.py\n/testbed/django/forms/forms.py\n/testbed/django/forms/formsets.py\n/testbed/django/forms/jinja2\n/testbed/django/forms/models.py\n/testbed/django/forms/renderers.py\n/testbed/django/forms/templates\n/testbed/django/forms/utils.py\n/testbed/django/forms/widgets.py\n/testbed/django/http\n/testbed/django/http/__init__.py\n/testbed/django/http/__pycache__\n/testbed/django/http/cookie.py\n/testbed/django/http/multipartparser.py\n/testbed/django/http/request.py\n/testbed/django/http/response.py\n/testbed/django/middleware\n/testbed/django/middleware/__init__.py\n/testbed/django/middleware/__pycache__\n/testbed/django/middleware/cache.py\n/testbed/django/middleware/clickjacking.py\n/testbed/django/middleware/common.py\n/testbed/django/middleware/csrf.py\n/testbed/django/middleware/gzip.py\n/testbed/django/middleware/http.py\n/testbed/django/middleware/locale.py\n/testbed/django/middleware/security.py\n/testbed/django/shortcuts.py\n/testbed/django/template\n/testbed/django/template/__init__.py\n/testbed/django/template/__pycache__\n/testbed/django/template/autoreload.py\n/testbed/django/template/backends\n/testbed/django/template/base.py\n/testbed/django/template/context.py\n/testbed/django/template/context_processors.py\n/testbed/django/template/defaultfilters.py\n/testbed/django/template/defaulttags.py\n/testbed/django/template/engine.py\n/testbed/django/template/exceptions.py\n/testbed/django/template/library.py\n/testbed/django/template/loader.py\n/testbed/django/template/loader_tags.py\n/testbed/django/template/loaders\n/testbed/django/template/response.py\n/testbed/django/template/smartif.py\n/testbed/django/template/utils.py\n/testbed/django/templatetags\n/testbed/django/templatetags/__init__.py\n/testbed/django/templatetags/__pycache__\n/testbed/django/templatetags/cache.py\n/testbed/django/templatetags/i18n.py\n/testbed/django/templatetags/l10n.py\n/testbed/django/templatetags/static.py\n/testbed/django/templatetags/tz.py\n/testbed/django/test\n/testbed/django/test/__init__.py\n/testbed/django/test/__pycache__\n/testbed/django/test/client.py\n/testbed/django/test/html.py\n/testbed/django/test/runner.py\n/testbed/django/test/selenium.py\n/testbed/django/test/signals.py\n/testbed/django/test/testcases.py\n/testbed/django/test/utils.py\n/testbed/django/urls\n/testbed/django/urls/__init__.py\n/testbed/django/urls/__pycache__\n/testbed/django/urls/base.py\n/testbed/django/urls/conf.py\n/testbed/django/urls/converters.py\n/testbed/django/urls/exceptions.py\n/testbed/django/urls/resolvers.py\n/testbed/django/urls/utils.py\n/testbed/django/utils\n/testbed/django/utils/__init__.py\n/testbed/django/utils/__pycache__\n/testbed/django/utils/_os.py\n/testbed/django/utils/archive.py\n/testbed/django/utils/asyncio.py\n/testbed/django/utils/autoreload.py\n/testbed/django/utils/cache.py\n/testbed/django/utils/connection.py\n/testbed/django/utils/crypto.py\n/testbed/django/utils/datastructures.py\n/testbed/django/utils/dateformat.py\n/testbed/django/utils/dateparse.py\n/testbed/django/utils/dates.py\n/testbed/django/utils/deconstruct.py\n/testbed/django/utils/decorators.py\n/testbed/django/utils/deprecation.py\n/testbed/django/utils/duration.py\n/testbed/django/utils/encoding.py\n/testbed/django/utils/feedgenerator.py\n/testbed/django/utils/formats.py\n/testbed/django/utils/functional.py\n/testbed/django/utils/hashable.py\n/testbed/django/utils/html.py\n/testbed/django/utils/http.py\n/testbed/django/utils/inspect.py\n/testbed/django/utils/ipv6.py\n/testbed/django/utils/itercompat.py\n/testbed/django/utils/jslex.py\n/testbed/django/utils/log.py\n/testbed/django/utils/lorem_ipsum.py\n/testbed/django/utils/module_loading.py\n/testbed/django/utils/numberformat.py\n/testbed/django/utils/regex_helper.py\n/testbed/django/utils/safestring.py\n/testbed/django/utils/termcolors.py\n/testbed/django/utils/text.py\n/testbed/django/utils/timesince.py\n/testbed/django/utils/timezone.py\n/testbed/django/utils/translation\n/testbed/django/utils/tree.py\n/testbed/django/utils/version.py\n/testbed/django/utils/xmlutils.py\n/testbed/django/views\n/testbed/django/views/__init__.py\n/testbed/django/views/__pycache__\n/testbed/django/views/csrf.py\n/testbed/django/views/debug.py\n/testbed/django/views/decorators\n/testbed/django/views/defaults.py\n/testbed/django/views/generic\n/testbed/django/views/i18n.py\n/testbed/django/views/static.py\n/testbed/django/views/templates\n</directory>\n<IMPLEMENTATION_TRAILS>\n<implementation_trial id=\"A\" status=\"tried; not working\">\n[Approach: Modify Field Validation]\n- Update get_related_selections() to check reverse relationships\n- Add validation for reverse one-to-one fields\n- Failed because it didn't address the core issue of field selection\n\nAnalysis: This approach only fixed the validation but didn't address the field selection issue.\n</implementation_trial>\n<implementation_trial id=\"B\" status=\"currently implementing\">\n[Approach: Enhance Related Field Resolution]\nKey changes:\n1. Update get_related_selections() to handle reverse relations:\n```python\ndef get_related_selections(self, select, select_mask):\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    # Handle forward relations\n    if self.query.select_related:\n        for field_name in self.query.select_related:\n            field = opts.get_field(field_name)\n            if hasattr(field, 'remote_field'):\n                related_klass_infos.append(\n                    self.get_related_klass_info(select, field, field.remote_field.model)\n                )\n    \n    # Handle reverse relations\n    for related in opts.related_objects:\n        if related.field.unique:  # One-to-one reverse relation\n            if related.get_accessor_name() in self.query.select_related:\n                related_klass_infos.append(\n                    self.get_related_klass_info(\n                        select,\n                        related.field,\n                        related.related_model,\n                        reverse=True\n                    )\n                )\n    \n    return related_klass_infos\n```\n\n2. Modify field selection to respect only() for reverse relations:\n```python\ndef get_related_klass_info(self, select, field, model, reverse=False):\n    if reverse:\n        to_field = field\n        from_field = field.remote_field\n    else:\n        from_field = field\n        to_field = field.remote_field\n        \n    select_fields = []\n    if self.query.deferred_loading:\n        only_load, _ = self.query.deferred_loading\n        if only_load:\n            select_fields = [f.attname for f in to_field.model._meta.concrete_fields\n                           if f.attname in only_load]\n    \n    return {\n        'model': model,\n        'field': field,\n        'reverse': reverse,\n        'select_fields': select_fields,\n    }\n```\n\nThis approach:\n- Properly handles reverse one-to-one relationships\n- Respects field selection from only()\n- Maintains compatibility with existing code\n- Handles edge cases properly\n</implementation_trial>\n<implementation_trial id=\"C\" status=\"not tried\">\n[Approach: Query Rewrite]\n- Completely rewrite query generation for reverse relations\n- More complex but could provide better long-term solution\n- Higher risk of breaking changes\n</implementation_trial>\n<implementation_trial id=\"D\" status=\"currently implementing\">\n[Approach: Fix Reverse OneToOne Field Recognition]\nKey changes:\n1. Modify get_related_selections() to properly handle reverse one-to-one fields:\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name instead of related_query_name\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    for name in self.query.select_related:\n        # Handle reverse relations\n        related_field = None\n        for f in opts.related_objects:\n            if f.get_accessor_name() == name:\n                related_field = f\n                break\n                \n        if related_field:\n            related_select_mask = select_mask.get(name) if select_mask else None\n            klass_info = {\n                'model': related_field.related_model,\n                'field': related_field.field,\n                'reverse': True,\n                'local_setter': related_field.field.set_cached_value,\n                'remote_setter': related_field.field.remote_field.set_cached_value,\n                'from_parent': False\n            }\n            related_klass_infos.append(klass_info)\n            \n            # Handle field selection for only()\n            select_fields = []\n            if related_select_mask:\n                for field in related_field.related_model._meta.concrete_fields:\n                    if field.attname in related_select_mask:\n                        select_fields.append(len(select))\n                        select.append((field.get_col(related_field.field.m2m_db_table()), None))\n            klass_info['select_fields'] = select_fields\n            \n        # Handle forward relations as before\n        else:\n            field = opts.get_field(name)\n            if hasattr(field, 'get_path_info'):\n                klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\nThis approach:\n- Uses get_accessor_name() to properly identify reverse relations\n- Handles both forward and reverse one-to-one fields\n- Properly applies field selection from only()\n- Maintains existing behavior for other relation types\n\nAnalysis:\n- Pros:\n  - Properly handles reverse one-to-one relations\n  - Maintains compatibility with existing code\n  - Correctly applies field selection\n- Cons:\n  - More complex implementation\n  - Need to handle edge cases carefully\n\nTest results pending implementation.\n</implementation_trial>\n<implementation_trial id=\"E\" status=\"currently implementing\">\n[Approach: Fix Reverse OneToOne Recognition in get_related_selections]\n\nKey changes:\n1. Modify get_related_selections() to properly handle reverse relations:\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name for reverse relations\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    # Handle reverse relations\n    for name in self.query.select_related:\n        related_field = None\n        for f in opts.related_objects:\n            if f.get_accessor_name() == name:\n                related_field = f\n                break\n                \n        if related_field:\n            related_select_mask = select_mask.get(name) if select_mask else None\n            klass_info = {\n                'model': related_field.related_model,\n                'field': related_field.field,\n                'reverse': True,\n                'local_setter': related_field.field.set_cached_value,\n                'remote_setter': related_field.field.remote_field.set_cached_value,\n                'from_parent': False\n            }\n            related_klass_infos.append(klass_info)\n            \n            # Handle field selection for only()\n            select_fields = []\n            if related_select_mask:\n                for field in related_field.related_model._meta.concrete_fields:\n                    if field.attname in related_select_mask:\n                        select_fields.append(len(select))\n                        select.append((field.get_col(related_field.field.m2m_db_table()), None))\n            klass_info['select_fields'] = select_fields\n            \n        # Handle forward relations as before\n        else:\n            field = opts.get_field(name)\n            if hasattr(field, 'get_path_info'):\n                klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\nPros:\n- Properly handles reverse one-to-one relationships\n- Maintains compatibility with existing code\n- Supports field selection via only()\n- Handles edge cases correctly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Properly identifying reverse one-to-one relationships\n2. Using correct accessor names for reverse relations\n3. Supporting field selection through only()\n4. Maintaining existing behavior for forward relations\n</implementation_trial>\n<implementation_trial id=\"F\" status=\"currently implementing\">\n[Approach: Enhanced Reverse OneToOne Recognition]\n\nKey changes:\n1. Modify get_related_selections() to properly handle reverse one-to-one fields:\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name instead of related_query_name\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.m2m_db_table()), None))\n                klass_info['select_fields'] = select_fields\n\n    return related_klass_infos\n```\n\n2. Update field resolution to handle reverse one-to-one fields:\n```python\ndef resolve_related_fields(self):\n    related_fields = super().resolve_related_fields()\n    if self.field.one_to_one and not self.field.concrete:\n        # Handle reverse one-to-one fields\n        related_fields = [(f, f.remote_field) for f in related_fields]\n    return related_fields\n```\n\nPros:\n- Properly handles reverse one-to-one relationships\n- Maintains compatibility with existing code\n- Supports field selection via only()\n- Handles edge cases correctly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Properly handling one-to-one field resolution\n3. Supporting field selection through only()\n4. Maintaining existing behavior for other relations\n</implementation_trial>\n<implementation_trial id=\"G\" status=\"not tried\">\n[Approach: Query Builder Refactor]\n- Complete refactor of query building for reverse relations\n- More complex but could provide better long-term solution\n- Higher risk of breaking changes\n</implementation_trial>\n<implementation_trial id=\"H\" status=\"currently implementing\">\n[Approach: Enhanced Reverse OneToOne Field Resolution]\n\nKey changes:\n1. Update get_related_selections() to properly handle reverse relations:\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name for reverse relations\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.db_table), None))\n                klass_info['select_fields'] = select_fields\n\n            # Handle forward relations as before\n            else:\n                field = opts.get_field(name)\n                if hasattr(field, 'get_path_info'):\n                    klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                    related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\n2. Update field validation to include reverse relations:\n```python\ndef _check_field_choices(self):\n    opts = self.query.get_meta()\n    valid_fields = set(\n        chain(\n            (f.name for f in opts.fields if f.is_relation),\n            (f.get_accessor_name() for f in opts.related_objects if f.field.unique)\n        )\n    )\n    return valid_fields\n```\n\nPros:\n- Properly handles reverse one-to-one fields\n- Maintains existing behavior for forward relations\n- Correctly applies field selection from only()\n- Handles edge cases properly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Properly handling one-to-one field resolution\n3. Supporting field selection through only()\n4. Maintaining existing behavior for other relations\n</implementation_trial>\n<implementation_trial id=\"I\" status=\"currently implementing\">\n[Approach: Enhanced Reverse OneToOne Field Resolution]\n\nKey changes to get_related_selections():\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name for reverse relations\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.db_table), None))\n                klass_info['select_fields'] = select_fields\n\n            # Handle forward relations as before\n            else:\n                field = opts.get_field(name)\n                if hasattr(field, 'get_path_info'):\n                    klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                    related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\nPros:\n- Properly handles reverse one-to-one relationships\n- Maintains existing behavior for forward relations\n- Correctly applies field selection from only()\n- Handles edge cases properly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Properly handling one-to-one field resolution\n3. Supporting field selection through only()\n4. Maintaining existing behavior for other relations\n</implementation_trial>\n<implementation_trial id=\"J\" status=\"currently implementing\">\n[Approach: Enhanced Reverse OneToOne Field Resolution]\n\nKey changes to get_related_selections():\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name for reverse relations\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.db_table), None))\n                klass_info['select_fields'] = select_fields\n\n            # Handle forward relations as before\n            else:\n                field = opts.get_field(name)\n                if hasattr(field, 'get_path_info'):\n                    klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                    related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\nPros:\n- Properly handles reverse one-to-one relationships\n- Maintains existing behavior for forward relations\n- Correctly applies field selection from only()\n- Handles edge cases properly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Properly handling one-to-one field resolution\n3. Supporting field selection through only()\n4. Maintaining existing behavior for other relations\n</implementation_trial>\n<implementation_trial id=\"K\" status=\"not tried\">\n[Approach: Field Resolution Refactor]\n- Complete refactor of field resolution logic\n- Separate handling for forward and reverse relations\n- More complex but potentially more maintainable\n</implementation_trial>\n<implementation_trial id=\"L\" status=\"currently implementing\">\n[Approach: Enhanced Reverse OneToOne Field Resolution]\n\nKey changes to get_related_selections():\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name for reverse relations\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.db_table), None))\n                klass_info['select_fields'] = select_fields\n\n            # Handle forward relations as before\n            else:\n                field = opts.get_field(name)\n                if hasattr(field, 'get_path_info'):\n                    klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                    related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\nPros:\n- Properly handles reverse one-to-one relationships\n- Maintains existing behavior for forward relations\n- Correctly applies field selection from only()\n- Handles edge cases properly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Properly handling one-to-one field resolution\n3. Supporting field selection through only()\n4. Maintaining existing behavior for other relations\n</implementation_trial>\n<implementation_trial id=\"M\" status=\"currently implementing\">\n[Approach: Enhanced Reverse OneToOne Field Recognition]\n\nKey changes to get_related_selections():\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name instead of related_query_name\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.db_table), None))\n                klass_info['select_fields'] = select_fields\n\n    return related_klass_infos\n```\n\nPros:\n- Properly handles reverse one-to-one relationships\n- Uses correct accessor names\n- Maintains existing behavior for other relations\n- Supports field selection via only()\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Including one-to-one fields in valid choices\n3. Properly handling field selection\n4. Maintaining existing behavior for other relations\n</implementation_trial>\n<implementation_trial id=\"N\" status=\"currently implementing\">\n[Approach: Enhanced Reverse OneToOne Field Resolution]\n\nKey changes to get_related_selections():\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name for reverse relations\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.db_table), None))\n                klass_info['select_fields'] = select_fields\n\n            # Handle forward relations as before\n            else:\n                field = opts.get_field(name)\n                if hasattr(field, 'get_path_info'):\n                    klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                    related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\nPros:\n- Properly handles reverse one-to-one relationships\n- Maintains existing behavior for forward relations\n- Correctly applies field selection from only()\n- Handles edge cases properly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Including one-to-one fields in valid choices\n3. Properly handling field selection\n4. Maintaining existing behavior for other relations\n</implementation_trial>\n</IMPLEMENTATION_TRAILS>\n<file path=\"/testbed/django/db/models/sql/compiler.py\">\nimport collections\nimport json\nimport re\nfrom functools import partial\nfrom itertools import chain\n\nfrom django.core.exceptions import EmptyResultSet, FieldError, FullResultSet\nfrom django.db import DatabaseError, NotSupportedError\nfrom django.db.models.constants import LOOKUP_SEP\nfrom django.db.models.expressions import F, OrderBy, RawSQL, Ref, Value\nfrom django.db.models.functions import Cast, Random\nfrom django.db.models.lookups import Lookup\nfrom django.db.models.query_utils import select_related_descend\nfrom django.db.models.sql.constants import (\n    CURSOR,\n    GET_ITERATOR_CHUNK_SIZE,\n    MULTI,\n    NO_RESULTS,\n    ORDER_DIR,\n    SINGLE,\n)\nfrom django.db.models.sql.query import Query, get_order_dir\nfrom django.db.models.sql.where import AND\nfrom django.db.transaction import TransactionManagementError\nfrom django.utils.functional import cached_property\nfrom django.utils.hashable import make_hashable\nfrom django.utils.regex_helper import _lazy_re_compile\n\n\nclass PositionRef(Ref):\n    def __init__(self, ordinal, refs, source):\n        self.ordinal = ordinal\n        super().__init__(refs, source)\n\n    def as_sql(self, compiler, connection):\n        return str(self.ordinal), ()\n\n\nclass SQLCompiler:\n    # Multiline ordering SQL clause may appear from RawSQL.\n    ordering_parts = _lazy_re_compile(\n        r\"^(.*)\\s(?:ASC|DESC).*\",\n        re.MULTILINE | re.DOTALL,\n    )\n\n    def __init__(self, query, connection, using, elide_empty=True):\n        self.query = query\n        self.connection = connection\n        self.using = using\n        # Some queries, e.g. coalesced aggregation, need to be executed even if\n        # they would return an empty result set.\n        self.elide_empty = elide_empty\n        self.quote_cache = {\"*\": \"*\"}\n        # The select, klass_info, and annotations are needed by QuerySet.iterator()\n        # these are set as a side-effect of executing the query. Note that we calculate\n        # separately a list of extra select columns needed for grammatical correctness\n        # of the query, but these columns are not included in self.select.\n        self.select = None\n        self.annotation_col_map = None\n        self.klass_info = None\n        self._meta_ordering = None\n\n    def __repr__(self):\n        return (\n            f\"<{self.__class__.__qualname__} \"\n            f\"model={self.query.model.__qualname__} \"\n            f\"connection={self.connection!r} using={self.using!r}>\"\n        )\n\n    def setup_query(self, with_col_aliases=False):\n        if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):\n            self.query.get_initial_alias()\n        self.select, self.klass_info, self.annotation_col_map = self.get_select(\n            with_col_aliases=with_col_aliases,\n        )\n        self.col_count = len(self.select)\n\n    def pre_sql_setup(self, with_col_aliases=False):\n        \"\"\"\n        Do any necessary class setup immediately prior to producing SQL. This\n        is for things that can't necessarily be done in __init__ because we\n        might not have all the pieces in place at that time.\n        \"\"\"\n        self.setup_query(with_col_aliases=with_col_aliases)\n        order_by = self.get_order_by()\n        self.where, self.having, self.qualify = self.query.where.split_having_qualify(\n            must_group_by=self.query.group_by is not None\n        )\n        extra_select = self.get_extra_select(order_by, self.select)\n        self.has_extra_select = bool(extra_select)\n        group_by = self.get_group_by(self.select + extra_select, order_by)\n        return extra_select, order_by, group_by\n\n    def get_group_by(self, select, order_by):\n        \"\"\"\n        Return a list of 2-tuples of form (sql, params).\n\n        The logic of what exactly the GROUP BY clause contains is hard\n        to describe in other words than \"if it passes the test suite,\n        then it is correct\".\n        \"\"\"\n        # Some examples:\n        #     SomeModel.objects.annotate(Count('somecol'))\n        #     GROUP BY: all fields of the model\n        #\n        #    SomeModel.objects.values('name').annotate(Count('somecol'))\n        #    GROUP BY: name\n        #\n        #    SomeModel.objects.annotate(Count('somecol')).values('name')\n        #    GROUP BY: all cols of the model\n        #\n        #    SomeModel.objects.values('name', 'pk')\n        #    .annotate(Count('somecol')).values('pk')\n        #    GROUP BY: name, pk\n        #\n        #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')\n        #    GROUP BY: name, pk\n        #\n        # In fact, the self.query.group_by is the minimal set to GROUP BY. It\n        # can't be ever restricted to a smaller set, but additional columns in\n        # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately\n        # the end result is that it is impossible to force the query to have\n        # a chosen GROUP BY clause - you can almost do this by using the form:\n        #     .values(*wanted_cols).annotate(AnAggregate())\n        # but any later annotations, extra selects, values calls that\n        # refer some column outside of the wanted_cols, order_by, or even\n        # filter calls can alter the GROUP BY clause.\n\n        # The query.group_by is either None (no GROUP BY at all), True\n        # (group by select fields), or a list of expressions to be added\n        # to the group by.\n        if self.query.group_by is None:\n            return []\n        expressions = []\n        group_by_refs = set()\n        if self.query.group_by is not True:\n            # If the group by is set to a list (by .values() call most likely),\n            # then we need to add everything in it to the GROUP BY clause.\n            # Backwards compatibility hack for setting query.group_by. Remove\n            # when we have public API way of forcing the GROUP BY clause.\n            # Converts string references to expressions.\n            for expr in self.query.group_by:\n                if not hasattr(expr, \"as_sql\"):\n                    expr = self.query.resolve_ref(expr)\n                if isinstance(expr, Ref):\n                    if expr.refs not in group_by_refs:\n                        group_by_refs.add(expr.refs)\n                        expressions.append(expr.source)\n                else:\n                    expressions.append(expr)\n        # Note that even if the group_by is set, it is only the minimal\n        # set to group by. So, we need to add cols in select, order_by, and\n        # having into the select in any case.\n        selected_expr_positions = {}\n        for ordinal, (expr, _, alias) in enumerate(select, start=1):\n            if alias:\n                selected_expr_positions[expr] = ordinal\n            # Skip members of the select clause that are already explicitly\n            # grouped against.\n            if alias in group_by_refs:\n                continue\n            expressions.extend(expr.get_group_by_cols())\n        if not self._meta_ordering:\n            for expr, (sql, params, is_ref) in order_by:\n                # Skip references to the SELECT clause, as all expressions in\n                # the SELECT clause are already part of the GROUP BY.\n                if not is_ref:\n                    expressions.extend(expr.get_group_by_cols())\n        having_group_by = self.having.get_group_by_cols() if self.having else ()\n        for expr in having_group_by:\n            expressions.append(expr)\n        result = []\n        seen = set()\n        expressions = self.collapse_group_by(expressions, having_group_by)\n\n        allows_group_by_select_index = (\n            self.connection.features.allows_group_by_select_index\n        )\n        for expr in expressions:\n            try:\n                sql, params = self.compile(expr)\n            except (EmptyResultSet, FullResultSet):\n                continue\n            if (\n                allows_group_by_select_index\n                and (position := selected_expr_positions.get(expr)) is not None\n            ):\n                sql, params = str(position), ()\n            else:\n                sql, params = expr.select_format(self, sql, params)\n            params_hash = make_hashable(params)\n            if (sql, params_hash) not in seen:\n                result.append((sql, params))\n                seen.add((sql, params_hash))\n        return result\n\n    def collapse_group_by(self, expressions, having):\n        # If the database supports group by functional dependence reduction,\n        # then the expressions can be reduced to the set of selected table\n        # primary keys as all other columns are functionally dependent on them.\n        if self.connection.features.allows_group_by_selected_pks:\n            # Filter out all expressions associated with a table's primary key\n            # present in the grouped columns. This is done by identifying all\n            # tables that have their primary key included in the grouped\n            # columns and removing non-primary key columns referring to them.\n            # Unmanaged models are excluded because they could be representing\n            # database views on which the optimization might not be allowed.\n            pks = {\n                expr\n                for expr in expressions\n                if (\n                    hasattr(expr, \"target\")\n                    and expr.target.primary_key\n                    and self.connection.features.allows_group_by_selected_pks_on_model(\n                        expr.target.model\n                    )\n                )\n            }\n            aliases = {expr.alias for expr in pks}\n            expressions = [\n                expr\n                for expr in expressions\n                if expr in pks\n                or expr in having\n                or getattr(expr, \"alias\", None) not in aliases\n            ]\n        return expressions\n\n    def get_select(self, with_col_aliases=False):\n        \"\"\"\n        Return three values:\n        - a list of 3-tuples of (expression, (sql, params), alias)\n        - a klass_info structure,\n        - a dictionary of annotations\n\n        The (sql, params) is what the expression will produce, and alias is the\n        \"AS alias\" for the column (possibly None).\n\n        The klass_info structure contains the following information:\n        - The base model of the query.\n        - Which columns for that model are present in the query (by\n          position of the select clause).\n        - related_klass_infos: [f, klass_info] to descent into\n\n        The annotations is a dictionary of {'attname': column position} values.\n        \"\"\"\n        select = []\n        klass_info = None\n        annotations = {}\n        select_idx = 0\n        for alias, (sql, params) in self.query.extra_select.items():\n            annotations[alias] = select_idx\n            select.append((RawSQL(sql, params), alias))\n            select_idx += 1\n        assert not (self.query.select and self.query.default_cols)\n        select_mask = self.query.get_select_mask()\n        if self.query.default_cols:\n            cols = self.get_default_columns(select_mask)\n        else:\n            # self.query.select is a special case. These columns never go to\n            # any model.\n            cols = self.query.select\n        if cols:\n            select_list = []\n            for col in cols:\n                select_list.append(select_idx)\n                select.append((col, None))\n                select_idx += 1\n            klass_info = {\n                \"model\": self.query.model,\n                \"select_fields\": select_list,\n            }\n        for alias, annotation in self.query.annotation_select.items():\n            annotations[alias] = select_idx\n            select.append((annotation, alias))\n            select_idx += 1\n\n        if self.query.select_related:\n            related_klass_infos = self.get_related_selections(select, select_mask)\n            klass_info[\"related_klass_infos\"] = related_klass_infos\n\n            def get_select_from_parent(klass_info):\n                for ki in klass_info[\"related_klass_infos\"]:\n                    if ki[\"from_parent\"]:\n                        ki[\"select_fields\"] = (\n                            klass_info[\"select_fields\"] + ki[\"select_fields\"]\n                        )\n                    get_select_from_parent(ki)\n\n            get_select_from_parent(klass_info)\n\n        ret = []\n        col_idx = 1\n        for col, alias in select:\n            try:\n                sql, params = self.compile(col)\n            except EmptyResultSet:\n                empty_result_set_value = getattr(\n                    col, \"empty_result_set_value\", NotImplemented\n                )\n                if empty_result_set_value is NotImplemented:\n                    # Select a predicate that's always False.\n                    sql, params = \"0\", ()\n                else:\n                    sql, params = self.compile(Value(empty_result_set_value))\n            except FullResultSet:\n                sql, params = self.compile(Value(True))\n            else:\n                sql, params = col.select_format(self, sql, params)\n            if alias is None and with_col_aliases:\n                alias = f\"col{col_idx}\"\n                col_idx += 1\n            ret.append((col, (sql, params), alias))\n        return ret, klass_info, annotations\n\n    def _order_by_pairs(self):\n        if self.query.extra_order_by:\n            ordering = self.query.extra_order_by\n        elif not self.query.default_ordering:\n            ordering = self.query.order_by\n        elif self.query.order_by:\n            ordering = self.query.order_by\n        elif (meta := self.query.get_meta()) and meta.ordering:\n            ordering = meta.ordering\n            self._meta_ordering = ordering\n        else:\n            ordering = []\n        if self.query.standard_ordering:\n            default_order, _ = ORDER_DIR[\"ASC\"]\n        else:\n            default_order, _ = ORDER_DIR[\"DESC\"]\n\n        selected_exprs = {}\n        # Avoid computing `selected_exprs` if there is no `ordering` as it's\n        # relatively expensive.\n        if ordering and (select := self.select):\n            for ordinal, (expr, _, alias) in enumerate(select, start=1):\n                pos_expr = PositionRef(ordinal, alias, expr)\n                if alias:\n                    selected_exprs[alias] = pos_expr\n                selected_exprs[expr] = pos_expr\n\n        for field in ordering:\n            if hasattr(field, \"resolve_expression\"):\n                if isinstance(field, Value):\n                    # output_field must be resolved for constants.\n                    field = Cast(field, field.output_field)\n                if not isinstance(field, OrderBy):\n                    field = field.asc()\n                if not self.query.standard_ordering:\n                    field = field.copy()\n                    field.reverse_ordering()\n                select_ref = selected_exprs.get(field.expression)\n                if select_ref or (\n                    isinstance(field.expression, F)\n                    and (select_ref := selected_exprs.get(field.expression.name))\n                ):\n                    # Emulation of NULLS (FIRST|LAST) cannot be combined with\n                    # the usage of ordering by position.\n                    if (\n                        field.nulls_first is None and field.nulls_last is None\n                    ) or self.connection.features.supports_order_by_nulls_modifier:\n                        field = field.copy()\n                        field.expression = select_ref\n                    # Alias collisions are not possible when dealing with\n                    # combined queries so fallback to it if emulation of NULLS\n                    # handling is required.\n                    elif self.query.combinator:\n                        field = field.copy()\n                        field.expression = Ref(select_ref.refs, select_ref.source)\n                yield field, select_ref is not None\n                continue\n            if field == \"?\":  # random\n                yield OrderBy(Random()), False\n                continue\n\n            col, order = get_order_dir(field, default_order)\n            descending = order == \"DESC\"\n\n            if select_ref := selected_exprs.get(col):\n                # Reference to expression in SELECT clause\n                yield (\n                    OrderBy(\n                        select_ref,\n                        descending=descending,\n                    ),\n                    True,\n                )\n                continue\n            if col in self.query.annotations:\n                # References to an expression which is masked out of the SELECT\n                # clause.\n                if self.query.combinator and self.select:\n                    # Don't use the resolved annotation because other\n                    # combinated queries might define it differently.\n                    expr = F(col)\n                else:\n                    expr = self.query.annotations[col]\n                    if isinstance(expr, Value):\n                        # output_field must be resolved for constants.\n                        expr = Cast(expr, expr.output_field)\n                yield OrderBy(expr, descending=descending), False\n                continue\n\n            if \".\" in field:\n                # This came in through an extra(order_by=...) addition. Pass it\n                # on verbatim.\n                table, col = col.split(\".\", 1)\n                yield (\n                    OrderBy(\n                        RawSQL(\n                            \"%s.%s\" % (self.quote_name_unless_alias(table), col), []\n                        ),\n                        descending=descending,\n                    ),\n                    False,\n                )\n                continue\n\n            if self.query.extra and col in self.query.extra:\n                if col in self.query.extra_select:\n                    yield (\n                        OrderBy(\n                            Ref(col, RawSQL(*self.query.extra[col])),\n                            descending=descending,\n                        ),\n                        True,\n                    )\n                else:\n                    yield (\n                        OrderBy(RawSQL(*self.query.extra[col]), descending=descending),\n                        False,\n                    )\n            else:\n                if self.query.combinator and self.select:\n                    # Don't use the first model's field because other\n                    # combinated queries might define it differently.\n                    yield OrderBy(F(col), descending=descending), False\n                else:\n                    # 'col' is of the form 'field' or 'field1__field2' or\n                    # '-field1__field2__field', etc.\n                    yield from self.find_ordering_name(\n                        field,\n                        self.query.get_meta(),\n                        default_order=default_order,\n                    )\n\n    def get_order_by(self):\n        \"\"\"\n        Return a list of 2-tuples of the form (expr, (sql, params, is_ref)) for\n        the ORDER BY clause.\n\n        The order_by clause can alter the select clause (for example it can add\n        aliases to clauses that do not yet have one, or it can add totally new\n        select clauses).\n        \"\"\"\n        result = []\n        seen = set()\n        for expr, is_ref in self._order_by_pairs():\n            resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)\n            if not is_ref and self.query.combinator and self.select:\n                src = resolved.expression\n                expr_src = expr.expression\n                for sel_expr, _, col_alias in self.select:\n                    if src == sel_expr:\n                        # When values() is used the exact alias must be used to\n                        # reference annotations.\n                        if (\n                            self.query.has_select_fields\n                            and col_alias in self.query.annotation_select\n                            and not (\n                                isinstance(expr_src, F) and col_alias == expr_src.name\n                            )\n                        ):\n                            continue\n                        resolved.set_source_expressions(\n                            [Ref(col_alias if col_alias else src.target.column, src)]\n                        )\n                        break\n                else:\n                    # Add column used in ORDER BY clause to the selected\n                    # columns and to each combined query.\n                    order_by_idx = len(self.query.select) + 1\n                    col_alias = f\"__orderbycol{order_by_idx}\"\n                    for q in self.query.combined_queries:\n                        # If fields were explicitly selected through values()\n                        # combined queries cannot be augmented.\n                        if q.has_select_fields:\n                            raise DatabaseError(\n                                \"ORDER BY term does not match any column in \"\n                                \"the result set.\"\n                            )\n                        q.add_annotation(expr_src, col_alias)\n                    self.query.add_select_col(resolved, col_alias)\n                    resolved.set_source_expressions([Ref(col_alias, src)])\n            sql, params = self.compile(resolved)\n            # Don't add the same column twice, but the order direction is\n            # not taken into account so we strip it. When this entire method\n            # is refactored into expressions, then we can check each part as we\n            # generate it.\n            without_ordering = self.ordering_parts.search(sql)[1]\n            params_hash = make_hashable(params)\n            if (without_ordering, params_hash) in seen:\n                continue\n            seen.add((without_ordering, params_hash))\n            result.append((resolved, (sql, params, is_ref)))\n        return result\n\n    def get_extra_select(self, order_by, select):\n        extra_select = []\n        if self.query.distinct and not self.query.distinct_fields:\n            select_sql = [t[1] for t in select]\n            for expr, (sql, params, is_ref) in order_by:\n                without_ordering = self.ordering_parts.search(sql)[1]\n                if not is_ref and (without_ordering, params) not in select_sql:\n                    extra_select.append((expr, (without_ordering, params), None))\n        return extra_select\n\n    def quote_name_unless_alias(self, name):\n        \"\"\"\n        A wrapper around connection.ops.quote_name that doesn't quote aliases\n        for table names. This avoids problems with some SQL dialects that treat\n        quoted strings specially (e.g. PostgreSQL).\n        \"\"\"\n        if name in self.quote_cache:\n            return self.quote_cache[name]\n        if (\n            (name in self.query.alias_map and name not in self.query.table_map)\n            or name in self.query.extra_select\n            or (\n                self.query.external_aliases.get(name)\n                and name not in self.query.table_map\n            )\n        ):\n            self.quote_cache[name] = name\n            return name\n        r = self.connection.ops.quote_name(name)\n        self.quote_cache[name] = r\n        return r\n\n    def compile(self, node):\n        vendor_impl = getattr(node, \"as_\" + self.connection.vendor, None)\n        if vendor_impl:\n            sql, params = vendor_impl(self, self.connection)\n        else:\n            sql, params = node.as_sql(self, self.connection)\n        return sql, params\n\n    def get_combinator_sql(self, combinator, all):\n        features = self.connection.features\n        compilers = [\n            query.get_compiler(self.using, self.connection, self.elide_empty)\n            for query in self.query.combined_queries\n        ]\n        if not features.supports_slicing_ordering_in_compound:\n            for compiler in compilers:\n                if compiler.query.is_sliced:\n                    raise DatabaseError(\n                        \"LIMIT/OFFSET not allowed in subqueries of compound statements.\"\n                    )\n                if compiler.get_order_by():\n                    raise DatabaseError(\n                        \"ORDER BY not allowed in subqueries of compound statements.\"\n                    )\n        elif self.query.is_sliced and combinator == \"union\":\n            for compiler in compilers:\n                # A sliced union cannot have its parts elided as some of them\n                # might be sliced as well and in the event where only a single\n                # part produces a non-empty resultset it might be impossible to\n                # generate valid SQL.\n                compiler.elide_empty = False\n        parts = ()\n        for compiler in compilers:\n            try:\n                # If the columns list is limited, then all combined queries\n                # must have the same columns list. Set the selects defined on\n                # the query on all combined queries, if not already set.\n                if not compiler.query.values_select and self.query.values_select:\n                    compiler.query = compiler.query.clone()\n                    compiler.query.set_values(\n                        (\n                            *self.query.extra_select,\n                            *self.query.values_select,\n                            *self.query.annotation_select,\n                        )\n                    )\n                part_sql, part_args = compiler.as_sql(with_col_aliases=True)\n                if compiler.query.combinator:\n                    # Wrap in a subquery if wrapping in parentheses isn't\n                    # supported.\n                    if not features.supports_parentheses_in_compound:\n                        part_sql = \"SELECT * FROM ({})\".format(part_sql)\n                    # Add parentheses when combining with compound query if not\n                    # already added for all compound queries.\n                    elif (\n                        self.query.subquery\n                        or not features.supports_slicing_ordering_in_compound\n                    ):\n                        part_sql = \"({})\".format(part_sql)\n                elif (\n                    self.query.subquery\n                    and features.supports_slicing_ordering_in_compound\n                ):\n                    part_sql = \"({})\".format(part_sql)\n                parts += ((part_sql, part_args),)\n            except EmptyResultSet:\n                # Omit the empty queryset with UNION and with DIFFERENCE if the\n                # first queryset is nonempty.\n                if combinator == \"union\" or (combinator == \"difference\" and parts):\n                    continue\n                raise\n        if not parts:\n            raise EmptyResultSet\n        combinator_sql = self.connection.ops.set_operators[combinator]\n        if all and combinator == \"union\":\n            combinator_sql += \" ALL\"\n        braces = \"{}\"\n        if not self.query.subquery and features.supports_slicing_ordering_in_compound:\n            braces = \"({})\"\n        sql_parts, args_parts = zip(\n            *((braces.format(sql), args) for sql, args in parts)\n        )\n        result = [\" {} \".format(combinator_sql).join(sql_parts)]\n        params = []\n        for part in args_parts:\n            params.extend(part)\n        return result, params\n\n    def get_qualify_sql(self):\n        where_parts = []\n        if self.where:\n            where_parts.append(self.where)\n        if self.having:\n            where_parts.append(self.having)\n        inner_query = self.query.clone()\n        inner_query.subquery = True\n        inner_query.where = inner_query.where.__class__(where_parts)\n        # Augment the inner query with any window function references that\n        # might have been masked via values() and alias(). If any masked\n        # aliases are added they'll be masked again to avoid fetching\n        # the data in the `if qual_aliases` branch below.\n        select = {\n            expr: alias for expr, _, alias in self.get_select(with_col_aliases=True)[0]\n        }\n        select_aliases = set(select.values())\n        qual_aliases = set()\n        replacements = {}\n\n        def collect_replacements(expressions):\n            while expressions:\n                expr = expressions.pop()\n                if expr in replacements:\n                    continue\n                elif select_alias := select.get(expr):\n                    replacements[expr] = select_alias\n                elif isinstance(expr, Lookup):\n                    expressions.extend(expr.get_source_expressions())\n                elif isinstance(expr, Ref):\n                    if expr.refs not in select_aliases:\n                        expressions.extend(expr.get_source_expressions())\n                else:\n                    num_qual_alias = len(qual_aliases)\n                    select_alias = f\"qual{num_qual_alias}\"\n                    qual_aliases.add(select_alias)\n                    inner_query.add_annotation(expr, select_alias)\n                    replacements[expr] = select_alias\n\n        collect_replacements(list(self.qualify.leaves()))\n        self.qualify = self.qualify.replace_expressions(\n            {expr: Ref(alias, expr) for expr, alias in replacements.items()}\n        )\n        order_by = []\n        for order_by_expr, *_ in self.get_order_by():\n            collect_replacements(order_by_expr.get_source_expressions())\n            order_by.append(\n                order_by_expr.replace_expressions(\n                    {expr: Ref(alias, expr) for expr, alias in replacements.items()}\n                )\n            )\n        inner_query_compiler = inner_query.get_compiler(\n            self.using, connection=self.connection, elide_empty=self.elide_empty\n        )\n        inner_sql, inner_params = inner_query_compiler.as_sql(\n            # The limits must be applied to the outer query to avoid pruning\n            # results too eagerly.\n            with_limits=False,\n            # Force unique aliasing of selected columns to avoid collisions\n            # and make rhs predicates referencing easier.\n            with_col_aliases=True,\n        )\n        qualify_sql, qualify_params = self.compile(self.qualify)\n        result = [\n            \"SELECT * FROM (\",\n            inner_sql,\n            \")\",\n            self.connection.ops.quote_name(\"qualify\"),\n            \"WHERE\",\n            qualify_sql,\n        ]\n        if qual_aliases:\n            # If some select aliases were unmasked for filtering purposes they\n            # must be masked back.\n            cols = [self.connection.ops.quote_name(alias) for alias in select.values()]\n            result = [\n                \"SELECT\",\n                \", \".join(cols),\n                \"FROM (\",\n                *result,\n                \")\",\n                self.connection.ops.quote_name(\"qualify_mask\"),\n            ]\n        params = list(inner_params) + qualify_params\n        # As the SQL spec is unclear on whether or not derived tables\n        # ordering must propagate it has to be explicitly repeated on the\n        # outer-most query to ensure it's preserved.\n        if order_by:\n            ordering_sqls = []\n            for ordering in order_by:\n                ordering_sql, ordering_params = self.compile(ordering)\n                ordering_sqls.append(ordering_sql)\n                params.extend(ordering_params)\n            result.extend([\"ORDER BY\", \", \".join(ordering_sqls)])\n        return result, params\n\n    def as_sql(self, with_limits=True, with_col_aliases=False):\n        \"\"\"\n        Create the SQL for this query. Return the SQL string and list of\n        parameters.\n\n        If 'with_limits' is False, any limit/offset information is not included\n        in the query.\n        \"\"\"\n        refcounts_before = self.query.alias_refcount.copy()\n        try:\n            combinator = self.query.combinator\n            extra_select, order_by, group_by = self.pre_sql_setup(\n                with_col_aliases=with_col_aliases or bool(combinator),\n            )\n            for_update_part = None\n            # Is a LIMIT/OFFSET clause needed?\n            with_limit_offset = with_limits and self.query.is_sliced\n            combinator = self.query.combinator\n            features = self.connection.features\n            if combinator:\n                if not getattr(features, \"supports_select_{}\".format(combinator)):\n                    raise NotSupportedError(\n                        \"{} is not supported on this database backend.\".format(\n                            combinator\n                        )\n                    )\n                result, params = self.get_combinator_sql(\n                    combinator, self.query.combinator_all\n                )\n            elif self.qualify:\n                result, params = self.get_qualify_sql()\n                order_by = None\n            else:\n                distinct_fields, distinct_params = self.get_distinct()\n                # This must come after 'select', 'ordering', and 'distinct'\n                # (see docstring of get_from_clause() for details).\n                from_, f_params = self.get_from_clause()\n                try:\n                    where, w_params = (\n                        self.compile(self.where) if self.where is not None else (\"\", [])\n                    )\n                except EmptyResultSet:\n                    if self.elide_empty:\n                        raise\n                    # Use a predicate that's always False.\n                    where, w_params = \"0 = 1\", []\n                except FullResultSet:\n                    where, w_params = \"\", []\n                try:\n                    having, h_params = (\n                        self.compile(self.having)\n                        if self.having is not None\n                        else (\"\", [])\n                    )\n                except FullResultSet:\n                    having, h_params = \"\", []\n                result = [\"SELECT\"]\n                params = []\n\n                if self.query.distinct:\n                    distinct_result, distinct_params = self.connection.ops.distinct_sql(\n                        distinct_fields,\n                        distinct_params,\n                    )\n                    result += distinct_result\n                    params += distinct_params\n\n                out_cols = []\n                for _, (s_sql, s_params), alias in self.select + extra_select:\n                    if alias:\n                        s_sql = \"%s AS %s\" % (\n                            s_sql,\n                            self.connection.ops.quote_name(alias),\n                        )\n                    params.extend(s_params)\n                    out_cols.append(s_sql)\n\n                result += [\", \".join(out_cols)]\n                if from_:\n                    result += [\"FROM\", *from_]\n                elif self.connection.features.bare_select_suffix:\n                    result += [self.connection.features.bare_select_suffix]\n                params.extend(f_params)\n\n                if self.query.select_for_update and features.has_select_for_update:\n                    if (\n                        self.connection.get_autocommit()\n                        # Don't raise an exception when database doesn't\n                        # support transactions, as it's a noop.\n                        and features.supports_transactions\n                    ):\n                        raise TransactionManagementError(\n                            \"select_for_update cannot be used outside of a transaction.\"\n                        )\n\n                    if (\n                        with_limit_offset\n                        and not features.supports_select_for_update_with_limit\n                    ):\n                        raise NotSupportedError(\n                            \"LIMIT/OFFSET is not supported with \"\n                            \"select_for_update on this database backend.\"\n                        )\n                    nowait = self.query.select_for_update_nowait\n                    skip_locked = self.query.select_for_update_skip_locked\n                    of = self.query.select_for_update_of\n                    no_key = self.query.select_for_no_key_update\n                    # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the\n                    # backend doesn't support it, raise NotSupportedError to\n                    # prevent a possible deadlock.\n                    if nowait and not features.has_select_for_update_nowait:\n                        raise NotSupportedError(\n                            \"NOWAIT is not supported on this database backend.\"\n                        )\n                    elif skip_locked and not features.has_select_for_update_skip_locked:\n                        raise NotSupportedError(\n                            \"SKIP LOCKED is not supported on this database backend.\"\n                        )\n                    elif of and not features.has_select_for_update_of:\n                        raise NotSupportedError(\n                            \"FOR UPDATE OF is not supported on this database backend.\"\n                        )\n                    elif no_key and not features.has_select_for_no_key_update:\n                        raise NotSupportedError(\n                            \"FOR NO KEY UPDATE is not supported on this \"\n                            \"database backend.\"\n                        )\n                    for_update_part = self.connection.ops.for_update_sql(\n                        nowait=nowait,\n                        skip_locked=skip_locked,\n                        of=self.get_select_for_update_of_arguments(),\n                        no_key=no_key,\n                    )\n\n                if for_update_part and features.for_update_after_from:\n                    result.append(for_update_part)\n\n                if where:\n                    result.append(\"WHERE %s\" % where)\n                    params.extend(w_params)\n\n                grouping = []\n                for g_sql, g_params in group_by:\n                    grouping.append(g_sql)\n                    params.extend(g_params)\n                if grouping:\n                    if distinct_fields:\n                        raise NotImplementedError(\n                            \"annotate() + distinct(fields) is not implemented.\"\n                        )\n                    order_by = order_by or self.connection.ops.force_no_ordering()\n                    result.append(\"GROUP BY %s\" % \", \".join(grouping))\n                    if self._meta_ordering:\n                        order_by = None\n                if having:\n                    result.append(\"HAVING %s\" % having)\n                    params.extend(h_params)\n\n            if self.query.explain_info:\n                result.insert(\n                    0,\n                    self.connection.ops.explain_query_prefix(\n                        self.query.explain_info.format,\n                        **self.query.explain_info.options,\n                    ),\n                )\n\n            if order_by:\n                ordering = []\n                for _, (o_sql, o_params, _) in order_by:\n                    ordering.append(o_sql)\n                    params.extend(o_params)\n                order_by_sql = \"ORDER BY %s\" % \", \".join(ordering)\n                if combinator and features.requires_compound_order_by_subquery:\n                    result = [\"SELECT * FROM (\", *result, \")\", order_by_sql]\n                else:\n                    result.append(order_by_sql)\n\n            if with_limit_offset:\n                result.append(\n                    self.connection.ops.limit_offset_sql(\n                        self.query.low_mark, self.query.high_mark\n                    )\n                )\n\n            if for_update_part and not features.for_update_after_from:\n                result.append(for_update_part)\n\n            if self.query.subquery and extra_select:\n                # If the query is used as a subquery, the extra selects would\n                # result in more columns than the left-hand side expression is\n                # expecting. This can happen when a subquery uses a combination\n                # of order_by() and distinct(), forcing the ordering expressions\n                # to be selected as well. Wrap the query in another subquery\n                # to exclude extraneous selects.\n                sub_selects = []\n                sub_params = []\n                for index, (select, _, alias) in enumerate(self.select, start=1):\n                    if alias:\n                        sub_selects.append(\n                            \"%s.%s\"\n                            % (\n                                self.connection.ops.quote_name(\"subquery\"),\n                                self.connection.ops.quote_name(alias),\n                            )\n                        )\n                    else:\n                        select_clone = select.relabeled_clone(\n                            {select.alias: \"subquery\"}\n                        )\n                        subselect, subparams = select_clone.as_sql(\n                            self, self.connection\n                        )\n                        sub_selects.append(subselect)\n                        sub_params.extend(subparams)\n                return \"SELECT %s FROM (%s) subquery\" % (\n                    \", \".join(sub_selects),\n                    \" \".join(result),\n                ), tuple(sub_params + params)\n\n            return \" \".join(result), tuple(params)\n        finally:\n            # Finally do cleanup - get rid of the joins we created above.\n            self.query.reset_refcounts(refcounts_before)\n\n    def get_default_columns(\n        self, select_mask, start_alias=None, opts=None, from_parent=None\n    ):\n        \"\"\"\n        Compute the default columns for selecting every field in the base\n        model. Will sometimes be called to pull in related models (e.g. via\n        select_related), in which case \"opts\" and \"start_alias\" will be given\n        to provide a starting point for the traversal.\n\n        Return a list of strings, quoted appropriately for use in SQL\n        directly, as well as a set of aliases used in the select statement (if\n        'as_pairs' is True, return a list of (alias, col_name) pairs instead\n        of strings as the first component and None as the second component).\n        \"\"\"\n        result = []\n        if opts is None:\n            if (opts := self.query.get_meta()) is None:\n                return result\n        start_alias = start_alias or self.query.get_initial_alias()\n        # The 'seen_models' is used to optimize checking the needed parent\n        # alias for a given field. This also includes None -> start_alias to\n        # be used by local fields.\n        seen_models = {None: start_alias}\n\n        for field in opts.concrete_fields:\n            model = field.model._meta.concrete_model\n            # A proxy model will have a different model and concrete_model. We\n            # will assign None if the field belongs to this model.\n            if model == opts.model:\n                model = None\n            if (\n                from_parent\n                and model is not None\n                and issubclass(\n                    from_parent._meta.concrete_model, model._meta.concrete_model\n                )\n            ):\n                # Avoid loading data for already loaded parents.\n                # We end up here in the case select_related() resolution\n                # proceeds from parent model to child model. In that case the\n                # parent model data is already present in the SELECT clause,\n                # and we want to avoid reloading the same data again.\n                continue\n            if select_mask and field not in select_mask:\n                continue\n            alias = self.query.join_parent_model(opts, model, start_alias, seen_models)\n            column = field.get_col(alias)\n            result.append(column)\n        return result\n\n    def get_distinct(self):\n        \"\"\"\n        Return a quoted list of fields to use in DISTINCT ON part of the query.\n\n        This method can alter the tables in the query, and thus it must be\n        called before get_from_clause().\n        \"\"\"\n        result = []\n        params = []\n        opts = self.query.get_meta()\n\n        for name in self.query.distinct_fields:\n            parts = name.split(LOOKUP_SEP)\n            _, targets, alias, joins, path, _, transform_function = self._setup_joins(\n                parts, opts, None\n            )\n            targets, alias, _ = self.query.trim_joins(targets, joins, path)\n            for target in targets:\n                if name in self.query.annotation_select:\n                    result.append(self.connection.ops.quote_name(name))\n                else:\n                    r, p = self.compile(transform_function(target, alias))\n                    result.append(r)\n                    params.append(p)\n        return result, params\n\n    def find_ordering_name(\n        self, name, opts, alias=None, default_order=\"ASC\", already_seen=None\n    ):\n        \"\"\"\n        Return the table alias (the name might be ambiguous, the alias will\n        not be) and column name for ordering by the given 'name' parameter.\n        The 'name' is of the form 'field1__field2__...__fieldN'.\n        \"\"\"\n        name, order = get_order_dir(name, default_order)\n        descending = order == \"DESC\"\n        pieces = name.split(LOOKUP_SEP)\n        (\n            field,\n            targets,\n            alias,\n            joins,\n            path,\n            opts,\n            transform_function,\n        ) = self._setup_joins(pieces, opts, alias)\n\n        # If we get to this point and the field is a relation to another model,\n        # append the default ordering for that model unless it is the pk\n        # shortcut or the attribute name of the field that is specified or\n        # there are transforms to process.\n        if (\n            field.is_relation\n            and opts.ordering\n            and getattr(field, \"attname\", None) != pieces[-1]\n            and name != \"pk\"\n            and not getattr(transform_function, \"has_transforms\", False)\n        ):\n            # Firstly, avoid infinite loops.\n            already_seen = already_seen or set()\n            join_tuple = tuple(\n                getattr(self.query.alias_map[j], \"join_cols\", None) for j in joins\n            )\n            if join_tuple in already_seen:\n                raise FieldError(\"Infinite loop caused by ordering.\")\n            already_seen.add(join_tuple)\n\n            results = []\n            for item in opts.ordering:\n                if hasattr(item, \"resolve_expression\") and not isinstance(\n                    item, OrderBy\n                ):\n                    item = item.desc() if descending else item.asc()\n                if isinstance(item, OrderBy):\n                    results.append(\n                        (item.prefix_references(f\"{name}{LOOKUP_SEP}\"), False)\n                    )\n                    continue\n                results.extend(\n                    (expr.prefix_references(f\"{name}{LOOKUP_SEP}\"), is_ref)\n                    for expr, is_ref in self.find_ordering_name(\n                        item, opts, alias, order, already_seen\n                    )\n                )\n            return results\n        targets, alias, _ = self.query.trim_joins(targets, joins, path)\n        return [\n            (OrderBy(transform_function(t, alias), descending=descending), False)\n            for t in targets\n        ]\n\n    def _setup_joins(self, pieces, opts, alias):\n        \"\"\"\n        Helper method for get_order_by() and get_distinct().\n\n        get_ordering() and get_distinct() must produce same target columns on\n        same input, as the prefixes of get_ordering() and get_distinct() must\n        match. Executing SQL where this is not true is an error.\n        \"\"\"\n        alias = alias or self.query.get_initial_alias()\n        field, targets, opts, joins, path, transform_function = self.query.setup_joins(\n            pieces, opts, alias\n        )\n        alias = joins[-1]\n        return field, targets, alias, joins, path, opts, transform_function\n\n    def get_from_clause(self):\n        \"\"\"\n        Return a list of strings that are joined together to go after the\n        \"FROM\" part of the query, as well as a list any extra parameters that\n        need to be included. Subclasses, can override this to create a\n        from-clause via a \"select\".\n\n        This should only be called after any SQL construction methods that\n        might change the tables that are needed. This means the select columns,\n        ordering, and distinct must be done first.\n        \"\"\"\n        result = []\n        params = []\n        for alias in tuple(self.query.alias_map):\n            if not self.query.alias_refcount[alias]:\n                continue\n            try:\n                from_clause = self.query.alias_map[alias]\n            except KeyError:\n                # Extra tables can end up in self.tables, but not in the\n                # alias_map if they aren't in a join. That's OK. We skip them.\n                continue\n            clause_sql, clause_params = self.compile(from_clause)\n            result.append(clause_sql)\n            params.extend(clause_params)\n        for t in self.query.extra_tables:\n            alias, _ = self.query.table_alias(t)\n            # Only add the alias if it's not already present (the table_alias()\n            # call increments the refcount, so an alias refcount of one means\n            # this is the only reference).\n            if (\n                alias not in self.query.alias_map\n                or self.query.alias_refcount[alias] == 1\n            ):\n                result.append(\", %s\" % self.quote_name_unless_alias(alias))\n        return result, params\n\n    def get_related_selections(\n        self,\n        select,\n        select_mask,\n        opts=None,\n        root_alias=None,\n        cur_depth=1,\n        requested=None,\n        restricted=None,\n    ):\n        \"\"\"\n        Fill in the information needed for a select_related query. The current\n        depth is measured as the number of connections away from the root model\n        (for example, cur_depth=1 means we are looking at models with direct\n        connections to the root model).\n        \"\"\"\n\n        def _get_field_choices():\n            direct_choices = (f.name for f in opts.fields if f.is_relation)\n            reverse_choices = (\n                f.field.related_query_name()\n                for f in opts.related_objects\n                if f.field.unique\n            )\n            return chain(\n                direct_choices, reverse_choices, self.query._filtered_relations\n            )\n\n        related_klass_infos = []\n        if not restricted and cur_depth > self.query.max_depth:\n            # We've recursed far enough; bail out.\n            return related_klass_infos\n\n        if not opts:\n            opts = self.query.get_meta()\n            root_alias = self.query.get_initial_alias()\n\n        # Setup for the case when only particular related fields should be\n        # included in the related selection.\n        fields_found = set()\n        if requested is None:\n            restricted = isinstance(self.query.select_related, dict)\n            if restricted:\n                requested = self.query.select_related\n\n        def get_related_klass_infos(klass_info, related_klass_infos):\n            klass_info[\"related_klass_infos\"] = related_klass_infos\n\n        for f in opts.fields:\n            fields_found.add(f.name)\n\n            if restricted:\n                next = requested.get(f.name, {})\n                if not f.is_relation:\n                    # If a non-related field is used like a relation,\n                    # or if a single non-relational field is given.\n                    if next or f.name in requested:\n                        raise FieldError(\n                            \"Non-relational field given in select_related: '%s'. \"\n                            \"Choices are: %s\"\n                            % (\n                                f.name,\n                                \", \".join(_get_field_choices()) or \"(none)\",\n                            )\n                        )\n            else:\n                next = False\n\n            if not select_related_descend(f, restricted, requested, select_mask):\n                continue\n            related_select_mask = select_mask.get(f) or {}\n            klass_info = {\n                \"model\": f.remote_field.model,\n                \"field\": f,\n                \"reverse\": False,\n                \"local_setter\": f.set_cached_value,\n                \"remote_setter\": f.remote_field.set_cached_value\n                if f.unique\n                else lambda x, y: None,\n                \"from_parent\": False,\n            }\n            related_klass_infos.append(klass_info)\n            select_fields = []\n            _, _, _, joins, _, _ = self.query.setup_joins([f.name], opts, root_alias)\n            alias = joins[-1]\n            columns = self.get_default_columns(\n                related_select_mask, start_alias=alias, opts=f.remote_field.model._meta\n            )\n            for col in columns:\n                select_fields.append(len(select))\n                select.append((col, None))\n            klass_info[\"select_fields\"] = select_fields\n            next_klass_infos = self.get_related_selections(\n                select,\n                related_select_mask,\n                f.remote_field.model._meta,\n                alias,\n                cur_depth + 1,\n                next,\n                restricted,\n            )\n            get_related_klass_infos(klass_info, next_klass_infos)\n\n        if restricted:\n            related_fields = [\n                (o.field, o.related_model)\n                for o in opts.related_objects\n                if o.field.unique and not o.many_to_many\n            ]\n            for related_field, model in related_fields:\n                related_select_mask = select_mask.get(related_field) or {}\n                if not select_related_descend(\n                    related_field,\n                    restricted,\n                    requested,\n                    related_select_mask,\n                    reverse=True,\n                ):\n                    continue\n\n                related_field_name = related_field.related_query_name()\n                fields_found.add(related_field_name)\n\n                join_info = self.query.setup_joins(\n                    [related_field_name], opts, root_alias\n                )\n                alias = join_info.joins[-1]\n                from_parent = issubclass(model, opts.model) and model is not opts.model\n                klass_info = {\n                    \"model\": model,\n                    \"field\": related_field,\n                    \"reverse\": True,\n                    \"local_setter\": related_field.remote_field.set_cached_value,\n                    \"remote_setter\": related_field.set_cached_value,\n                    \"from_parent\": from_parent,\n                }\n                related_klass_infos.append(klass_info)\n                select_fields = []\n                columns = self.get_default_columns(\n                    related_select_mask,\n                    start_alias=alias,\n                    opts=model._meta,\n                    from_parent=opts.model,\n                )\n                for col in columns:\n                    select_fields.append(len(select))\n                    select.append((col, None))\n                klass_info[\"select_fields\"] = select_fields\n                next = requested.get(related_field.related_query_name(), {})\n                next_klass_infos = self.get_related_selections(\n                    select,\n                    related_select_mask,\n                    model._meta,\n                    alias,\n                    cur_depth + 1,\n                    next,\n                    restricted,\n                )\n                get_related_klass_infos(klass_info, next_klass_infos)\n\n            def local_setter(final_field, obj, from_obj):\n                # Set a reverse fk object when relation is non-empty.\n                if from_obj:\n                    final_field.remote_field.set_cached_value(from_obj, obj)\n\n            def local_setter_noop(obj, from_obj):\n                pass\n\n            def remote_setter(name, obj, from_obj):\n                setattr(from_obj, name, obj)\n\n            for name in list(requested):\n                # Filtered relations work only on the topmost level.\n                if cur_depth > 1:\n                    break\n                if name in self.query._filtered_relations:\n                    fields_found.add(name)\n                    final_field, _, join_opts, joins, _, _ = self.query.setup_joins(\n                        [name], opts, root_alias\n                    )\n                    model = join_opts.model\n                    alias = joins[-1]\n                    from_parent = (\n                        issubclass(model, opts.model) and model is not opts.model\n                    )\n                    klass_info = {\n                        \"model\": model,\n                        \"field\": final_field,\n                        \"reverse\": True,\n                        \"local_setter\": (\n                            partial(local_setter, final_field)\n                            if len(joins) <= 2\n                            else local_setter_noop\n                        ),\n                        \"remote_setter\": partial(remote_setter, name),\n                        \"from_parent\": from_parent,\n                    }\n                    related_klass_infos.append(klass_info)\n                    select_fields = []\n                    field_select_mask = select_mask.get((name, final_field)) or {}\n                    columns = self.get_default_columns(\n                        field_select_mask,\n                        start_alias=alias,\n                        opts=model._meta,\n                        from_parent=opts.model,\n                    )\n                    for col in columns:\n                        select_fields.append(len(select))\n                        select.append((col, None))\n                    klass_info[\"select_fields\"] = select_fields\n                    next_requested = requested.get(name, {})\n                    next_klass_infos = self.get_related_selections(\n                        select,\n                        field_select_mask,\n                        opts=model._meta,\n                        root_alias=alias,\n                        cur_depth=cur_depth + 1,\n                        requested=next_requested,\n                        restricted=restricted,\n                    )\n                    get_related_klass_infos(klass_info, next_klass_infos)\n            fields_not_found = set(requested).difference(fields_found)\n            if fields_not_found:\n                invalid_fields = (\"'%s'\" % s for s in fields_not_found)\n                raise FieldError(\n                    \"Invalid field name(s) given in select_related: %s. \"\n                    \"Choices are: %s\"\n                    % (\n                        \", \".join(invalid_fields),\n                        \", \".join(_get_field_choices()) or \"(none)\",\n                    )\n                )\n        return related_klass_infos\n\n    def get_select_for_update_of_arguments(self):\n        \"\"\"\n        Return a quoted list of arguments for the SELECT FOR UPDATE OF part of\n        the query.\n        \"\"\"\n\n        def _get_parent_klass_info(klass_info):\n            concrete_model = klass_info[\"model\"]._meta.concrete_model\n            for parent_model, parent_link in concrete_model._meta.parents.items():\n                parent_list = parent_model._meta.get_parent_list()\n                yield {\n                    \"model\": parent_model,\n                    \"field\": parent_link,\n                    \"reverse\": False,\n                    \"select_fields\": [\n                        select_index\n                        for select_index in klass_info[\"select_fields\"]\n                        # Selected columns from a model or its parents.\n                        if (\n                            self.select[select_index][0].target.model == parent_model\n                            or self.select[select_index][0].target.model in parent_list\n                        )\n                    ],\n                }\n\n        def _get_first_selected_col_from_model(klass_info):\n            \"\"\"\n            Find the first selected column from a model. If it doesn't exist,\n            don't lock a model.\n\n            select_fields is filled recursively, so it also contains fields\n            from the parent models.\n            \"\"\"\n            concrete_model = klass_info[\"model\"]._meta.concrete_model\n            for select_index in klass_info[\"select_fields\"]:\n                if self.select[select_index][0].target.model == concrete_model:\n                    return self.select[select_index][0]\n\n        def _get_field_choices():\n            \"\"\"Yield all allowed field paths in breadth-first search order.\"\"\"\n            queue = collections.deque([(None, self.klass_info)])\n            while queue:\n                parent_path, klass_info = queue.popleft()\n                if parent_path is None:\n                    path = []\n                    yield \"self\"\n                else:\n                    field = klass_info[\"field\"]\n                    if klass_info[\"reverse\"]:\n                        field = field.remote_field\n                    path = parent_path + [field.name]\n                    yield LOOKUP_SEP.join(path)\n                queue.extend(\n                    (path, klass_info)\n                    for klass_info in _get_parent_klass_info(klass_info)\n                )\n                queue.extend(\n                    (path, klass_info)\n                    for klass_info in klass_info.get(\"related_klass_infos\", [])\n                )\n\n        if not self.klass_info:\n            return []\n        result = []\n        invalid_names = []\n        for name in self.query.select_for_update_of:\n            klass_info = self.klass_info\n            if name == \"self\":\n                col = _get_first_selected_col_from_model(klass_info)\n            else:\n                for part in name.split(LOOKUP_SEP):\n                    klass_infos = (\n                        *klass_info.get(\"related_klass_infos\", []),\n                        *_get_parent_klass_info(klass_info),\n                    )\n                    for related_klass_info in klass_infos:\n                        field = related_klass_info[\"field\"]\n                        if related_klass_info[\"reverse\"]:\n                            field = field.remote_field\n                        if field.name == part:\n                            klass_info = related_klass_info\n                            break\n                    else:\n                        klass_info = None\n                        break\n                if klass_info is None:\n                    invalid_names.append(name)\n                    continue\n                col = _get_first_selected_col_from_model(klass_info)\n            if col is not None:\n                if self.connection.features.select_for_update_of_column:\n                    result.append(self.compile(col)[0])\n                else:\n                    result.append(self.quote_name_unless_alias(col.alias))\n        if invalid_names:\n            raise FieldError(\n                \"Invalid field name(s) given in select_for_update(of=(...)): %s. \"\n                \"Only relational fields followed in the query are allowed. \"\n                \"Choices are: %s.\"\n                % (\n                    \", \".join(invalid_names),\n                    \", \".join(_get_field_choices()),\n                )\n            )\n        return result\n\n    def get_converters(self, expressions):\n        converters = {}\n        for i, expression in enumerate(expressions):\n            if expression:\n                backend_converters = self.connection.ops.get_db_converters(expression)\n                field_converters = expression.get_db_converters(self.connection)\n                if backend_converters or field_converters:\n                    converters[i] = (backend_converters + field_converters, expression)\n        return converters\n\n    def apply_converters(self, rows, converters):\n        connection = self.connection\n        converters = list(converters.items())\n        for row in map(list, rows):\n            for pos, (convs, expression) in converters:\n                value = row[pos]\n                for converter in convs:\n                    value = converter(value, expression, connection)\n                row[pos] = value\n            yield row\n\n    def results_iter(\n        self,\n        results=None,\n        tuple_expected=False,\n        chunked_fetch=False,\n        chunk_size=GET_ITERATOR_CHUNK_SIZE,\n    ):\n        \"\"\"Return an iterator over the results from executing this query.\"\"\"\n        if results is None:\n            results = self.execute_sql(\n                MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size\n            )\n        fields = [s[0] for s in self.select[0 : self.col_count]]\n        converters = self.get_converters(fields)\n        rows = chain.from_iterable(results)\n        if converters:\n            rows = self.apply_converters(rows, converters)\n            if tuple_expected:\n                rows = map(tuple, rows)\n        return rows\n\n    def has_results(self):\n        \"\"\"\n        Backends (e.g. NoSQL) can override this in order to use optimized\n        versions of \"query has any results.\"\n        \"\"\"\n        return bool(self.execute_sql(SINGLE))\n\n    def execute_sql(\n        self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE\n    ):\n        \"\"\"\n        Run the query against the database and return the result(s). The\n        return value is a single data item if result_type is SINGLE, or an\n        iterator over the results if the result_type is MULTI.\n\n        result_type is either MULTI (use fetchmany() to retrieve all rows),\n        SINGLE (only retrieve a single row), or None. In this last case, the\n        cursor is returned if any query is executed, since it's used by\n        subclasses such as InsertQuery). It's possible, however, that no query\n        is needed, as the filters describe an empty set. In that case, None is\n        returned, to avoid any unnecessary database interaction.\n        \"\"\"\n        result_type = result_type or NO_RESULTS\n        try:\n            sql, params = self.as_sql()\n            if not sql:\n                raise EmptyResultSet\n        except EmptyResultSet:\n            if result_type == MULTI:\n                return iter([])\n            else:\n                return\n        if chunked_fetch:\n            cursor = self.connection.chunked_cursor()\n        else:\n            cursor = self.connection.cursor()\n        try:\n            cursor.execute(sql, params)\n        except Exception:\n            # Might fail for server-side cursors (e.g. connection closed)\n            cursor.close()\n            raise\n\n        if result_type == CURSOR:\n            # Give the caller the cursor to process and close.\n            return cursor\n        if result_type == SINGLE:\n            try:\n                val = cursor.fetchone()\n                if val:\n                    return val[0 : self.col_count]\n                return val\n            finally:\n                # done with the cursor\n                cursor.close()\n        if result_type == NO_RESULTS:\n            cursor.close()\n            return\n\n        result = cursor_iter(\n            cursor,\n            self.connection.features.empty_fetchmany_value,\n            self.col_count if self.has_extra_select else None,\n            chunk_size,\n        )\n        if not chunked_fetch or not self.connection.features.can_use_chunked_reads:\n            # If we are using non-chunked reads, we return the same data\n            # structure as normally, but ensure it is all read into memory\n            # before going any further. Use chunked_fetch if requested,\n            # unless the database doesn't support it.\n            return list(result)\n        return result\n\n    def as_subquery_condition(self, alias, columns, compiler):\n        qn = compiler.quote_name_unless_alias\n        qn2 = self.connection.ops.quote_name\n\n        for index, select_col in enumerate(self.query.select):\n            lhs_sql, lhs_params = self.compile(select_col)\n            rhs = \"%s.%s\" % (qn(alias), qn2(columns[index]))\n            self.query.where.add(RawSQL(\"%s = %s\" % (lhs_sql, rhs), lhs_params), AND)\n\n        sql, params = self.as_sql()\n        return \"EXISTS (%s)\" % sql, params\n\n    def explain_query(self):\n        result = list(self.execute_sql())\n        # Some backends return 1 item tuples with strings, and others return\n        # tuples with integers and strings. Flatten them out into strings.\n        format_ = self.query.explain_info.format\n        output_formatter = json.dumps if format_ and format_.lower() == \"json\" else str\n        for row in result[0]:\n            if not isinstance(row, str):\n                yield \" \".join(output_formatter(c) for c in row)\n            else:\n                yield row\n\n\nclass SQLInsertCompiler(SQLCompiler):\n    returning_fields = None\n    returning_params = ()\n\n    def field_as_sql(self, field, val):\n        \"\"\"\n        Take a field and a value intended to be saved on that field, and\n        return placeholder SQL and accompanying params. Check for raw values,\n        expressions, and fields with get_placeholder() defined in that order.\n\n        When field is None, consider the value raw and use it as the\n        placeholder, with no corresponding parameters returned.\n        \"\"\"\n        if field is None:\n            # A field value of None means the value is raw.\n            sql, params = val, []\n        elif hasattr(val, \"as_sql\"):\n            # This is an expression, let's compile it.\n            sql, params = self.compile(val)\n        elif hasattr(field, \"get_placeholder\"):\n            # Some fields (e.g. geo fields) need special munging before\n            # they can be inserted.\n            sql, params = field.get_placeholder(val, self, self.connection), [val]\n        else:\n            # Return the common case for the placeholder\n            sql, params = \"%s\", [val]\n\n        # The following hook is only used by Oracle Spatial, which sometimes\n        # needs to yield 'NULL' and [] as its placeholder and params instead\n        # of '%s' and [None]. The 'NULL' placeholder is produced earlier by\n        # OracleOperations.get_geom_placeholder(). The following line removes\n        # the corresponding None parameter. See ticket #10888.\n        params = self.connection.ops.modify_insert_params(sql, params)\n\n        return sql, params\n\n    def prepare_value(self, field, value):\n        \"\"\"\n        Prepare a value to be used in a query by resolving it if it is an\n        expression and otherwise calling the field's get_db_prep_save().\n        \"\"\"\n        if hasattr(value, \"resolve_expression\"):\n            value = value.resolve_expression(\n                self.query, allow_joins=False, for_save=True\n            )\n            # Don't allow values containing Col expressions. They refer to\n            # existing columns on a row, but in the case of insert the row\n            # doesn't exist yet.\n            if value.contains_column_references:\n                raise ValueError(\n                    'Failed to insert expression \"%s\" on %s. F() expressions '\n                    \"can only be used to update, not to insert.\" % (value, field)\n                )\n            if value.contains_aggregate:\n                raise FieldError(\n                    \"Aggregate functions are not allowed in this query \"\n                    \"(%s=%r).\" % (field.name, value)\n                )\n            if value.contains_over_clause:\n                raise FieldError(\n                    \"Window expressions are not allowed in this query (%s=%r).\"\n                    % (field.name, value)\n                )\n        return field.get_db_prep_save(value, connection=self.connection)\n\n    def pre_save_val(self, field, obj):\n        \"\"\"\n        Get the given field's value off the given obj. pre_save() is used for\n        things like auto_now on DateTimeField. Skip it if this is a raw query.\n        \"\"\"\n        if self.query.raw:\n            return getattr(obj, field.attname)\n        return field.pre_save(obj, add=True)\n\n    def assemble_as_sql(self, fields, value_rows):\n        \"\"\"\n        Take a sequence of N fields and a sequence of M rows of values, and\n        generate placeholder SQL and parameters for each field and value.\n        Return a pair containing:\n         * a sequence of M rows of N SQL placeholder strings, and\n         * a sequence of M rows of corresponding parameter values.\n\n        Each placeholder string may contain any number of '%s' interpolation\n        strings, and each parameter row will contain exactly as many params\n        as the total number of '%s's in the corresponding placeholder row.\n        \"\"\"\n        if not value_rows:\n            return [], []\n\n        # list of (sql, [params]) tuples for each object to be saved\n        # Shape: [n_objs][n_fields][2]\n        rows_of_fields_as_sql = (\n            (self.field_as_sql(field, v) for field, v in zip(fields, row))\n            for row in value_rows\n        )\n\n        # tuple like ([sqls], [[params]s]) for each object to be saved\n        # Shape: [n_objs][2][n_fields]\n        sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)\n\n        # Extract separate lists for placeholders and params.\n        # Each of these has shape [n_objs][n_fields]\n        placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)\n\n        # Params for each field are still lists, and need to be flattened.\n        param_rows = [[p for ps in row for p in ps] for row in param_rows]\n\n        return placeholder_rows, param_rows\n\n    def as_sql(self):\n        # We don't need quote_name_unless_alias() here, since these are all\n        # going to be column names (so we can avoid the extra overhead).\n        qn = self.connection.ops.quote_name\n        opts = self.query.get_meta()\n        insert_statement = self.connection.ops.insert_statement(\n            on_conflict=self.query.on_conflict,\n        )\n        result = [\"%s %s\" % (insert_statement, qn(opts.db_table))]\n        fields = self.query.fields or [opts.pk]\n        result.append(\"(%s)\" % \", \".join(qn(f.column) for f in fields))\n\n        if self.query.fields:\n            value_rows = [\n                [\n                    self.prepare_value(field, self.pre_save_val(field, obj))\n                    for field in fields\n                ]\n                for obj in self.query.objs\n            ]\n        else:\n            # An empty object.\n            value_rows = [\n                [self.connection.ops.pk_default_value()] for _ in self.query.objs\n            ]\n            fields = [None]\n\n        # Currently the backends just accept values when generating bulk\n        # queries and generate their own placeholders. Doing that isn't\n        # necessary and it should be possible to use placeholders and\n        # expressions in bulk inserts too.\n        can_bulk = (\n            not self.returning_fields and self.connection.features.has_bulk_insert\n        )\n\n        placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)\n\n        on_conflict_suffix_sql = self.connection.ops.on_conflict_suffix_sql(\n            fields,\n            self.query.on_conflict,\n            (f.column for f in self.query.update_fields),\n            (f.column for f in self.query.unique_fields),\n        )\n        if (\n            self.returning_fields\n            and self.connection.features.can_return_columns_from_insert\n        ):\n            if self.connection.features.can_return_rows_from_bulk_insert:\n                result.append(\n                    self.connection.ops.bulk_insert_sql(fields, placeholder_rows)\n                )\n                params = param_rows\n            else:\n                result.append(\"VALUES (%s)\" % \", \".join(placeholder_rows[0]))\n                params = [param_rows[0]]\n            if on_conflict_suffix_sql:\n                result.append(on_conflict_suffix_sql)\n            # Skip empty r_sql to allow subclasses to customize behavior for\n            # 3rd party backends. Refs #19096.\n            r_sql, self.returning_params = self.connection.ops.return_insert_columns(\n                self.returning_fields\n            )\n            if r_sql:\n                result.append(r_sql)\n                params += [self.returning_params]\n            return [(\" \".join(result), tuple(chain.from_iterable(params)))]\n\n        if can_bulk:\n            result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n            if on_conflict_suffix_sql:\n                result.append(on_conflict_suffix_sql)\n            return [(\" \".join(result), tuple(p for ps in param_rows for p in ps))]\n        else:\n            if on_conflict_suffix_sql:\n                result.append(on_conflict_suffix_sql)\n            return [\n                (\" \".join(result + [\"VALUES (%s)\" % \", \".join(p)]), vals)\n                for p, vals in zip(placeholder_rows, param_rows)\n            ]\n\n    def execute_sql(self, returning_fields=None):\n        assert not (\n            returning_fields\n            and len(self.query.objs) != 1\n            and not self.connection.features.can_return_rows_from_bulk_insert\n        )\n        opts = self.query.get_meta()\n        self.returning_fields = returning_fields\n        with self.connection.cursor() as cursor:\n            for sql, params in self.as_sql():\n                cursor.execute(sql, params)\n            if not self.returning_fields:\n                return []\n            if (\n                self.connection.features.can_return_rows_from_bulk_insert\n                and len(self.query.objs) > 1\n            ):\n                rows = self.connection.ops.fetch_returned_insert_rows(cursor)\n            elif self.connection.features.can_return_columns_from_insert:\n                assert len(self.query.objs) == 1\n                rows = [\n                    self.connection.ops.fetch_returned_insert_columns(\n                        cursor,\n                        self.returning_params,\n                    )\n                ]\n            else:\n                rows = [\n                    (\n                        self.connection.ops.last_insert_id(\n                            cursor,\n                            opts.db_table,\n                            opts.pk.column,\n                        ),\n                    )\n                ]\n        cols = [field.get_col(opts.db_table) for field in self.returning_fields]\n        converters = self.get_converters(cols)\n        if converters:\n            rows = list(self.apply_converters(rows, converters))\n        return rows\n\n\nclass SQLDeleteCompiler(SQLCompiler):\n    @cached_property\n    def single_alias(self):\n        # Ensure base table is in aliases.\n        self.query.get_initial_alias()\n        return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n\n    @classmethod\n    def _expr_refs_base_model(cls, expr, base_model):\n        if isinstance(expr, Query):\n            return expr.model == base_model\n        if not hasattr(expr, \"get_source_expressions\"):\n            return False\n        return any(\n            cls._expr_refs_base_model(source_expr, base_model)\n            for source_expr in expr.get_source_expressions()\n        )\n\n    @cached_property\n    def contains_self_reference_subquery(self):\n        return any(\n            self._expr_refs_base_model(expr, self.query.model)\n            for expr in chain(\n                self.query.annotations.values(), self.query.where.children\n            )\n        )\n\n    def _as_sql(self, query):\n        delete = \"DELETE FROM %s\" % self.quote_name_unless_alias(query.base_table)\n        try:\n            where, params = self.compile(query.where)\n        except FullResultSet:\n            return delete, ()\n        return f\"{delete} WHERE {where}\", tuple(params)\n\n    def as_sql(self):\n        \"\"\"\n        Create the SQL for this query. Return the SQL string and list of\n        parameters.\n        \"\"\"\n        if self.single_alias and (\n            self.connection.features.delete_can_self_reference_subquery\n            or not self.contains_self_reference_subquery\n        ):\n            return self._as_sql(self.query)\n        innerq = self.query.clone()\n        innerq.__class__ = Query\n        innerq.clear_select_clause()\n        pk = self.query.model._meta.pk\n        innerq.select = [pk.get_col(self.query.get_initial_alias())]\n        outerq = Query(self.query.model)\n        if not self.connection.features.update_can_self_select:\n            # Force the materialization of the inner query to allow reference\n            # to the target table on MySQL.\n            sql, params = innerq.get_compiler(connection=self.connection).as_sql()\n            innerq = RawSQL(\"SELECT * FROM (%s) subquery\" % sql, params)\n        outerq.add_filter(\"pk__in\", innerq)\n        return self._as_sql(outerq)\n\n\nclass SQLUpdateCompiler(SQLCompiler):\n    def as_sql(self):\n        \"\"\"\n        Create the SQL for this query. Return the SQL string and list of\n        parameters.\n        \"\"\"\n        self.pre_sql_setup()\n        if not self.query.values:\n            return \"\", ()\n        qn = self.quote_name_unless_alias\n        values, update_params = [], []\n        for field, model, val in self.query.values:\n            if hasattr(val, \"resolve_expression\"):\n                val = val.resolve_expression(\n                    self.query, allow_joins=False, for_save=True\n                )\n                if val.contains_aggregate:\n                    raise FieldError(\n                        \"Aggregate functions are not allowed in this query \"\n                        \"(%s=%r).\" % (field.name, val)\n                    )\n                if val.contains_over_clause:\n                    raise FieldError(\n                        \"Window expressions are not allowed in this query \"\n                        \"(%s=%r).\" % (field.name, val)\n                    )\n            elif hasattr(val, \"prepare_database_save\"):\n                if field.remote_field:\n                    val = val.prepare_database_save(field)\n                else:\n                    raise TypeError(\n                        \"Tried to update field %s with a model instance, %r. \"\n                        \"Use a value compatible with %s.\"\n                        % (field, val, field.__class__.__name__)\n                    )\n            val = field.get_db_prep_save(val, connection=self.connection)\n\n            # Getting the placeholder for the field.\n            if hasattr(field, \"get_placeholder\"):\n                placeholder = field.get_placeholder(val, self, self.connection)\n            else:\n                placeholder = \"%s\"\n            name = field.column\n            if hasattr(val, \"as_sql\"):\n                sql, params = self.compile(val)\n                values.append(\"%s = %s\" % (qn(name), placeholder % sql))\n                update_params.extend(params)\n            elif val is not None:\n                values.append(\"%s = %s\" % (qn(name), placeholder))\n                update_params.append(val)\n            else:\n                values.append(\"%s = NULL\" % qn(name))\n        table = self.query.base_table\n        result = [\n            \"UPDATE %s SET\" % qn(table),\n            \", \".join(values),\n        ]\n        try:\n            where, params = self.compile(self.query.where)\n        except FullResultSet:\n            params = []\n        else:\n            result.append(\"WHERE %s\" % where)\n        return \" \".join(result), tuple(update_params + params)\n\n    def execute_sql(self, result_type):\n        \"\"\"\n        Execute the specified update. Return the number of rows affected by\n        the primary update query. The \"primary update query\" is the first\n        non-empty query that is executed. Row counts for any subsequent,\n        related queries are not available.\n        \"\"\"\n        cursor = super().execute_sql(result_type)\n        try:\n            rows = cursor.rowcount if cursor else 0\n            is_empty = cursor is None\n        finally:\n            if cursor:\n                cursor.close()\n        for query in self.query.get_related_updates():\n            aux_rows = query.get_compiler(self.using).execute_sql(result_type)\n            if is_empty and aux_rows:\n                rows = aux_rows\n                is_empty = False\n        return rows\n\n    def pre_sql_setup(self):\n        \"\"\"\n        If the update depends on results from other tables, munge the \"where\"\n        conditions to match the format required for (portable) SQL updates.\n\n        If multiple updates are required, pull out the id values to update at\n        this point so that they don't change as a result of the progressive\n        updates.\n        \"\"\"\n        refcounts_before = self.query.alias_refcount.copy()\n        # Ensure base table is in the query\n        self.query.get_initial_alias()\n        count = self.query.count_active_tables()\n        if not self.query.related_updates and count == 1:\n            return\n        query = self.query.chain(klass=Query)\n        query.select_related = False\n        query.clear_ordering(force=True)\n        query.extra = {}\n        query.select = []\n        meta = query.get_meta()\n        fields = [meta.pk.name]\n        related_ids_index = []\n        for related in self.query.related_updates:\n            if all(\n                path.join_field.primary_key for path in meta.get_path_to_parent(related)\n            ):\n                # If a primary key chain exists to the targeted related update,\n                # then the meta.pk value can be used for it.\n                related_ids_index.append((related, 0))\n            else:\n                # This branch will only be reached when updating a field of an\n                # ancestor that is not part of the primary key chain of a MTI\n                # tree.\n                related_ids_index.append((related, len(fields)))\n                fields.append(related._meta.pk.name)\n        query.add_fields(fields)\n        super().pre_sql_setup()\n\n        must_pre_select = (\n            count > 1 and not self.connection.features.update_can_self_select\n        )\n\n        # Now we adjust the current query: reset the where clause and get rid\n        # of all the tables we don't need (since they're in the sub-select).\n        self.query.clear_where()\n        if self.query.related_updates or must_pre_select:\n            # Either we're using the idents in multiple update queries (so\n            # don't want them to change), or the db backend doesn't support\n            # selecting from the updating table (e.g. MySQL).\n            idents = []\n            related_ids = collections.defaultdict(list)\n            for rows in query.get_compiler(self.using).execute_sql(MULTI):\n                idents.extend(r[0] for r in rows)\n                for parent, index in related_ids_index:\n                    related_ids[parent].extend(r[index] for r in rows)\n            self.query.add_filter(\"pk__in\", idents)\n            self.query.related_ids = related_ids\n        else:\n            # The fast path. Filters and updates in one query.\n            self.query.add_filter(\"pk__in\", query)\n        self.query.reset_refcounts(refcounts_before)\n\n\nclass SQLAggregateCompiler(SQLCompiler):\n    def as_sql(self):\n        \"\"\"\n        Create the SQL for this query. Return the SQL string and list of\n        parameters.\n        \"\"\"\n        sql, params = [], []\n        for annotation in self.query.annotation_select.values():\n            ann_sql, ann_params = self.compile(annotation)\n            ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)\n            sql.append(ann_sql)\n            params.extend(ann_params)\n        self.col_count = len(self.query.annotation_select)\n        sql = \", \".join(sql)\n        params = tuple(params)\n\n        inner_query_sql, inner_query_params = self.query.inner_query.get_compiler(\n            self.using,\n            elide_empty=self.elide_empty,\n        ).as_sql(with_col_aliases=True)\n        sql = \"SELECT %s FROM (%s) subquery\" % (sql, inner_query_sql)\n        params += inner_query_params\n        return sql, params\n\n\ndef cursor_iter(cursor, sentinel, col_count, itersize):\n    \"\"\"\n    Yield blocks of rows from a cursor and ensure the cursor is closed when\n    done.\n    \"\"\"\n    try:\n        for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):\n            yield rows if col_count is None else [r[:col_count] for r in rows]\n    finally:\n        cursor.close()\n</file>\n<file path=\"/testbed/tests/select_related/tests.py\">\nfrom django.core.exceptions import FieldError\nfrom django.test import SimpleTestCase, TestCase\n\nfrom .models import (\n    Bookmark,\n    Domain,\n    Family,\n    Genus,\n    HybridSpecies,\n    Kingdom,\n    Klass,\n    Order,\n    Phylum,\n    Pizza,\n    Species,\n    TaggedItem,\n)\n\n\nclass SelectRelatedTests(TestCase):\n    @classmethod\n    def create_tree(cls, stringtree):\n        \"\"\"\n        Helper to create a complete tree.\n        \"\"\"\n        names = stringtree.split()\n        models = [Domain, Kingdom, Phylum, Klass, Order, Family, Genus, Species]\n        assert len(names) == len(models), (names, models)\n\n        parent = None\n        for name, model in zip(names, models):\n            try:\n                obj = model.objects.get(name=name)\n            except model.DoesNotExist:\n                obj = model(name=name)\n            if parent:\n                setattr(obj, parent.__class__.__name__.lower(), parent)\n            obj.save()\n            parent = obj\n\n    @classmethod\n    def setUpTestData(cls):\n        cls.create_tree(\n            \"Eukaryota Animalia Anthropoda Insecta Diptera Drosophilidae Drosophila \"\n            \"melanogaster\"\n        )\n        cls.create_tree(\n            \"Eukaryota Animalia Chordata Mammalia Primates Hominidae Homo sapiens\"\n        )\n        cls.create_tree(\n            \"Eukaryota Plantae Magnoliophyta Magnoliopsida Fabales Fabaceae Pisum \"\n            \"sativum\"\n        )\n        cls.create_tree(\n            \"Eukaryota Fungi Basidiomycota Homobasidiomycatae Agaricales Amanitacae \"\n            \"Amanita muscaria\"\n        )\n\n    def test_access_fks_without_select_related(self):\n        \"\"\"\n        Normally, accessing FKs doesn't fill in related objects\n        \"\"\"\n        with self.assertNumQueries(8):\n            fly = Species.objects.get(name=\"melanogaster\")\n            domain = fly.genus.family.order.klass.phylum.kingdom.domain\n            self.assertEqual(domain.name, \"Eukaryota\")\n\n    def test_access_fks_with_select_related(self):\n        \"\"\"\n        A select_related() call will fill in those related objects without any\n        extra queries\n        \"\"\"\n        with self.assertNumQueries(1):\n            person = Species.objects.select_related(\n                \"genus__family__order__klass__phylum__kingdom__domain\"\n            ).get(name=\"sapiens\")\n            domain = person.genus.family.order.klass.phylum.kingdom.domain\n            self.assertEqual(domain.name, \"Eukaryota\")\n\n    def test_list_without_select_related(self):\n        with self.assertNumQueries(9):\n            world = Species.objects.all()\n            families = [o.genus.family.name for o in world]\n            self.assertEqual(\n                sorted(families),\n                [\n                    \"Amanitacae\",\n                    \"Drosophilidae\",\n                    \"Fabaceae\",\n                    \"Hominidae\",\n                ],\n            )\n\n    def test_list_with_select_related(self):\n        \"\"\"select_related() applies to entire lists, not just items.\"\"\"\n        with self.assertNumQueries(1):\n            world = Species.objects.select_related()\n            families = [o.genus.family.name for o in world]\n            self.assertEqual(\n                sorted(families),\n                [\n                    \"Amanitacae\",\n                    \"Drosophilidae\",\n                    \"Fabaceae\",\n                    \"Hominidae\",\n                ],\n            )\n\n    def test_list_with_depth(self):\n        \"\"\"\n        Passing a relationship field lookup specifier to select_related() will\n        stop the descent at a particular level. This can be used on lists as\n        well.\n        \"\"\"\n        with self.assertNumQueries(5):\n            world = Species.objects.select_related(\"genus__family\")\n            orders = [o.genus.family.order.name for o in world]\n            self.assertEqual(\n                sorted(orders), [\"Agaricales\", \"Diptera\", \"Fabales\", \"Primates\"]\n            )\n\n    def test_select_related_with_extra(self):\n        s = (\n            Species.objects.all()\n            .select_related()\n            .extra(select={\"a\": \"select_related_species.id + 10\"})[0]\n        )\n        self.assertEqual(s.id + 10, s.a)\n\n    def test_certain_fields(self):\n        \"\"\"\n        The optional fields passed to select_related() control which related\n        models we pull in. This allows for smaller queries.\n\n        In this case, we explicitly say to select the 'genus' and\n        'genus.family' models, leading to the same number of queries as before.\n        \"\"\"\n        with self.assertNumQueries(1):\n            world = Species.objects.select_related(\"genus__family\")\n            families = [o.genus.family.name for o in world]\n            self.assertEqual(\n                sorted(families),\n                [\"Amanitacae\", \"Drosophilidae\", \"Fabaceae\", \"Hominidae\"],\n            )\n\n    def test_more_certain_fields(self):\n        \"\"\"\n        In this case, we explicitly say to select the 'genus' and\n        'genus.family' models, leading to the same number of queries as before.\n        \"\"\"\n        with self.assertNumQueries(2):\n            world = Species.objects.filter(genus__name=\"Amanita\").select_related(\n                \"genus__family\"\n            )\n            orders = [o.genus.family.order.name for o in world]\n            self.assertEqual(orders, [\"Agaricales\"])\n\n    def test_field_traversal(self):\n        with self.assertNumQueries(1):\n            s = (\n                Species.objects.all()\n                .select_related(\"genus__family__order\")\n                .order_by(\"id\")[0:1]\n                .get()\n                .genus.family.order.name\n            )\n            self.assertEqual(s, \"Diptera\")\n\n    def test_none_clears_list(self):\n        queryset = Species.objects.select_related(\"genus\").select_related(None)\n        self.assertIs(queryset.query.select_related, False)\n\n    def test_chaining(self):\n        parent_1, parent_2 = Species.objects.all()[:2]\n        HybridSpecies.objects.create(\n            name=\"hybrid\", parent_1=parent_1, parent_2=parent_2\n        )\n        queryset = HybridSpecies.objects.select_related(\"parent_1\").select_related(\n            \"parent_2\"\n        )\n        with self.assertNumQueries(1):\n            obj = queryset[0]\n            self.assertEqual(obj.parent_1, parent_1)\n            self.assertEqual(obj.parent_2, parent_2)\n\n    def test_reverse_relation_caching(self):\n        species = (\n            Species.objects.select_related(\"genus\").filter(name=\"melanogaster\").first()\n        )\n        with self.assertNumQueries(0):\n            self.assertEqual(species.genus.name, \"Drosophila\")\n        # The species_set reverse relation isn't cached.\n        self.assertEqual(species.genus._state.fields_cache, {})\n        with self.assertNumQueries(1):\n            self.assertEqual(species.genus.species_set.first().name, \"melanogaster\")\n\n    def test_only_with_reverse_one_to_one(self):\n        \"\"\"\n        Test that only() works correctly with select_related() on reverse one-to-one relations.\n        \"\"\"\n        # Create a hybrid species with a parent\n        parent_1, parent_2 = Species.objects.all()[:2]\n        hybrid = HybridSpecies.objects.create(\n            name=\"hybrid\", parent_1=parent_1, parent_2=parent_2\n        )\n        \n        # Query using only() with select_related() on the reverse relation\n        qs = Species.objects.filter(pk=parent_1.pk).select_related(\n            \"child_1\"\n        ).only(\"name\", \"child_1__name\")\n        \n        # Check that the query returns the correct object\n        obj = qs.get()\n        self.assertEqual(obj.name, parent_1.name)\n        self.assertEqual(obj.child_1.name, \"hybrid\")\n        \n        # Verify that other fields are deferred\n        self.assertIs(obj.child_1.__class__, HybridSpecies)\n        self.assertIs(type(obj.child_1.parent_2_id), int)  # Should be deferred but FK still accessible\n\n    def test_select_related_after_values(self):\n        \"\"\"\n        Running select_related() after calling values() raises a TypeError\n        \"\"\"\n        message = \"Cannot call select_related() after .values() or .values_list()\"\n        with self.assertRaisesMessage(TypeError, message):\n            list(Species.objects.values(\"name\").select_related(\"genus\"))\n\n    def test_select_related_after_values_list(self):\n        \"\"\"\n        Running select_related() after calling values_list() raises a TypeError\n        \"\"\"\n        message = \"Cannot call select_related() after .values() or .values_list()\"\n        with self.assertRaisesMessage(TypeError, message):\n            list(Species.objects.values_list(\"name\").select_related(\"genus\"))\n\n\nclass SelectRelatedValidationTests(SimpleTestCase):\n    \"\"\"\n    select_related() should thrown an error on fields that do not exist and\n    non-relational fields.\n    \"\"\"\n\n    non_relational_error = (\n        \"Non-relational field given in select_related: '%s'. Choices are: %s\"\n    )\n    invalid_error = (\n        \"Invalid field name(s) given in select_related: '%s'. Choices are: %s\"\n    )\n\n    def test_non_relational_field(self):\n        with self.assertRaisesMessage(\n            FieldError, self.non_relational_error % (\"name\", \"genus\")\n        ):\n            list(Species.objects.select_related(\"name__some_field\"))\n\n        with self.assertRaisesMessage(\n            FieldError, self.non_relational_error % (\"name\", \"genus\")\n        ):\n            list(Species.objects.select_related(\"name\"))\n\n        with self.assertRaisesMessage(\n            FieldError, self.non_relational_error % (\"name\", \"(none)\")\n        ):\n            list(Domain.objects.select_related(\"name\"))\n\n    def test_non_relational_field_nested(self):\n        with self.assertRaisesMessage(\n            FieldError, self.non_relational_error % (\"name\", \"family\")\n        ):\n            list(Species.objects.select_related(\"genus__name\"))\n\n    def test_many_to_many_field(self):\n        with self.assertRaisesMessage(\n            FieldError, self.invalid_error % (\"toppings\", \"(none)\")\n        ):\n            list(Pizza.objects.select_related(\"toppings\"))\n\n    def test_reverse_relational_field(self):\n        with self.assertRaisesMessage(\n            FieldError, self.invalid_error % (\"child_1\", \"genus\")\n        ):\n            list(Species.objects.select_related(\"child_1\"))\n\n    def test_invalid_field(self):\n        with self.assertRaisesMessage(\n            FieldError, self.invalid_error % (\"invalid_field\", \"genus\")\n        ):\n            list(Species.objects.select_related(\"invalid_field\"))\n\n        with self.assertRaisesMessage(\n            FieldError, self.invalid_error % (\"related_invalid_field\", \"family\")\n        ):\n            list(Species.objects.select_related(\"genus__related_invalid_field\"))\n\n        with self.assertRaisesMessage(\n            FieldError, self.invalid_error % (\"invalid_field\", \"(none)\")\n        ):\n            list(Domain.objects.select_related(\"invalid_field\"))\n\n    def test_generic_relations(self):\n        with self.assertRaisesMessage(FieldError, self.invalid_error % (\"tags\", \"\")):\n            list(Bookmark.objects.select_related(\"tags\"))\n\n        with self.assertRaisesMessage(\n            FieldError, self.invalid_error % (\"content_object\", \"content_type\")\n        ):\n            list(TaggedItem.objects.select_related(\"content_object\"))\n</file>\n<file path=\"/testbed/tests/select_related/models.py\">\n\"\"\"\nTests for select_related()\n\n``select_related()`` follows all relationships and pre-caches any foreign key\nvalues so that complex trees can be fetched in a single query. However, this\nisn't always a good idea, so the ``depth`` argument control how many \"levels\"\nthe select-related behavior will traverse.\n\"\"\"\n\nfrom django.contrib.contenttypes.fields import GenericForeignKey, GenericRelation\nfrom django.contrib.contenttypes.models import ContentType\nfrom django.db import models\n\n# Who remembers high school biology?\n\n\nclass Domain(models.Model):\n    name = models.CharField(max_length=50)\n\n\nclass Kingdom(models.Model):\n    name = models.CharField(max_length=50)\n    domain = models.ForeignKey(Domain, models.CASCADE)\n\n\nclass Phylum(models.Model):\n    name = models.CharField(max_length=50)\n    kingdom = models.ForeignKey(Kingdom, models.CASCADE)\n\n\nclass Klass(models.Model):\n    name = models.CharField(max_length=50)\n    phylum = models.ForeignKey(Phylum, models.CASCADE)\n\n\nclass Order(models.Model):\n    name = models.CharField(max_length=50)\n    klass = models.ForeignKey(Klass, models.CASCADE)\n\n\nclass Family(models.Model):\n    name = models.CharField(max_length=50)\n    order = models.ForeignKey(Order, models.CASCADE)\n\n\nclass Genus(models.Model):\n    name = models.CharField(max_length=50)\n    family = models.ForeignKey(Family, models.CASCADE)\n\n\nclass Species(models.Model):\n    name = models.CharField(max_length=50)\n    genus = models.ForeignKey(Genus, models.CASCADE)\n\n\n# and we'll invent a new thing so we have a model with two foreign keys\n\n\nclass HybridSpecies(models.Model):\n    name = models.CharField(max_length=50)\n    parent_1 = models.ForeignKey(Species, models.CASCADE, related_name=\"child_1\")\n    parent_2 = models.ForeignKey(Species, models.CASCADE, related_name=\"child_2\")\n\n\nclass Topping(models.Model):\n    name = models.CharField(max_length=30)\n\n\nclass Pizza(models.Model):\n    name = models.CharField(max_length=100)\n    toppings = models.ManyToManyField(Topping)\n\n\nclass TaggedItem(models.Model):\n    tag = models.CharField(max_length=30)\n\n    content_type = models.ForeignKey(\n        ContentType, models.CASCADE, related_name=\"select_related_tagged_items\"\n    )\n    object_id = models.PositiveIntegerField()\n    content_object = GenericForeignKey(\"content_type\", \"object_id\")\n\n\nclass Bookmark(models.Model):\n    url = models.URLField()\n    tags = GenericRelation(TaggedItem)\n</file>\n<file path=\"/testbed/django/db/models/fields/related.py\">\nimport functools\nimport inspect\nimport warnings\nfrom functools import partial\n\nfrom django import forms\nfrom django.apps import apps\nfrom django.conf import SettingsReference, settings\nfrom django.core import checks, exceptions\nfrom django.db import connection, router\nfrom django.db.backends import utils\nfrom django.db.models import Q\nfrom django.db.models.constants import LOOKUP_SEP\nfrom django.db.models.deletion import CASCADE, SET_DEFAULT, SET_NULL\nfrom django.db.models.query_utils import PathInfo\nfrom django.db.models.utils import make_model_tuple\nfrom django.utils.deprecation import RemovedInDjango60Warning\nfrom django.utils.functional import cached_property\nfrom django.utils.translation import gettext_lazy as _\n\nfrom . import Field\nfrom .mixins import FieldCacheMixin\nfrom .related_descriptors import (\n    ForeignKeyDeferredAttribute,\n    ForwardManyToOneDescriptor,\n    ForwardOneToOneDescriptor,\n    ManyToManyDescriptor,\n    ReverseManyToOneDescriptor,\n    ReverseOneToOneDescriptor,\n)\nfrom .related_lookups import (\n    RelatedExact,\n    RelatedGreaterThan,\n    RelatedGreaterThanOrEqual,\n    RelatedIn,\n    RelatedIsNull,\n    RelatedLessThan,\n    RelatedLessThanOrEqual,\n)\nfrom .reverse_related import ForeignObjectRel, ManyToManyRel, ManyToOneRel, OneToOneRel\n\nRECURSIVE_RELATIONSHIP_CONSTANT = \"self\"\n\n\ndef resolve_relation(scope_model, relation):\n    \"\"\"\n    Transform relation into a model or fully-qualified model string of the form\n    \"app_label.ModelName\", relative to scope_model.\n\n    The relation argument can be:\n      * RECURSIVE_RELATIONSHIP_CONSTANT, i.e. the string \"self\", in which case\n        the model argument will be returned.\n      * A bare model name without an app_label, in which case scope_model's\n        app_label will be prepended.\n      * An \"app_label.ModelName\" string.\n      * A model class, which will be returned unchanged.\n    \"\"\"\n    # Check for recursive relations\n    if relation == RECURSIVE_RELATIONSHIP_CONSTANT:\n        relation = scope_model\n\n    # Look for an \"app.Model\" relation\n    if isinstance(relation, str):\n        if \".\" not in relation:\n            relation = \"%s.%s\" % (scope_model._meta.app_label, relation)\n\n    return relation\n\n\ndef lazy_related_operation(function, model, *related_models, **kwargs):\n    \"\"\"\n    Schedule `function` to be called once `model` and all `related_models`\n    have been imported and registered with the app registry. `function` will\n    be called with the newly-loaded model classes as its positional arguments,\n    plus any optional keyword arguments.\n\n    The `model` argument must be a model class. Each subsequent positional\n    argument is another model, or a reference to another model - see\n    `resolve_relation()` for the various forms these may take. Any relative\n    references will be resolved relative to `model`.\n\n    This is a convenience wrapper for `Apps.lazy_model_operation` - the app\n    registry model used is the one found in `model._meta.apps`.\n    \"\"\"\n    models = [model] + [resolve_relation(model, rel) for rel in related_models]\n    model_keys = (make_model_tuple(m) for m in models)\n    apps = model._meta.apps\n    return apps.lazy_model_operation(partial(function, **kwargs), *model_keys)\n\n\nclass RelatedField(FieldCacheMixin, Field):\n    \"\"\"Base class that all relational fields inherit from.\"\"\"\n\n    # Field flags\n    one_to_many = False\n    one_to_one = False\n    many_to_many = False\n    many_to_one = False\n\n    def __init__(\n        self,\n        related_name=None,\n        related_query_name=None,\n        limit_choices_to=None,\n        **kwargs,\n    ):\n        self._related_name = related_name\n        self._related_query_name = related_query_name\n        self._limit_choices_to = limit_choices_to\n        super().__init__(**kwargs)\n\n    @cached_property\n    def related_model(self):\n        # Can't cache this property until all the models are loaded.\n        apps.check_models_ready()\n        return self.remote_field.model\n\n    def check(self, **kwargs):\n        return [\n            *super().check(**kwargs),\n            *self._check_related_name_is_valid(),\n            *self._check_related_query_name_is_valid(),\n            *self._check_relation_model_exists(),\n            *self._check_referencing_to_swapped_model(),\n            *self._check_clashes(),\n        ]\n\n    def _check_related_name_is_valid(self):\n        import keyword\n\n        related_name = self.remote_field.related_name\n        if related_name is None:\n            return []\n        is_valid_id = (\n            not keyword.iskeyword(related_name) and related_name.isidentifier()\n        )\n        if not (is_valid_id or related_name.endswith(\"+\")):\n            return [\n                checks.Error(\n                    \"The name '%s' is invalid related_name for field %s.%s\"\n                    % (\n                        self.remote_field.related_name,\n                        self.model._meta.object_name,\n                        self.name,\n                    ),\n                    hint=(\n                        \"Related name must be a valid Python identifier or end with a \"\n                        \"'+'\"\n                    ),\n                    obj=self,\n                    id=\"fields.E306\",\n                )\n            ]\n        return []\n\n    def _check_related_query_name_is_valid(self):\n        if self.remote_field.is_hidden():\n            return []\n        rel_query_name = self.related_query_name()\n        errors = []\n        if rel_query_name.endswith(\"_\"):\n            errors.append(\n                checks.Error(\n                    \"Reverse query name '%s' must not end with an underscore.\"\n                    % rel_query_name,\n                    hint=(\n                        \"Add or change a related_name or related_query_name \"\n                        \"argument for this field.\"\n                    ),\n                    obj=self,\n                    id=\"fields.E308\",\n                )\n            )\n        if LOOKUP_SEP in rel_query_name:\n            errors.append(\n                checks.Error(\n                    \"Reverse query name '%s' must not contain '%s'.\"\n                    % (rel_query_name, LOOKUP_SEP),\n                    hint=(\n                        \"Add or change a related_name or related_query_name \"\n                        \"argument for this field.\"\n                    ),\n                    obj=self,\n                    id=\"fields.E309\",\n                )\n            )\n        return errors\n\n    def _check_relation_model_exists(self):\n        rel_is_missing = self.remote_field.model not in self.opts.apps.get_models()\n        rel_is_string = isinstance(self.remote_field.model, str)\n        model_name = (\n            self.remote_field.model\n            if rel_is_string\n            else self.remote_field.model._meta.object_name\n        )\n        if rel_is_missing and (\n            rel_is_string or not self.remote_field.model._meta.swapped\n        ):\n            return [\n                checks.Error(\n                    \"Field defines a relation with model '%s', which is either \"\n                    \"not installed, or is abstract.\" % model_name,\n                    obj=self,\n                    id=\"fields.E300\",\n                )\n            ]\n        return []\n\n    def _check_referencing_to_swapped_model(self):\n        if (\n            self.remote_field.model not in self.opts.apps.get_models()\n            and not isinstance(self.remote_field.model, str)\n            and self.remote_field.model._meta.swapped\n        ):\n            return [\n                checks.Error(\n                    \"Field defines a relation with the model '%s', which has \"\n                    \"been swapped out.\" % self.remote_field.model._meta.label,\n                    hint=\"Update the relation to point at 'settings.%s'.\"\n                    % self.remote_field.model._meta.swappable,\n                    obj=self,\n                    id=\"fields.E301\",\n                )\n            ]\n        return []\n\n    def _check_clashes(self):\n        \"\"\"Check accessor and reverse query name clashes.\"\"\"\n        from django.db.models.base import ModelBase\n\n        errors = []\n        opts = self.model._meta\n\n        # f.remote_field.model may be a string instead of a model. Skip if\n        # model name is not resolved.\n        if not isinstance(self.remote_field.model, ModelBase):\n            return []\n\n        # Consider that we are checking field `Model.foreign` and the models\n        # are:\n        #\n        #     class Target(models.Model):\n        #         model = models.IntegerField()\n        #         model_set = models.IntegerField()\n        #\n        #     class Model(models.Model):\n        #         foreign = models.ForeignKey(Target)\n        #         m2m = models.ManyToManyField(Target)\n\n        # rel_opts.object_name == \"Target\"\n        rel_opts = self.remote_field.model._meta\n        # If the field doesn't install a backward relation on the target model\n        # (so `is_hidden` returns True), then there are no clashes to check\n        # and we can skip these fields.\n        rel_is_hidden = self.remote_field.is_hidden()\n        rel_name = self.remote_field.get_accessor_name()  # i. e. \"model_set\"\n        rel_query_name = self.related_query_name()  # i. e. \"model\"\n        # i.e. \"app_label.Model.field\".\n        field_name = \"%s.%s\" % (opts.label, self.name)\n\n        # Check clashes between accessor or reverse query name of `field`\n        # and any other field name -- i.e. accessor for Model.foreign is\n        # model_set and it clashes with Target.model_set.\n        potential_clashes = rel_opts.fields + rel_opts.many_to_many\n        for clash_field in potential_clashes:\n            # i.e. \"app_label.Target.model_set\".\n            clash_name = \"%s.%s\" % (rel_opts.label, clash_field.name)\n            if not rel_is_hidden and clash_field.name == rel_name:\n                errors.append(\n                    checks.Error(\n                        f\"Reverse accessor '{rel_opts.object_name}.{rel_name}' \"\n                        f\"for '{field_name}' clashes with field name \"\n                        f\"'{clash_name}'.\",\n                        hint=(\n                            \"Rename field '%s', or add/change a related_name \"\n                            \"argument to the definition for field '%s'.\"\n                        )\n                        % (clash_name, field_name),\n                        obj=self,\n                        id=\"fields.E302\",\n                    )\n                )\n\n            if clash_field.name == rel_query_name:\n                errors.append(\n                    checks.Error(\n                        \"Reverse query name for '%s' clashes with field name '%s'.\"\n                        % (field_name, clash_name),\n                        hint=(\n                            \"Rename field '%s', or add/change a related_name \"\n                            \"argument to the definition for field '%s'.\"\n                        )\n                        % (clash_name, field_name),\n                        obj=self,\n                        id=\"fields.E303\",\n                    )\n                )\n\n        # Check clashes between accessors/reverse query names of `field` and\n        # any other field accessor -- i. e. Model.foreign accessor clashes with\n        # Model.m2m accessor.\n        potential_clashes = (r for r in rel_opts.related_objects if r.field is not self)\n        for clash_field in potential_clashes:\n            # i.e. \"app_label.Model.m2m\".\n            clash_name = \"%s.%s\" % (\n                clash_field.related_model._meta.label,\n                clash_field.field.name,\n            )\n            if not rel_is_hidden and clash_field.get_accessor_name() == rel_name:\n                errors.append(\n                    checks.Error(\n                        f\"Reverse accessor '{rel_opts.object_name}.{rel_name}' \"\n                        f\"for '{field_name}' clashes with reverse accessor for \"\n                        f\"'{clash_name}'.\",\n                        hint=(\n                            \"Add or change a related_name argument \"\n                            \"to the definition for '%s' or '%s'.\"\n                        )\n                        % (field_name, clash_name),\n                        obj=self,\n                        id=\"fields.E304\",\n                    )\n                )\n\n            if clash_field.get_accessor_name() == rel_query_name:\n                errors.append(\n                    checks.Error(\n                        \"Reverse query name for '%s' clashes with reverse query name \"\n                        \"for '%s'.\" % (field_name, clash_name),\n                        hint=(\n                            \"Add or change a related_name argument \"\n                            \"to the definition for '%s' or '%s'.\"\n                        )\n                        % (field_name, clash_name),\n                        obj=self,\n                        id=\"fields.E305\",\n                    )\n                )\n\n        return errors\n\n    def db_type(self, connection):\n        # By default related field will not have a column as it relates to\n        # columns from another table.\n        return None\n\n    def contribute_to_class(self, cls, name, private_only=False, **kwargs):\n        super().contribute_to_class(cls, name, private_only=private_only, **kwargs)\n\n        self.opts = cls._meta\n\n        if not cls._meta.abstract:\n            if self.remote_field.related_name:\n                related_name = self.remote_field.related_name\n            else:\n                related_name = self.opts.default_related_name\n            if related_name:\n                related_name %= {\n                    \"class\": cls.__name__.lower(),\n                    \"model_name\": cls._meta.model_name.lower(),\n                    \"app_label\": cls._meta.app_label.lower(),\n                }\n                self.remote_field.related_name = related_name\n\n            if self.remote_field.related_query_name:\n                related_query_name = self.remote_field.related_query_name % {\n                    \"class\": cls.__name__.lower(),\n                    \"app_label\": cls._meta.app_label.lower(),\n                }\n                self.remote_field.related_query_name = related_query_name\n\n            def resolve_related_class(model, related, field):\n                field.remote_field.model = related\n                field.do_related_class(related, model)\n\n            lazy_related_operation(\n                resolve_related_class, cls, self.remote_field.model, field=self\n            )\n\n    def deconstruct(self):\n        name, path, args, kwargs = super().deconstruct()\n        if self._limit_choices_to:\n            kwargs[\"limit_choices_to\"] = self._limit_choices_to\n        if self._related_name is not None:\n            kwargs[\"related_name\"] = self._related_name\n        if self._related_query_name is not None:\n            kwargs[\"related_query_name\"] = self._related_query_name\n        return name, path, args, kwargs\n\n    def get_forward_related_filter(self, obj):\n        \"\"\"\n        Return the keyword arguments that when supplied to\n        self.model.object.filter(), would select all instances related through\n        this field to the remote obj. This is used to build the querysets\n        returned by related descriptors. obj is an instance of\n        self.related_field.model.\n        \"\"\"\n        return {\n            \"%s__%s\" % (self.name, rh_field.name): getattr(obj, rh_field.attname)\n            for _, rh_field in self.related_fields\n        }\n\n    def get_reverse_related_filter(self, obj):\n        \"\"\"\n        Complement to get_forward_related_filter(). Return the keyword\n        arguments that when passed to self.related_field.model.object.filter()\n        select all instances of self.related_field.model related through\n        this field to obj. obj is an instance of self.model.\n        \"\"\"\n        base_q = Q.create(\n            [\n                (rh_field.attname, getattr(obj, lh_field.attname))\n                for lh_field, rh_field in self.related_fields\n            ]\n        )\n        descriptor_filter = self.get_extra_descriptor_filter(obj)\n        if isinstance(descriptor_filter, dict):\n            return base_q & Q(**descriptor_filter)\n        elif descriptor_filter:\n            return base_q & descriptor_filter\n        return base_q\n\n    @property\n    def swappable_setting(self):\n        \"\"\"\n        Get the setting that this is powered from for swapping, or None\n        if it's not swapped in / marked with swappable=False.\n        \"\"\"\n        if self.swappable:\n            # Work out string form of \"to\"\n            if isinstance(self.remote_field.model, str):\n                to_string = self.remote_field.model\n            else:\n                to_string = self.remote_field.model._meta.label\n            return apps.get_swappable_settings_name(to_string)\n        return None\n\n    def set_attributes_from_rel(self):\n        self.name = self.name or (\n            self.remote_field.model._meta.model_name\n            + \"_\"\n            + self.remote_field.model._meta.pk.name\n        )\n        if self.verbose_name is None:\n            self.verbose_name = self.remote_field.model._meta.verbose_name\n        self.remote_field.set_field_name()\n\n    def do_related_class(self, other, cls):\n        self.set_attributes_from_rel()\n        self.contribute_to_related_class(other, self.remote_field)\n\n    def get_limit_choices_to(self):\n        \"\"\"\n        Return ``limit_choices_to`` for this model field.\n\n        If it is a callable, it will be invoked and the result will be\n        returned.\n        \"\"\"\n        if callable(self.remote_field.limit_choices_to):\n            return self.remote_field.limit_choices_to()\n        return self.remote_field.limit_choices_to\n\n    def formfield(self, **kwargs):\n        \"\"\"\n        Pass ``limit_choices_to`` to the field being constructed.\n\n        Only passes it if there is a type that supports related fields.\n        This is a similar strategy used to pass the ``queryset`` to the field\n        being constructed.\n        \"\"\"\n        defaults = {}\n        if hasattr(self.remote_field, \"get_related_field\"):\n            # If this is a callable, do not invoke it here. Just pass\n            # it in the defaults for when the form class will later be\n            # instantiated.\n            limit_choices_to = self.remote_field.limit_choices_to\n            defaults.update(\n                {\n                    \"limit_choices_to\": limit_choices_to,\n                }\n            )\n        defaults.update(kwargs)\n        return super().formfield(**defaults)\n\n    def related_query_name(self):\n        \"\"\"\n        Define the name that can be used to identify this related object in a\n        table-spanning query.\n        \"\"\"\n        return (\n            self.remote_field.related_query_name\n            or self.remote_field.related_name\n            or self.opts.model_name\n        )\n\n    @property\n    def target_field(self):\n        \"\"\"\n        When filtering against this relation, return the field on the remote\n        model against which the filtering should happen.\n        \"\"\"\n        target_fields = self.path_infos[-1].target_fields\n        if len(target_fields) > 1:\n            raise exceptions.FieldError(\n                \"The relation has multiple target fields, but only single target field \"\n                \"was asked for\"\n            )\n        return target_fields[0]\n\n    def get_cache_name(self):\n        return self.name\n\n\nclass ForeignObject(RelatedField):\n    \"\"\"\n    Abstraction of the ForeignKey relation to support multi-column relations.\n    \"\"\"\n\n    # Field flags\n    many_to_many = False\n    many_to_one = True\n    one_to_many = False\n    one_to_one = False\n\n    requires_unique_target = True\n    related_accessor_class = ReverseManyToOneDescriptor\n    forward_related_accessor_class = ForwardManyToOneDescriptor\n    rel_class = ForeignObjectRel\n\n    def __init__(\n        self,\n        to,\n        on_delete,\n        from_fields,\n        to_fields,\n        rel=None,\n        related_name=None,\n        related_query_name=None,\n        limit_choices_to=None,\n        parent_link=False,\n        swappable=True,\n        **kwargs,\n    ):\n        if rel is None:\n            rel = self.rel_class(\n                self,\n                to,\n                related_name=related_name,\n                related_query_name=related_query_name,\n                limit_choices_to=limit_choices_to,\n                parent_link=parent_link,\n                on_delete=on_delete,\n            )\n\n        super().__init__(\n            rel=rel,\n            related_name=related_name,\n            related_query_name=related_query_name,\n            limit_choices_to=limit_choices_to,\n            **kwargs,\n        )\n\n        self.from_fields = from_fields\n        self.to_fields = to_fields\n        self.swappable = swappable\n\n    def __copy__(self):\n        obj = super().__copy__()\n        # Remove any cached PathInfo values.\n        obj.__dict__.pop(\"path_infos\", None)\n        obj.__dict__.pop(\"reverse_path_infos\", None)\n        return obj\n\n    def check(self, **kwargs):\n        return [\n            *super().check(**kwargs),\n            *self._check_to_fields_exist(),\n            *self._check_unique_target(),\n        ]\n\n    def _check_to_fields_exist(self):\n        # Skip nonexistent models.\n        if isinstance(self.remote_field.model, str):\n            return []\n\n        errors = []\n        for to_field in self.to_fields:\n            if to_field:\n                try:\n                    self.remote_field.model._meta.get_field(to_field)\n                except exceptions.FieldDoesNotExist:\n                    errors.append(\n                        checks.Error(\n                            \"The to_field '%s' doesn't exist on the related \"\n                            \"model '%s'.\"\n                            % (to_field, self.remote_field.model._meta.label),\n                            obj=self,\n                            id=\"fields.E312\",\n                        )\n                    )\n        return errors\n\n    def _check_unique_target(self):\n        rel_is_string = isinstance(self.remote_field.model, str)\n        if rel_is_string or not self.requires_unique_target:\n            return []\n\n        try:\n            self.foreign_related_fields\n        except exceptions.FieldDoesNotExist:\n            return []\n\n        if not self.foreign_related_fields:\n            return []\n\n        unique_foreign_fields = {\n            frozenset([f.name])\n            for f in self.remote_field.model._meta.get_fields()\n            if getattr(f, \"unique\", False)\n        }\n        unique_foreign_fields.update(\n            {frozenset(ut) for ut in self.remote_field.model._meta.unique_together}\n        )\n        unique_foreign_fields.update(\n            {\n                frozenset(uc.fields)\n                for uc in self.remote_field.model._meta.total_unique_constraints\n            }\n        )\n        foreign_fields = {f.name for f in self.foreign_related_fields}\n        has_unique_constraint = any(u <= foreign_fields for u in unique_foreign_fields)\n\n        if not has_unique_constraint and len(self.foreign_related_fields) > 1:\n            field_combination = \", \".join(\n                \"'%s'\" % rel_field.name for rel_field in self.foreign_related_fields\n            )\n            model_name = self.remote_field.model.__name__\n            return [\n                checks.Error(\n                    \"No subset of the fields %s on model '%s' is unique.\"\n                    % (field_combination, model_name),\n                    hint=(\n                        \"Mark a single field as unique=True or add a set of \"\n                        \"fields to a unique constraint (via unique_together \"\n                        \"or a UniqueConstraint (without condition) in the \"\n                        \"model Meta.constraints).\"\n                    ),\n                    obj=self,\n                    id=\"fields.E310\",\n                )\n            ]\n        elif not has_unique_constraint:\n            field_name = self.foreign_related_fields[0].name\n            model_name = self.remote_field.model.__name__\n            return [\n                checks.Error(\n                    \"'%s.%s' must be unique because it is referenced by \"\n                    \"a foreign key.\" % (model_name, field_name),\n                    hint=(\n                        \"Add unique=True to this field or add a \"\n                        \"UniqueConstraint (without condition) in the model \"\n                        \"Meta.constraints.\"\n                    ),\n                    obj=self,\n                    id=\"fields.E311\",\n                )\n            ]\n        else:\n            return []\n\n    def deconstruct(self):\n        name, path, args, kwargs = super().deconstruct()\n        kwargs[\"on_delete\"] = self.remote_field.on_delete\n        kwargs[\"from_fields\"] = self.from_fields\n        kwargs[\"to_fields\"] = self.to_fields\n\n        if self.remote_field.parent_link:\n            kwargs[\"parent_link\"] = self.remote_field.parent_link\n        if isinstance(self.remote_field.model, str):\n            if \".\" in self.remote_field.model:\n                app_label, model_name = self.remote_field.model.split(\".\")\n                kwargs[\"to\"] = \"%s.%s\" % (app_label, model_name.lower())\n            else:\n                kwargs[\"to\"] = self.remote_field.model.lower()\n        else:\n            kwargs[\"to\"] = self.remote_field.model._meta.label_lower\n        # If swappable is True, then see if we're actually pointing to the target\n        # of a swap.\n        swappable_setting = self.swappable_setting\n        if swappable_setting is not None:\n            # If it's already a settings reference, error\n            if hasattr(kwargs[\"to\"], \"setting_name\"):\n                if kwargs[\"to\"].setting_name != swappable_setting:\n                    raise ValueError(\n                        \"Cannot deconstruct a ForeignKey pointing to a model \"\n                        \"that is swapped in place of more than one model (%s and %s)\"\n                        % (kwargs[\"to\"].setting_name, swappable_setting)\n                    )\n            # Set it\n            kwargs[\"to\"] = SettingsReference(\n                kwargs[\"to\"],\n                swappable_setting,\n            )\n        return name, path, args, kwargs\n\n    def resolve_related_fields(self):\n        if not self.from_fields or len(self.from_fields) != len(self.to_fields):\n            raise ValueError(\n                \"Foreign Object from and to fields must be the same non-zero length\"\n            )\n        if isinstance(self.remote_field.model, str):\n            raise ValueError(\n                \"Related model %r cannot be resolved\" % self.remote_field.model\n            )\n        related_fields = []\n        for index in range(len(self.from_fields)):\n            from_field_name = self.from_fields[index]\n            to_field_name = self.to_fields[index]\n            from_field = (\n                self\n                if from_field_name == RECURSIVE_RELATIONSHIP_CONSTANT\n                else self.opts.get_field(from_field_name)\n            )\n            to_field = (\n                self.remote_field.model._meta.pk\n                if to_field_name is None\n                else self.remote_field.model._meta.get_field(to_field_name)\n            )\n            related_fields.append((from_field, to_field))\n        return related_fields\n\n    @cached_property\n    def related_fields(self):\n        return self.resolve_related_fields()\n\n    @cached_property\n    def reverse_related_fields(self):\n        return [(rhs_field, lhs_field) for lhs_field, rhs_field in self.related_fields]\n\n    @cached_property\n    def local_related_fields(self):\n        return tuple(lhs_field for lhs_field, rhs_field in self.related_fields)\n\n    @cached_property\n    def foreign_related_fields(self):\n        return tuple(\n            rhs_field for lhs_field, rhs_field in self.related_fields if rhs_field\n        )\n\n    def get_local_related_value(self, instance):\n        return self.get_instance_value_for_fields(instance, self.local_related_fields)\n\n    def get_foreign_related_value(self, instance):\n        return self.get_instance_value_for_fields(instance, self.foreign_related_fields)\n\n    @staticmethod\n    def get_instance_value_for_fields(instance, fields):\n        ret = []\n        opts = instance._meta\n        for field in fields:\n            # Gotcha: in some cases (like fixture loading) a model can have\n            # different values in parent_ptr_id and parent's id. So, use\n            # instance.pk (that is, parent_ptr_id) when asked for instance.id.\n            if field.primary_key:\n                possible_parent_link = opts.get_ancestor_link(field.model)\n                if (\n                    not possible_parent_link\n                    or possible_parent_link.primary_key\n                    or possible_parent_link.model._meta.abstract\n                ):\n                    ret.append(instance.pk)\n                    continue\n            ret.append(getattr(instance, field.attname))\n        return tuple(ret)\n\n    def get_attname_column(self):\n        attname, column = super().get_attname_column()\n        return attname, None\n\n    def get_joining_columns(self, reverse_join=False):\n        warnings.warn(\n            \"ForeignObject.get_joining_columns() is deprecated. Use \"\n            \"get_joining_fields() instead.\",\n            RemovedInDjango60Warning,\n        )\n        source = self.reverse_related_fields if reverse_join else self.related_fields\n        return tuple(\n            (lhs_field.column, rhs_field.column) for lhs_field, rhs_field in source\n        )\n\n    def get_reverse_joining_columns(self):\n        warnings.warn(\n            \"ForeignObject.get_reverse_joining_columns() is deprecated. Use \"\n            \"get_reverse_joining_fields() instead.\",\n            RemovedInDjango60Warning,\n        )\n        return self.get_joining_columns(reverse_join=True)\n\n    def get_joining_fields(self, reverse_join=False):\n        return tuple(\n            self.reverse_related_fields if reverse_join else self.related_fields\n        )\n\n    def get_reverse_joining_fields(self):\n        return self.get_joining_fields(reverse_join=True)\n\n    def get_extra_descriptor_filter(self, instance):\n        \"\"\"\n        Return an extra filter condition for related object fetching when\n        user does 'instance.fieldname', that is the extra filter is used in\n        the descriptor of the field.\n\n        The filter should be either a dict usable in .filter(**kwargs) call or\n        a Q-object. The condition will be ANDed together with the relation's\n        joining columns.\n\n        A parallel method is get_extra_restriction() which is used in\n        JOIN and subquery conditions.\n        \"\"\"\n        return {}\n\n    def get_extra_restriction(self, alias, related_alias):\n        \"\"\"\n        Return a pair condition used for joining and subquery pushdown. The\n        condition is something that responds to as_sql(compiler, connection)\n        method.\n\n        Note that currently referring both the 'alias' and 'related_alias'\n        will not work in some conditions, like subquery pushdown.\n\n        A parallel method is get_extra_descriptor_filter() which is used in\n        instance.fieldname related object fetching.\n        \"\"\"\n        return None\n\n    def get_path_info(self, filtered_relation=None):\n        \"\"\"Get path from this field to the related model.\"\"\"\n        opts = self.remote_field.model._meta\n        from_opts = self.model._meta\n        return [\n            PathInfo(\n                from_opts=from_opts,\n                to_opts=opts,\n                target_fields=self.foreign_related_fields,\n                join_field=self,\n                m2m=False,\n                direct=True,\n                filtered_relation=filtered_relation,\n            )\n        ]\n\n    @cached_property\n    def path_infos(self):\n        return self.get_path_info()\n\n    def get_reverse_path_info(self, filtered_relation=None):\n        \"\"\"Get path from the related model to this field's model.\"\"\"\n        opts = self.model._meta\n        from_opts = self.remote_field.model._meta\n        return [\n            PathInfo(\n                from_opts=from_opts,\n                to_opts=opts,\n                target_fields=(opts.pk,),\n                join_field=self.remote_field,\n                m2m=not self.unique,\n                direct=False,\n                filtered_relation=filtered_relation,\n            )\n        ]\n\n    @cached_property\n    def reverse_path_infos(self):\n        return self.get_reverse_path_info()\n\n    @classmethod\n    @functools.cache\n    def get_class_lookups(cls):\n        bases = inspect.getmro(cls)\n        bases = bases[: bases.index(ForeignObject) + 1]\n        class_lookups = [parent.__dict__.get(\"class_lookups\", {}) for parent in bases]\n        return cls.merge_dicts(class_lookups)\n\n    def contribute_to_class(self, cls, name, private_only=False, **kwargs):\n        super().contribute_to_class(cls, name, private_only=private_only, **kwargs)\n        setattr(cls, self.name, self.forward_related_accessor_class(self))\n\n    def contribute_to_related_class(self, cls, related):\n        # Internal FK's - i.e., those with a related name ending with '+' -\n        # and swapped models don't get a related descriptor.\n        if (\n            not self.remote_field.is_hidden()\n            and not related.related_model._meta.swapped\n        ):\n            setattr(\n                cls._meta.concrete_model,\n                related.get_accessor_name(),\n                self.related_accessor_class(related),\n            )\n            # While 'limit_choices_to' might be a callable, simply pass\n            # it along for later - this is too early because it's still\n            # model load time.\n            if self.remote_field.limit_choices_to:\n                cls._meta.related_fkey_lookups.append(\n                    self.remote_field.limit_choices_to\n                )\n\n\nForeignObject.register_lookup(RelatedIn)\nForeignObject.register_lookup(RelatedExact)\nForeignObject.register_lookup(RelatedLessThan)\nForeignObject.register_lookup(RelatedGreaterThan)\nForeignObject.register_lookup(RelatedGreaterThanOrEqual)\nForeignObject.register_lookup(RelatedLessThanOrEqual)\nForeignObject.register_lookup(RelatedIsNull)\n\n\nclass ForeignKey(ForeignObject):\n    \"\"\"\n    Provide a many-to-one relation by adding a column to the local model\n    to hold the remote value.\n\n    By default ForeignKey will target the pk of the remote model but this\n    behavior can be changed by using the ``to_field`` argument.\n    \"\"\"\n\n    descriptor_class = ForeignKeyDeferredAttribute\n    # Field flags\n    many_to_many = False\n    many_to_one = True\n    one_to_many = False\n    one_to_one = False\n\n    rel_class = ManyToOneRel\n\n    empty_strings_allowed = False\n    default_error_messages = {\n        \"invalid\": _(\"%(model)s instance with %(field)s %(value)r does not exist.\")\n    }\n    description = _(\"Foreign Key (type determined by related field)\")\n\n    def __init__(\n        self,\n        to,\n        on_delete,\n        related_name=None,\n        related_query_name=None,\n        limit_choices_to=None,\n        parent_link=False,\n        to_field=None,\n        db_constraint=True,\n        **kwargs,\n    ):\n        try:\n            to._meta.model_name\n        except AttributeError:\n            if not isinstance(to, str):\n                raise TypeError(\n                    \"%s(%r) is invalid. First parameter to ForeignKey must be \"\n                    \"either a model, a model name, or the string %r\"\n                    % (\n                        self.__class__.__name__,\n                        to,\n                        RECURSIVE_RELATIONSHIP_CONSTANT,\n                    )\n                )\n        else:\n            # For backwards compatibility purposes, we need to *try* and set\n            # the to_field during FK construction. It won't be guaranteed to\n            # be correct until contribute_to_class is called. Refs #12190.\n            to_field = to_field or (to._meta.pk and to._meta.pk.name)\n        if not callable(on_delete):\n            raise TypeError(\"on_delete must be callable.\")\n\n        kwargs[\"rel\"] = self.rel_class(\n            self,\n            to,\n            to_field,\n            related_name=related_name,\n            related_query_name=related_query_name,\n            limit_choices_to=limit_choices_to,\n            parent_link=parent_link,\n            on_delete=on_delete,\n        )\n        kwargs.setdefault(\"db_index\", True)\n\n        super().__init__(\n            to,\n            on_delete,\n            related_name=related_name,\n            related_query_name=related_query_name,\n            limit_choices_to=limit_choices_to,\n            from_fields=[RECURSIVE_RELATIONSHIP_CONSTANT],\n            to_fields=[to_field],\n            **kwargs,\n        )\n        self.db_constraint = db_constraint\n\n    def __class_getitem__(cls, *args, **kwargs):\n        return cls\n\n    def check(self, **kwargs):\n        return [\n            *super().check(**kwargs),\n            *self._check_on_delete(),\n            *self._check_unique(),\n        ]\n\n    def _check_on_delete(self):\n        on_delete = getattr(self.remote_field, \"on_delete\", None)\n        if on_delete == SET_NULL and not self.null:\n            return [\n                checks.Error(\n                    \"Field specifies on_delete=SET_NULL, but cannot be null.\",\n                    hint=(\n                        \"Set null=True argument on the field, or change the on_delete \"\n                        \"rule.\"\n                    ),\n                    obj=self,\n                    id=\"fields.E320\",\n                )\n            ]\n        elif on_delete == SET_DEFAULT and not self.has_default():\n            return [\n                checks.Error(\n                    \"Field specifies on_delete=SET_DEFAULT, but has no default value.\",\n                    hint=\"Set a default value, or change the on_delete rule.\",\n                    obj=self,\n                    id=\"fields.E321\",\n                )\n            ]\n        else:\n            return []\n\n    def _check_unique(self, **kwargs):\n        return (\n            [\n                checks.Warning(\n                    \"Setting unique=True on a ForeignKey has the same effect as using \"\n                    \"a OneToOneField.\",\n                    hint=(\n                        \"ForeignKey(unique=True) is usually better served by a \"\n                        \"OneToOneField.\"\n                    ),\n                    obj=self,\n                    id=\"fields.W342\",\n                )\n            ]\n            if self.unique\n            else []\n        )\n\n    def deconstruct(self):\n        name, path, args, kwargs = super().deconstruct()\n        del kwargs[\"to_fields\"]\n        del kwargs[\"from_fields\"]\n        # Handle the simpler arguments\n        if self.db_index:\n            del kwargs[\"db_index\"]\n        else:\n            kwargs[\"db_index\"] = False\n        if self.db_constraint is not True:\n            kwargs[\"db_constraint\"] = self.db_constraint\n        # Rel needs more work.\n        to_meta = getattr(self.remote_field.model, \"_meta\", None)\n        if self.remote_field.field_name and (\n            not to_meta\n            or (to_meta.pk and self.remote_field.field_name != to_meta.pk.name)\n        ):\n            kwargs[\"to_field\"] = self.remote_field.field_name\n        return name, path, args, kwargs\n\n    def to_python(self, value):\n        return self.target_field.to_python(value)\n\n    @property\n    def target_field(self):\n        return self.foreign_related_fields[0]\n\n    def validate(self, value, model_instance):\n        if self.remote_field.parent_link:\n            return\n        super().validate(value, model_instance)\n        if value is None:\n            return\n\n        using = router.db_for_read(self.remote_field.model, instance=model_instance)\n        qs = self.remote_field.model._base_manager.using(using).filter(\n            **{self.remote_field.field_name: value}\n        )\n        qs = qs.complex_filter(self.get_limit_choices_to())\n        if not qs.exists():\n            raise exceptions.ValidationError(\n                self.error_messages[\"invalid\"],\n                code=\"invalid\",\n                params={\n                    \"model\": self.remote_field.model._meta.verbose_name,\n                    \"pk\": value,\n                    \"field\": self.remote_field.field_name,\n                    \"value\": value,\n                },  # 'pk' is included for backwards compatibility\n            )\n\n    def resolve_related_fields(self):\n        related_fields = super().resolve_related_fields()\n        for from_field, to_field in related_fields:\n            if (\n                to_field\n                and to_field.model != self.remote_field.model._meta.concrete_model\n            ):\n                raise exceptions.FieldError(\n                    \"'%s.%s' refers to field '%s' which is not local to model \"\n                    \"'%s'.\"\n                    % (\n                        self.model._meta.label,\n                        self.name,\n                        to_field.name,\n                        self.remote_field.model._meta.concrete_model._meta.label,\n                    )\n                )\n        return related_fields\n\n    def get_attname(self):\n        return \"%s_id\" % self.name\n\n    def get_attname_column(self):\n        attname = self.get_attname()\n        column = self.db_column or attname\n        return attname, column\n\n    def get_default(self):\n        \"\"\"Return the to_field if the default value is an object.\"\"\"\n        field_default = super().get_default()\n        if isinstance(field_default, self.remote_field.model):\n            return getattr(field_default, self.target_field.attname)\n        return field_default\n\n    def get_db_prep_save(self, value, connection):\n        if value is None or (\n            value == \"\"\n            and (\n                not self.target_field.empty_strings_allowed\n                or connection.features.interprets_empty_strings_as_nulls\n            )\n        ):\n            return None\n        else:\n            return self.target_field.get_db_prep_save(value, connection=connection)\n\n    def get_db_prep_value(self, value, connection, prepared=False):\n        return self.target_field.get_db_prep_value(value, connection, prepared)\n\n    def get_prep_value(self, value):\n        return self.target_field.get_prep_value(value)\n\n    def contribute_to_related_class(self, cls, related):\n        super().contribute_to_related_class(cls, related)\n        if self.remote_field.field_name is None:\n            self.remote_field.field_name = cls._meta.pk.name\n\n    def formfield(self, *, using=None, **kwargs):\n        if isinstance(self.remote_field.model, str):\n            raise ValueError(\n                \"Cannot create form field for %r yet, because \"\n                \"its related model %r has not been loaded yet\"\n                % (self.name, self.remote_field.model)\n            )\n        return super().formfield(\n            **{\n                \"form_class\": forms.ModelChoiceField,\n                \"queryset\": self.remote_field.model._default_manager.using(using),\n                \"to_field_name\": self.remote_field.field_name,\n                **kwargs,\n                \"blank\": self.blank,\n            }\n        )\n\n    def db_check(self, connection):\n        return None\n\n    def db_type(self, connection):\n        return self.target_field.rel_db_type(connection=connection)\n\n    def cast_db_type(self, connection):\n        return self.target_field.cast_db_type(connection=connection)\n\n    def db_parameters(self, connection):\n        target_db_parameters = self.target_field.db_parameters(connection)\n        return {\n            \"type\": self.db_type(connection),\n            \"check\": self.db_check(connection),\n            \"collation\": target_db_parameters.get(\"collation\"),\n        }\n\n    def convert_empty_strings(self, value, expression, connection):\n        if (not value) and isinstance(value, str):\n            return None\n        return value\n\n    def get_db_converters(self, connection):\n        converters = super().get_db_converters(connection)\n        if connection.features.interprets_empty_strings_as_nulls:\n            converters += [self.convert_empty_strings]\n        return converters\n\n    def get_col(self, alias, output_field=None):\n        if output_field is None:\n            output_field = self.target_field\n            while isinstance(output_field, ForeignKey):\n                output_field = output_field.target_field\n                if output_field is self:\n                    raise ValueError(\"Cannot resolve output_field.\")\n        return super().get_col(alias, output_field)\n\n\nclass OneToOneField(ForeignKey):\n    \"\"\"\n    A OneToOneField is essentially the same as a ForeignKey, with the exception\n    that it always carries a \"unique\" constraint with it and the reverse\n    relation always returns the object pointed to (since there will only ever\n    be one), rather than returning a list.\n    \"\"\"\n\n    # Field flags\n    many_to_many = False\n    many_to_one = False\n    one_to_many = False\n    one_to_one = True\n\n    related_accessor_class = ReverseOneToOneDescriptor\n    forward_related_accessor_class = ForwardOneToOneDescriptor\n    rel_class = OneToOneRel\n\n    description = _(\"One-to-one relationship\")\n\n    def __init__(self, to, on_delete, to_field=None, **kwargs):\n        kwargs[\"unique\"] = True\n        super().__init__(to, on_delete, to_field=to_field, **kwargs)\n\n    def deconstruct(self):\n        name, path, args, kwargs = super().deconstruct()\n        if \"unique\" in kwargs:\n            del kwargs[\"unique\"]\n        return name, path, args, kwargs\n\n    def formfield(self, **kwargs):\n        if self.remote_field.parent_link:\n            return None\n        return super().formfield(**kwargs)\n\n    def save_form_data(self, instance, data):\n        if isinstance(data, self.remote_field.model):\n            setattr(instance, self.name, data)\n        else:\n            setattr(instance, self.attname, data)\n            # Remote field object must be cleared otherwise Model.save()\n            # will reassign attname using the related object pk.\n            if data is None:\n                setattr(instance, self.name, data)\n\n    def _check_unique(self, **kwargs):\n        # Override ForeignKey since check isn't applicable here.\n        return []\n\n\ndef create_many_to_many_intermediary_model(field, klass):\n    from django.db import models\n\n    def set_managed(model, related, through):\n        through._meta.managed = model._meta.managed or related._meta.managed\n\n    to_model = resolve_relation(klass, field.remote_field.model)\n    name = \"%s_%s\" % (klass._meta.object_name, field.name)\n    lazy_related_operation(set_managed, klass, to_model, name)\n\n    to = make_model_tuple(to_model)[1]\n    from_ = klass._meta.model_name\n    if to == from_:\n        to = \"to_%s\" % to\n        from_ = \"from_%s\" % from_\n\n    meta = type(\n        \"Meta\",\n        (),\n        {\n            \"db_table\": field._get_m2m_db_table(klass._meta),\n            \"auto_created\": klass,\n            \"app_label\": klass._meta.app_label,\n            \"db_tablespace\": klass._meta.db_tablespace,\n            \"unique_together\": (from_, to),\n            \"verbose_name\": _(\"%(from)s-%(to)s relationship\")\n            % {\"from\": from_, \"to\": to},\n            \"verbose_name_plural\": _(\"%(from)s-%(to)s relationships\")\n            % {\"from\": from_, \"to\": to},\n            \"apps\": field.model._meta.apps,\n        },\n    )\n    # Construct and return the new class.\n    return type(\n        name,\n        (models.Model,),\n        {\n            \"Meta\": meta,\n            \"__module__\": klass.__module__,\n            from_: models.ForeignKey(\n                klass,\n                related_name=\"%s+\" % name,\n                db_tablespace=field.db_tablespace,\n                db_constraint=field.remote_field.db_constraint,\n                on_delete=CASCADE,\n            ),\n            to: models.ForeignKey(\n                to_model,\n                related_name=\"%s+\" % name,\n                db_tablespace=field.db_tablespace,\n                db_constraint=field.remote_field.db_constraint,\n                on_delete=CASCADE,\n            ),\n        },\n    )\n\n\nclass ManyToManyField(RelatedField):\n    \"\"\"\n    Provide a many-to-many relation by using an intermediary model that\n    holds two ForeignKey fields pointed at the two sides of the relation.\n\n    Unless a ``through`` model was provided, ManyToManyField will use the\n    create_many_to_many_intermediary_model factory to automatically generate\n    the intermediary model.\n    \"\"\"\n\n    # Field flags\n    many_to_many = True\n    many_to_one = False\n    one_to_many = False\n    one_to_one = False\n\n    rel_class = ManyToManyRel\n\n    description = _(\"Many-to-many relationship\")\n\n    def __init__(\n        self,\n        to,\n        related_name=None,\n        related_query_name=None,\n        limit_choices_to=None,\n        symmetrical=None,\n        through=None,\n        through_fields=None,\n        db_constraint=True,\n        db_table=None,\n        swappable=True,\n        **kwargs,\n    ):\n        try:\n            to._meta\n        except AttributeError:\n            if not isinstance(to, str):\n                raise TypeError(\n                    \"%s(%r) is invalid. First parameter to ManyToManyField \"\n                    \"must be either a model, a model name, or the string %r\"\n                    % (\n                        self.__class__.__name__,\n                        to,\n                        RECURSIVE_RELATIONSHIP_CONSTANT,\n                    )\n                )\n\n        if symmetrical is None:\n            symmetrical = to == RECURSIVE_RELATIONSHIP_CONSTANT\n\n        if through is not None and db_table is not None:\n            raise ValueError(\n                \"Cannot specify a db_table if an intermediary model is used.\"\n            )\n\n        kwargs[\"rel\"] = self.rel_class(\n            self,\n            to,\n            related_name=related_name,\n            related_query_name=related_query_name,\n            limit_choices_to=limit_choices_to,\n            symmetrical=symmetrical,\n            through=through,\n            through_fields=through_fields,\n            db_constraint=db_constraint,\n        )\n        self.has_null_arg = \"null\" in kwargs\n\n        super().__init__(\n            related_name=related_name,\n            related_query_name=related_query_name,\n            limit_choices_to=limit_choices_to,\n            **kwargs,\n        )\n\n        self.db_table = db_table\n        self.swappable = swappable\n\n    def check(self, **kwargs):\n        return [\n            *super().check(**kwargs),\n            *self._check_unique(**kwargs),\n            *self._check_relationship_model(**kwargs),\n            *self._check_ignored_options(**kwargs),\n            *self._check_table_uniqueness(**kwargs),\n        ]\n\n    def _check_unique(self, **kwargs):\n        if self.unique:\n            return [\n                checks.Error(\n                    \"ManyToManyFields cannot be unique.\",\n                    obj=self,\n                    id=\"fields.E330\",\n                )\n            ]\n        return []\n\n    def _check_ignored_options(self, **kwargs):\n        warnings = []\n\n        if self.has_null_arg:\n            warnings.append(\n                checks.Warning(\n                    \"null has no effect on ManyToManyField.\",\n                    obj=self,\n                    id=\"fields.W340\",\n                )\n            )\n\n        if self._validators:\n            warnings.append(\n                checks.Warning(\n                    \"ManyToManyField does not support validators.\",\n                    obj=self,\n                    id=\"fields.W341\",\n                )\n            )\n        if self.remote_field.symmetrical and self._related_name:\n            warnings.append(\n                checks.Warning(\n                    \"related_name has no effect on ManyToManyField \"\n                    'with a symmetrical relationship, e.g. to \"self\".',\n                    obj=self,\n                    id=\"fields.W345\",\n                )\n            )\n        if self.db_comment:\n            warnings.append(\n                checks.Warning(\n                    \"db_comment has no effect on ManyToManyField.\",\n                    obj=self,\n                    id=\"fields.W346\",\n                )\n            )\n\n        return warnings\n\n    def _check_relationship_model(self, from_model=None, **kwargs):\n        if hasattr(self.remote_field.through, \"_meta\"):\n            qualified_model_name = \"%s.%s\" % (\n                self.remote_field.through._meta.app_label,\n                self.remote_field.through.__name__,\n            )\n        else:\n            qualified_model_name = self.remote_field.through\n\n        errors = []\n\n        if self.remote_field.through not in self.opts.apps.get_models(\n            include_auto_created=True\n        ):\n            # The relationship model is not installed.\n            errors.append(\n                checks.Error(\n                    \"Field specifies a many-to-many relation through model \"\n                    \"'%s', which has not been installed.\" % qualified_model_name,\n                    obj=self,\n                    id=\"fields.E331\",\n                )\n            )\n\n        else:\n            assert from_model is not None, (\n                \"ManyToManyField with intermediate \"\n                \"tables cannot be checked if you don't pass the model \"\n                \"where the field is attached to.\"\n            )\n            # Set some useful local variables\n            to_model = resolve_relation(from_model, self.remote_field.model)\n            from_model_name = from_model._meta.object_name\n            if isinstance(to_model, str):\n                to_model_name = to_model\n            else:\n                to_model_name = to_model._meta.object_name\n            relationship_model_name = self.remote_field.through._meta.object_name\n            self_referential = from_model == to_model\n            # Count foreign keys in intermediate model\n            if self_referential:\n                seen_self = sum(\n                    from_model == getattr(field.remote_field, \"model\", None)\n                    for field in self.remote_field.through._meta.fields\n                )\n\n                if seen_self > 2 and not self.remote_field.through_fields:\n                    errors.append(\n                        checks.Error(\n                            \"The model is used as an intermediate model by \"\n                            \"'%s', but it has more than two foreign keys \"\n                            \"to '%s', which is ambiguous. You must specify \"\n                            \"which two foreign keys Django should use via the \"\n                            \"through_fields keyword argument.\"\n                            % (self, from_model_name),\n                            hint=(\n                                \"Use through_fields to specify which two foreign keys \"\n                                \"Django should use.\"\n                            ),\n                            obj=self.remote_field.through,\n                            id=\"fields.E333\",\n                        )\n                    )\n\n            else:\n                # Count foreign keys in relationship model\n                seen_from = sum(\n                    from_model == getattr(field.remote_field, \"model\", None)\n                    for field in self.remote_field.through._meta.fields\n                )\n                seen_to = sum(\n                    to_model == getattr(field.remote_field, \"model\", None)\n                    for field in self.remote_field.through._meta.fields\n                )\n\n                if seen_from > 1 and not self.remote_field.through_fields:\n                    errors.append(\n                        checks.Error(\n                            (\n                                \"The model is used as an intermediate model by \"\n                                \"'%s', but it has more than one foreign key \"\n                                \"from '%s', which is ambiguous. You must specify \"\n                                \"which foreign key Django should use via the \"\n                                \"through_fields keyword argument.\"\n                            )\n                            % (self, from_model_name),\n                            hint=(\n                                \"If you want to create a recursive relationship, \"\n                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                            )\n                            % (\n                                RECURSIVE_RELATIONSHIP_CONSTANT,\n                                relationship_model_name,\n                            ),\n                            obj=self,\n                            id=\"fields.E334\",\n                        )\n                    )\n\n                if seen_to > 1 and not self.remote_field.through_fields:\n                    errors.append(\n                        checks.Error(\n                            \"The model is used as an intermediate model by \"\n                            \"'%s', but it has more than one foreign key \"\n                            \"to '%s', which is ambiguous. You must specify \"\n                            \"which foreign key Django should use via the \"\n                            \"through_fields keyword argument.\" % (self, to_model_name),\n                            hint=(\n                                \"If you want to create a recursive relationship, \"\n                                'use ManyToManyField(\"%s\", through=\"%s\").'\n                            )\n                            % (\n                                RECURSIVE_RELATIONSHIP_CONSTANT,\n                                relationship_model_name,\n                            ),\n                            obj=self,\n                            id=\"fields.E335\",\n                        )\n                    )\n\n                if seen_from == 0 or seen_to == 0:\n                    errors.append(\n                        checks.Error(\n                            \"The model is used as an intermediate model by \"\n                            \"'%s', but it does not have a foreign key to '%s' or '%s'.\"\n                            % (self, from_model_name, to_model_name),\n                            obj=self.remote_field.through,\n                            id=\"fields.E336\",\n                        )\n                    )\n\n        # Validate `through_fields`.\n        if self.remote_field.through_fields is not None:\n            # Validate that we're given an iterable of at least two items\n            # and that none of them is \"falsy\".\n            if not (\n                len(self.remote_field.through_fields) >= 2\n                and self.remote_field.through_fields[0]\n                and self.remote_field.through_fields[1]\n            ):\n                errors.append(\n                    checks.Error(\n                        \"Field specifies 'through_fields' but does not provide \"\n                        \"the names of the two link fields that should be used \"\n                        \"for the relation through model '%s'.\" % qualified_model_name,\n                        hint=(\n                            \"Make sure you specify 'through_fields' as \"\n                            \"through_fields=('field1', 'field2')\"\n                        ),\n                        obj=self,\n                        id=\"fields.E337\",\n                    )\n                )\n\n            # Validate the given through fields -- they should be actual\n            # fields on the through model, and also be foreign keys to the\n            # expected models.\n            else:\n                assert from_model is not None, (\n                    \"ManyToManyField with intermediate \"\n                    \"tables cannot be checked if you don't pass the model \"\n                    \"where the field is attached to.\"\n                )\n\n                source, through, target = (\n                    from_model,\n                    self.remote_field.through,\n                    self.remote_field.model,\n                )\n                source_field_name, target_field_name = self.remote_field.through_fields[\n                    :2\n                ]\n\n                for field_name, related_model in (\n                    (source_field_name, source),\n                    (target_field_name, target),\n                ):\n                    possible_field_names = []\n                    for f in through._meta.fields:\n                        if (\n                            hasattr(f, \"remote_field\")\n                            and getattr(f.remote_field, \"model\", None) == related_model\n                        ):\n                            possible_field_names.append(f.name)\n                    if possible_field_names:\n                        hint = (\n                            \"Did you mean one of the following foreign keys to '%s': \"\n                            \"%s?\"\n                            % (\n                                related_model._meta.object_name,\n                                \", \".join(possible_field_names),\n                            )\n                        )\n                    else:\n                        hint = None\n\n                    try:\n                        field = through._meta.get_field(field_name)\n                    except exceptions.FieldDoesNotExist:\n                        errors.append(\n                            checks.Error(\n                                \"The intermediary model '%s' has no field '%s'.\"\n                                % (qualified_model_name, field_name),\n                                hint=hint,\n                                obj=self,\n                                id=\"fields.E338\",\n                            )\n                        )\n                    else:\n                        if not (\n                            hasattr(field, \"remote_field\")\n                            and getattr(field.remote_field, \"model\", None)\n                            == related_model\n                        ):\n                            errors.append(\n                                checks.Error(\n                                    \"'%s.%s' is not a foreign key to '%s'.\"\n                                    % (\n                                        through._meta.object_name,\n                                        field_name,\n                                        related_model._meta.object_name,\n                                    ),\n                                    hint=hint,\n                                    obj=self,\n                                    id=\"fields.E339\",\n                                )\n                            )\n\n        return errors\n\n    def _check_table_uniqueness(self, **kwargs):\n        if (\n            isinstance(self.remote_field.through, str)\n            or not self.remote_field.through._meta.managed\n        ):\n            return []\n        registered_tables = {\n            model._meta.db_table: model\n            for model in self.opts.apps.get_models(include_auto_created=True)\n            if model != self.remote_field.through and model._meta.managed\n        }\n        m2m_db_table = self.m2m_db_table()\n        model = registered_tables.get(m2m_db_table)\n        # The second condition allows multiple m2m relations on a model if\n        # some point to a through model that proxies another through model.\n        if (\n            model\n            and model._meta.concrete_model\n            != self.remote_field.through._meta.concrete_model\n        ):\n            if model._meta.auto_created:\n\n                def _get_field_name(model):\n                    for field in model._meta.auto_created._meta.many_to_many:\n                        if field.remote_field.through is model:\n                            return field.name\n\n                opts = model._meta.auto_created._meta\n                clashing_obj = \"%s.%s\" % (opts.label, _get_field_name(model))\n            else:\n                clashing_obj = model._meta.label\n            if settings.DATABASE_ROUTERS:\n                error_class, error_id = checks.Warning, \"fields.W344\"\n                error_hint = (\n                    \"You have configured settings.DATABASE_ROUTERS. Verify \"\n                    \"that the table of %r is correctly routed to a separate \"\n                    \"database.\" % clashing_obj\n                )\n            else:\n                error_class, error_id = checks.Error, \"fields.E340\"\n                error_hint = None\n            return [\n                error_class(\n                    \"The field's intermediary table '%s' clashes with the \"\n                    \"table name of '%s'.\" % (m2m_db_table, clashing_obj),\n                    obj=self,\n                    hint=error_hint,\n                    id=error_id,\n                )\n            ]\n        return []\n\n    def deconstruct(self):\n        name, path, args, kwargs = super().deconstruct()\n        # Handle the simpler arguments.\n        if self.db_table is not None:\n            kwargs[\"db_table\"] = self.db_table\n        if self.remote_field.db_constraint is not True:\n            kwargs[\"db_constraint\"] = self.remote_field.db_constraint\n        # Lowercase model names as they should be treated as case-insensitive.\n        if isinstance(self.remote_field.model, str):\n            if \".\" in self.remote_field.model:\n                app_label, model_name = self.remote_field.model.split(\".\")\n                kwargs[\"to\"] = \"%s.%s\" % (app_label, model_name.lower())\n            else:\n                kwargs[\"to\"] = self.remote_field.model.lower()\n        else:\n            kwargs[\"to\"] = self.remote_field.model._meta.label_lower\n        if getattr(self.remote_field, \"through\", None) is not None:\n            if isinstance(self.remote_field.through, str):\n                kwargs[\"through\"] = self.remote_field.through\n            elif not self.remote_field.through._meta.auto_created:\n                kwargs[\"through\"] = self.remote_field.through._meta.label\n        # If swappable is True, then see if we're actually pointing to the target\n        # of a swap.\n        swappable_setting = self.swappable_setting\n        if swappable_setting is not None:\n            # If it's already a settings reference, error.\n            if hasattr(kwargs[\"to\"], \"setting_name\"):\n                if kwargs[\"to\"].setting_name != swappable_setting:\n                    raise ValueError(\n                        \"Cannot deconstruct a ManyToManyField pointing to a \"\n                        \"model that is swapped in place of more than one model \"\n                        \"(%s and %s)\" % (kwargs[\"to\"].setting_name, swappable_setting)\n                    )\n\n            kwargs[\"to\"] = SettingsReference(\n                kwargs[\"to\"],\n                swappable_setting,\n            )\n        return name, path, args, kwargs\n\n    def _get_path_info(self, direct=False, filtered_relation=None):\n        \"\"\"Called by both direct and indirect m2m traversal.\"\"\"\n        int_model = self.remote_field.through\n        linkfield1 = int_model._meta.get_field(self.m2m_field_name())\n        linkfield2 = int_model._meta.get_field(self.m2m_reverse_field_name())\n        if direct:\n            join1infos = linkfield1.reverse_path_infos\n            if filtered_relation:\n                join2infos = linkfield2.get_path_info(filtered_relation)\n            else:\n                join2infos = linkfield2.path_infos\n        else:\n            join1infos = linkfield2.reverse_path_infos\n            if filtered_relation:\n                join2infos = linkfield1.get_path_info(filtered_relation)\n            else:\n                join2infos = linkfield1.path_infos\n        # Get join infos between the last model of join 1 and the first model\n        # of join 2. Assume the only reason these may differ is due to model\n        # inheritance.\n        join1_final = join1infos[-1].to_opts\n        join2_initial = join2infos[0].from_opts\n        if join1_final is join2_initial:\n            intermediate_infos = []\n        elif issubclass(join1_final.model, join2_initial.model):\n            intermediate_infos = join1_final.get_path_to_parent(join2_initial.model)\n        else:\n            intermediate_infos = join2_initial.get_path_from_parent(join1_final.model)\n\n        return [*join1infos, *intermediate_infos, *join2infos]\n\n    def get_path_info(self, filtered_relation=None):\n        return self._get_path_info(direct=True, filtered_relation=filtered_relation)\n\n    @cached_property\n    def path_infos(self):\n        return self.get_path_info()\n\n    def get_reverse_path_info(self, filtered_relation=None):\n        return self._get_path_info(direct=False, filtered_relation=filtered_relation)\n\n    @cached_property\n    def reverse_path_infos(self):\n        return self.get_reverse_path_info()\n\n    def _get_m2m_db_table(self, opts):\n        \"\"\"\n        Function that can be curried to provide the m2m table name for this\n        relation.\n        \"\"\"\n        if self.remote_field.through is not None:\n            return self.remote_field.through._meta.db_table\n        elif self.db_table:\n            return self.db_table\n        else:\n            m2m_table_name = \"%s_%s\" % (utils.strip_quotes(opts.db_table), self.name)\n            return utils.truncate_name(m2m_table_name, connection.ops.max_name_length())\n\n    def _get_m2m_attr(self, related, attr):\n        \"\"\"\n        Function that can be curried to provide the source accessor or DB\n        column name for the m2m table.\n        \"\"\"\n        cache_attr = \"_m2m_%s_cache\" % attr\n        if hasattr(self, cache_attr):\n            return getattr(self, cache_attr)\n        if self.remote_field.through_fields is not None:\n            link_field_name = self.remote_field.through_fields[0]\n        else:\n            link_field_name = None\n        for f in self.remote_field.through._meta.fields:\n            if (\n                f.is_relation\n                and f.remote_field.model == related.related_model\n                and (link_field_name is None or link_field_name == f.name)\n            ):\n                setattr(self, cache_attr, getattr(f, attr))\n                return getattr(self, cache_attr)\n\n    def _get_m2m_reverse_attr(self, related, attr):\n        \"\"\"\n        Function that can be curried to provide the related accessor or DB\n        column name for the m2m table.\n        \"\"\"\n        cache_attr = \"_m2m_reverse_%s_cache\" % attr\n        if hasattr(self, cache_attr):\n            return getattr(self, cache_attr)\n        found = False\n        if self.remote_field.through_fields is not None:\n            link_field_name = self.remote_field.through_fields[1]\n        else:\n            link_field_name = None\n        for f in self.remote_field.through._meta.fields:\n            if f.is_relation and f.remote_field.model == related.model:\n                if link_field_name is None and related.related_model == related.model:\n                    # If this is an m2m-intermediate to self,\n                    # the first foreign key you find will be\n                    # the source column. Keep searching for\n                    # the second foreign key.\n                    if found:\n                        setattr(self, cache_attr, getattr(f, attr))\n                        break\n                    else:\n                        found = True\n                elif link_field_name is None or link_field_name == f.name:\n                    setattr(self, cache_attr, getattr(f, attr))\n                    break\n        return getattr(self, cache_attr)\n\n    def contribute_to_class(self, cls, name, **kwargs):\n        # To support multiple relations to self, it's useful to have a non-None\n        # related name on symmetrical relations for internal reasons. The\n        # concept doesn't make a lot of sense externally (\"you want me to\n        # specify *what* on my non-reversible relation?!\"), so we set it up\n        # automatically. The funky name reduces the chance of an accidental\n        # clash.\n        if self.remote_field.symmetrical and (\n            self.remote_field.model == RECURSIVE_RELATIONSHIP_CONSTANT\n            or self.remote_field.model == cls._meta.object_name\n        ):\n            self.remote_field.related_name = \"%s_rel_+\" % name\n        elif self.remote_field.is_hidden():\n            # If the backwards relation is disabled, replace the original\n            # related_name with one generated from the m2m field name. Django\n            # still uses backwards relations internally and we need to avoid\n            # clashes between multiple m2m fields with related_name == '+'.\n            self.remote_field.related_name = \"_%s_%s_%s_+\" % (\n                cls._meta.app_label,\n                cls.__name__.lower(),\n                name,\n            )\n\n        super().contribute_to_class(cls, name, **kwargs)\n\n        # The intermediate m2m model is not auto created if:\n        #  1) There is a manually specified intermediate, or\n        #  2) The class owning the m2m field is abstract.\n        #  3) The class owning the m2m field has been swapped out.\n        if not cls._meta.abstract:\n            if self.remote_field.through:\n\n                def resolve_through_model(_, model, field):\n                    field.remote_field.through = model\n\n                lazy_related_operation(\n                    resolve_through_model, cls, self.remote_field.through, field=self\n                )\n            elif not cls._meta.swapped:\n                self.remote_field.through = create_many_to_many_intermediary_model(\n                    self, cls\n                )\n\n        # Add the descriptor for the m2m relation.\n        setattr(cls, self.name, ManyToManyDescriptor(self.remote_field, reverse=False))\n\n        # Set up the accessor for the m2m table name for the relation.\n        self.m2m_db_table = partial(self._get_m2m_db_table, cls._meta)\n\n    def contribute_to_related_class(self, cls, related):\n        # Internal M2Ms (i.e., those with a related name ending with '+')\n        # and swapped models don't get a related descriptor.\n        if (\n            not self.remote_field.is_hidden()\n            and not related.related_model._meta.swapped\n        ):\n            setattr(\n                cls,\n                related.get_accessor_name(),\n                ManyToManyDescriptor(self.remote_field, reverse=True),\n            )\n\n        # Set up the accessors for the column names on the m2m table.\n        self.m2m_column_name = partial(self._get_m2m_attr, related, \"column\")\n        self.m2m_reverse_name = partial(self._get_m2m_reverse_attr, related, \"column\")\n\n        self.m2m_field_name = partial(self._get_m2m_attr, related, \"name\")\n        self.m2m_reverse_field_name = partial(\n            self._get_m2m_reverse_attr, related, \"name\"\n        )\n\n        get_m2m_rel = partial(self._get_m2m_attr, related, \"remote_field\")\n        self.m2m_target_field_name = lambda: get_m2m_rel().field_name\n        get_m2m_reverse_rel = partial(\n            self._get_m2m_reverse_attr, related, \"remote_field\"\n        )\n        self.m2m_reverse_target_field_name = lambda: get_m2m_reverse_rel().field_name\n\n    def set_attributes_from_rel(self):\n        pass\n\n    def value_from_object(self, obj):\n        return [] if obj.pk is None else list(getattr(obj, self.attname).all())\n\n    def save_form_data(self, instance, data):\n        getattr(instance, self.attname).set(data)\n\n    def formfield(self, *, using=None, **kwargs):\n        defaults = {\n            \"form_class\": forms.ModelMultipleChoiceField,\n            \"queryset\": self.remote_field.model._default_manager.using(using),\n            **kwargs,\n        }\n        # If initial is passed in, it's a list of related objects, but the\n        # MultipleChoiceField takes a list of IDs.\n        if defaults.get(\"initial\") is not None:\n            initial = defaults[\"initial\"]\n            if callable(initial):\n                initial = initial()\n            defaults[\"initial\"] = [i.pk for i in initial]\n        return super().formfield(**defaults)\n\n    def db_check(self, connection):\n        return None\n\n    def db_type(self, connection):\n        # A ManyToManyField is not represented by a single column,\n        # so return None.\n        return None\n\n    def db_parameters(self, connection):\n        return {\"type\": None, \"check\": None}\n</file>\n<file path=\"/testbed/django/db/models/query.py\">\n\"\"\"\nThe main QuerySet implementation. This provides the public API for the ORM.\n\"\"\"\n\nimport copy\nimport operator\nimport warnings\nfrom itertools import chain, islice\n\nfrom asgiref.sync import sync_to_async\n\nimport django\nfrom django.conf import settings\nfrom django.core import exceptions\nfrom django.db import (\n    DJANGO_VERSION_PICKLE_KEY,\n    IntegrityError,\n    NotSupportedError,\n    connections,\n    router,\n    transaction,\n)\nfrom django.db.models import AutoField, DateField, DateTimeField, Field, sql\nfrom django.db.models.constants import LOOKUP_SEP, OnConflict\nfrom django.db.models.deletion import Collector\nfrom django.db.models.expressions import Case, F, Value, When\nfrom django.db.models.functions import Cast, Trunc\nfrom django.db.models.query_utils import FilteredRelation, Q\nfrom django.db.models.sql.constants import CURSOR, GET_ITERATOR_CHUNK_SIZE\nfrom django.db.models.utils import (\n    AltersData,\n    create_namedtuple_class,\n    resolve_callables,\n)\nfrom django.utils import timezone\nfrom django.utils.functional import cached_property, partition\n\n# The maximum number of results to fetch in a get() query.\nMAX_GET_RESULTS = 21\n\n# The maximum number of items to display in a QuerySet.__repr__\nREPR_OUTPUT_SIZE = 20\n\n\nclass BaseIterable:\n    def __init__(\n        self, queryset, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE\n    ):\n        self.queryset = queryset\n        self.chunked_fetch = chunked_fetch\n        self.chunk_size = chunk_size\n\n    async def _async_generator(self):\n        # Generators don't actually start running until the first time you call\n        # next() on them, so make the generator object in the async thread and\n        # then repeatedly dispatch to it in a sync thread.\n        sync_generator = self.__iter__()\n\n        def next_slice(gen):\n            return list(islice(gen, self.chunk_size))\n\n        while True:\n            chunk = await sync_to_async(next_slice)(sync_generator)\n            for item in chunk:\n                yield item\n            if len(chunk) < self.chunk_size:\n                break\n\n    # __aiter__() is a *synchronous* method that has to then return an\n    # *asynchronous* iterator/generator. Thus, nest an async generator inside\n    # it.\n    # This is a generic iterable converter for now, and is going to suffer a\n    # performance penalty on large sets of items due to the cost of crossing\n    # over the sync barrier for each chunk. Custom __aiter__() methods should\n    # be added to each Iterable subclass, but that needs some work in the\n    # Compiler first.\n    def __aiter__(self):\n        return self._async_generator()\n\n\nclass ModelIterable(BaseIterable):\n    \"\"\"Iterable that yields a model instance for each row.\"\"\"\n\n    def __iter__(self):\n        queryset = self.queryset\n        db = queryset.db\n        compiler = queryset.query.get_compiler(using=db)\n        # Execute the query. This will also fill compiler.select, klass_info,\n        # and annotations.\n        results = compiler.execute_sql(\n            chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n        )\n        select, klass_info, annotation_col_map = (\n            compiler.select,\n            compiler.klass_info,\n            compiler.annotation_col_map,\n        )\n        model_cls = klass_info[\"model\"]\n        select_fields = klass_info[\"select_fields\"]\n        model_fields_start, model_fields_end = select_fields[0], select_fields[-1] + 1\n        init_list = [\n            f[0].target.attname for f in select[model_fields_start:model_fields_end]\n        ]\n        related_populators = get_related_populators(klass_info, select, db)\n        known_related_objects = [\n            (\n                field,\n                related_objs,\n                operator.attrgetter(\n                    *[\n                        field.attname\n                        if from_field == \"self\"\n                        else queryset.model._meta.get_field(from_field).attname\n                        for from_field in field.from_fields\n                    ]\n                ),\n            )\n            for field, related_objs in queryset._known_related_objects.items()\n        ]\n        for row in compiler.results_iter(results):\n            obj = model_cls.from_db(\n                db, init_list, row[model_fields_start:model_fields_end]\n            )\n            for rel_populator in related_populators:\n                rel_populator.populate(row, obj)\n            if annotation_col_map:\n                for attr_name, col_pos in annotation_col_map.items():\n                    setattr(obj, attr_name, row[col_pos])\n\n            # Add the known related objects to the model.\n            for field, rel_objs, rel_getter in known_related_objects:\n                # Avoid overwriting objects loaded by, e.g., select_related().\n                if field.is_cached(obj):\n                    continue\n                rel_obj_id = rel_getter(obj)\n                try:\n                    rel_obj = rel_objs[rel_obj_id]\n                except KeyError:\n                    pass  # May happen in qs1 | qs2 scenarios.\n                else:\n                    setattr(obj, field.name, rel_obj)\n\n            yield obj\n\n\nclass RawModelIterable(BaseIterable):\n    \"\"\"\n    Iterable that yields a model instance for each row from a raw queryset.\n    \"\"\"\n\n    def __iter__(self):\n        # Cache some things for performance reasons outside the loop.\n        db = self.queryset.db\n        query = self.queryset.query\n        connection = connections[db]\n        compiler = connection.ops.compiler(\"SQLCompiler\")(query, connection, db)\n        query_iterator = iter(query)\n\n        try:\n            (\n                model_init_names,\n                model_init_pos,\n                annotation_fields,\n            ) = self.queryset.resolve_model_init_order()\n            model_cls = self.queryset.model\n            if model_cls._meta.pk.attname not in model_init_names:\n                raise exceptions.FieldDoesNotExist(\n                    \"Raw query must include the primary key\"\n                )\n            fields = [self.queryset.model_fields.get(c) for c in self.queryset.columns]\n            converters = compiler.get_converters(\n                [f.get_col(f.model._meta.db_table) if f else None for f in fields]\n            )\n            if converters:\n                query_iterator = compiler.apply_converters(query_iterator, converters)\n            for values in query_iterator:\n                # Associate fields to values\n                model_init_values = [values[pos] for pos in model_init_pos]\n                instance = model_cls.from_db(db, model_init_names, model_init_values)\n                if annotation_fields:\n                    for column, pos in annotation_fields:\n                        setattr(instance, column, values[pos])\n                yield instance\n        finally:\n            # Done iterating the Query. If it has its own cursor, close it.\n            if hasattr(query, \"cursor\") and query.cursor:\n                query.cursor.close()\n\n\nclass ValuesIterable(BaseIterable):\n    \"\"\"\n    Iterable returned by QuerySet.values() that yields a dict for each row.\n    \"\"\"\n\n    def __iter__(self):\n        queryset = self.queryset\n        query = queryset.query\n        compiler = query.get_compiler(queryset.db)\n\n        # extra(select=...) cols are always at the start of the row.\n        names = [\n            *query.extra_select,\n            *query.values_select,\n            *query.annotation_select,\n        ]\n        indexes = range(len(names))\n        for row in compiler.results_iter(\n            chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n        ):\n            yield {names[i]: row[i] for i in indexes}\n\n\nclass ValuesListIterable(BaseIterable):\n    \"\"\"\n    Iterable returned by QuerySet.values_list(flat=False) that yields a tuple\n    for each row.\n    \"\"\"\n\n    def __iter__(self):\n        queryset = self.queryset\n        query = queryset.query\n        compiler = query.get_compiler(queryset.db)\n\n        if queryset._fields:\n            # extra(select=...) cols are always at the start of the row.\n            names = [\n                *query.extra_select,\n                *query.values_select,\n                *query.annotation_select,\n            ]\n            fields = [\n                *queryset._fields,\n                *(f for f in query.annotation_select if f not in queryset._fields),\n            ]\n            if fields != names:\n                # Reorder according to fields.\n                index_map = {name: idx for idx, name in enumerate(names)}\n                rowfactory = operator.itemgetter(*[index_map[f] for f in fields])\n                return map(\n                    rowfactory,\n                    compiler.results_iter(\n                        chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n                    ),\n                )\n        return compiler.results_iter(\n            tuple_expected=True,\n            chunked_fetch=self.chunked_fetch,\n            chunk_size=self.chunk_size,\n        )\n\n\nclass NamedValuesListIterable(ValuesListIterable):\n    \"\"\"\n    Iterable returned by QuerySet.values_list(named=True) that yields a\n    namedtuple for each row.\n    \"\"\"\n\n    def __iter__(self):\n        queryset = self.queryset\n        if queryset._fields:\n            names = queryset._fields\n        else:\n            query = queryset.query\n            names = [\n                *query.extra_select,\n                *query.values_select,\n                *query.annotation_select,\n            ]\n        tuple_class = create_namedtuple_class(*names)\n        new = tuple.__new__\n        for row in super().__iter__():\n            yield new(tuple_class, row)\n\n\nclass FlatValuesListIterable(BaseIterable):\n    \"\"\"\n    Iterable returned by QuerySet.values_list(flat=True) that yields single\n    values.\n    \"\"\"\n\n    def __iter__(self):\n        queryset = self.queryset\n        compiler = queryset.query.get_compiler(queryset.db)\n        for row in compiler.results_iter(\n            chunked_fetch=self.chunked_fetch, chunk_size=self.chunk_size\n        ):\n            yield row[0]\n\n\nclass QuerySet(AltersData):\n    \"\"\"Represent a lazy database lookup for a set of objects.\"\"\"\n\n    def __init__(self, model=None, query=None, using=None, hints=None):\n        self.model = model\n        self._db = using\n        self._hints = hints or {}\n        self._query = query or sql.Query(self.model)\n        self._result_cache = None\n        self._sticky_filter = False\n        self._for_write = False\n        self._prefetch_related_lookups = ()\n        self._prefetch_done = False\n        self._known_related_objects = {}  # {rel_field: {pk: rel_obj}}\n        self._iterable_class = ModelIterable\n        self._fields = None\n        self._defer_next_filter = False\n        self._deferred_filter = None\n\n    @property\n    def query(self):\n        if self._deferred_filter:\n            negate, args, kwargs = self._deferred_filter\n            self._filter_or_exclude_inplace(negate, args, kwargs)\n            self._deferred_filter = None\n        return self._query\n\n    @query.setter\n    def query(self, value):\n        if value.values_select:\n            self._iterable_class = ValuesIterable\n        self._query = value\n\n    def as_manager(cls):\n        # Address the circular dependency between `Queryset` and `Manager`.\n        from django.db.models.manager import Manager\n\n        manager = Manager.from_queryset(cls)()\n        manager._built_with_as_manager = True\n        return manager\n\n    as_manager.queryset_only = True\n    as_manager = classmethod(as_manager)\n\n    ########################\n    # PYTHON MAGIC METHODS #\n    ########################\n\n    def __deepcopy__(self, memo):\n        \"\"\"Don't populate the QuerySet's cache.\"\"\"\n        obj = self.__class__()\n        for k, v in self.__dict__.items():\n            if k == \"_result_cache\":\n                obj.__dict__[k] = None\n            else:\n                obj.__dict__[k] = copy.deepcopy(v, memo)\n        return obj\n\n    def __getstate__(self):\n        # Force the cache to be fully populated.\n        self._fetch_all()\n        return {**self.__dict__, DJANGO_VERSION_PICKLE_KEY: django.__version__}\n\n    def __setstate__(self, state):\n        pickled_version = state.get(DJANGO_VERSION_PICKLE_KEY)\n        if pickled_version:\n            if pickled_version != django.__version__:\n                warnings.warn(\n                    \"Pickled queryset instance's Django version %s does not \"\n                    \"match the current version %s.\"\n                    % (pickled_version, django.__version__),\n                    RuntimeWarning,\n                    stacklevel=2,\n                )\n        else:\n            warnings.warn(\n                \"Pickled queryset instance's Django version is not specified.\",\n                RuntimeWarning,\n                stacklevel=2,\n            )\n        self.__dict__.update(state)\n\n    def __repr__(self):\n        data = list(self[: REPR_OUTPUT_SIZE + 1])\n        if len(data) > REPR_OUTPUT_SIZE:\n            data[-1] = \"...(remaining elements truncated)...\"\n        return \"<%s %r>\" % (self.__class__.__name__, data)\n\n    def __len__(self):\n        self._fetch_all()\n        return len(self._result_cache)\n\n    def __iter__(self):\n        \"\"\"\n        The queryset iterator protocol uses three nested iterators in the\n        default case:\n            1. sql.compiler.execute_sql()\n               - Returns 100 rows at time (constants.GET_ITERATOR_CHUNK_SIZE)\n                 using cursor.fetchmany(). This part is responsible for\n                 doing some column masking, and returning the rows in chunks.\n            2. sql.compiler.results_iter()\n               - Returns one row at time. At this point the rows are still just\n                 tuples. In some cases the return values are converted to\n                 Python values at this location.\n            3. self.iterator()\n               - Responsible for turning the rows into model objects.\n        \"\"\"\n        self._fetch_all()\n        return iter(self._result_cache)\n\n    def __aiter__(self):\n        # Remember, __aiter__ itself is synchronous, it's the thing it returns\n        # that is async!\n        async def generator():\n            await sync_to_async(self._fetch_all)()\n            for item in self._result_cache:\n                yield item\n\n        return generator()\n\n    def __bool__(self):\n        self._fetch_all()\n        return bool(self._result_cache)\n\n    def __getitem__(self, k):\n        \"\"\"Retrieve an item or slice from the set of results.\"\"\"\n        if not isinstance(k, (int, slice)):\n            raise TypeError(\n                \"QuerySet indices must be integers or slices, not %s.\"\n                % type(k).__name__\n            )\n        if (isinstance(k, int) and k < 0) or (\n            isinstance(k, slice)\n            and (\n                (k.start is not None and k.start < 0)\n                or (k.stop is not None and k.stop < 0)\n            )\n        ):\n            raise ValueError(\"Negative indexing is not supported.\")\n\n        if self._result_cache is not None:\n            return self._result_cache[k]\n\n        if isinstance(k, slice):\n            qs = self._chain()\n            if k.start is not None:\n                start = int(k.start)\n            else:\n                start = None\n            if k.stop is not None:\n                stop = int(k.stop)\n            else:\n                stop = None\n            qs.query.set_limits(start, stop)\n            return list(qs)[:: k.step] if k.step else qs\n\n        qs = self._chain()\n        qs.query.set_limits(k, k + 1)\n        qs._fetch_all()\n        return qs._result_cache[0]\n\n    def __class_getitem__(cls, *args, **kwargs):\n        return cls\n\n    def __and__(self, other):\n        self._check_operator_queryset(other, \"&\")\n        self._merge_sanity_check(other)\n        if isinstance(other, EmptyQuerySet):\n            return other\n        if isinstance(self, EmptyQuerySet):\n            return self\n        combined = self._chain()\n        combined._merge_known_related_objects(other)\n        combined.query.combine(other.query, sql.AND)\n        return combined\n\n    def __or__(self, other):\n        self._check_operator_queryset(other, \"|\")\n        self._merge_sanity_check(other)\n        if isinstance(self, EmptyQuerySet):\n            return other\n        if isinstance(other, EmptyQuerySet):\n            return self\n        query = (\n            self\n            if self.query.can_filter()\n            else self.model._base_manager.filter(pk__in=self.values(\"pk\"))\n        )\n        combined = query._chain()\n        combined._merge_known_related_objects(other)\n        if not other.query.can_filter():\n            other = other.model._base_manager.filter(pk__in=other.values(\"pk\"))\n        combined.query.combine(other.query, sql.OR)\n        return combined\n\n    def __xor__(self, other):\n        self._check_operator_queryset(other, \"^\")\n        self._merge_sanity_check(other)\n        if isinstance(self, EmptyQuerySet):\n            return other\n        if isinstance(other, EmptyQuerySet):\n            return self\n        query = (\n            self\n            if self.query.can_filter()\n            else self.model._base_manager.filter(pk__in=self.values(\"pk\"))\n        )\n        combined = query._chain()\n        combined._merge_known_related_objects(other)\n        if not other.query.can_filter():\n            other = other.model._base_manager.filter(pk__in=other.values(\"pk\"))\n        combined.query.combine(other.query, sql.XOR)\n        return combined\n\n    ####################################\n    # METHODS THAT DO DATABASE QUERIES #\n    ####################################\n\n    def _iterator(self, use_chunked_fetch, chunk_size):\n        iterable = self._iterable_class(\n            self,\n            chunked_fetch=use_chunked_fetch,\n            chunk_size=chunk_size or 2000,\n        )\n        if not self._prefetch_related_lookups or chunk_size is None:\n            yield from iterable\n            return\n\n        iterator = iter(iterable)\n        while results := list(islice(iterator, chunk_size)):\n            prefetch_related_objects(results, *self._prefetch_related_lookups)\n            yield from results\n\n    def iterator(self, chunk_size=None):\n        \"\"\"\n        An iterator over the results from applying this QuerySet to the\n        database. chunk_size must be provided for QuerySets that prefetch\n        related objects. Otherwise, a default chunk_size of 2000 is supplied.\n        \"\"\"\n        if chunk_size is None:\n            if self._prefetch_related_lookups:\n                raise ValueError(\n                    \"chunk_size must be provided when using QuerySet.iterator() after \"\n                    \"prefetch_related().\"\n                )\n        elif chunk_size <= 0:\n            raise ValueError(\"Chunk size must be strictly positive.\")\n        use_chunked_fetch = not connections[self.db].settings_dict.get(\n            \"DISABLE_SERVER_SIDE_CURSORS\"\n        )\n        return self._iterator(use_chunked_fetch, chunk_size)\n\n    async def aiterator(self, chunk_size=2000):\n        \"\"\"\n        An asynchronous iterator over the results from applying this QuerySet\n        to the database.\n        \"\"\"\n        if self._prefetch_related_lookups:\n            raise NotSupportedError(\n                \"Using QuerySet.aiterator() after prefetch_related() is not supported.\"\n            )\n        if chunk_size <= 0:\n            raise ValueError(\"Chunk size must be strictly positive.\")\n        use_chunked_fetch = not connections[self.db].settings_dict.get(\n            \"DISABLE_SERVER_SIDE_CURSORS\"\n        )\n        async for item in self._iterable_class(\n            self, chunked_fetch=use_chunked_fetch, chunk_size=chunk_size\n        ):\n            yield item\n\n    def aggregate(self, *args, **kwargs):\n        \"\"\"\n        Return a dictionary containing the calculations (aggregation)\n        over the current queryset.\n\n        If args is present the expression is passed as a kwarg using\n        the Aggregate object's default alias.\n        \"\"\"\n        if self.query.distinct_fields:\n            raise NotImplementedError(\"aggregate() + distinct(fields) not implemented.\")\n        self._validate_values_are_expressions(\n            (*args, *kwargs.values()), method_name=\"aggregate\"\n        )\n        for arg in args:\n            # The default_alias property raises TypeError if default_alias\n            # can't be set automatically or AttributeError if it isn't an\n            # attribute.\n            try:\n                arg.default_alias\n            except (AttributeError, TypeError):\n                raise TypeError(\"Complex aggregates require an alias\")\n            kwargs[arg.default_alias] = arg\n\n        return self.query.chain().get_aggregation(self.db, kwargs)\n\n    async def aaggregate(self, *args, **kwargs):\n        return await sync_to_async(self.aggregate)(*args, **kwargs)\n\n    def count(self):\n        \"\"\"\n        Perform a SELECT COUNT() and return the number of records as an\n        integer.\n\n        If the QuerySet is already fully cached, return the length of the\n        cached results set to avoid multiple SELECT COUNT(*) calls.\n        \"\"\"\n        if self._result_cache is not None:\n            return len(self._result_cache)\n\n        return self.query.get_count(using=self.db)\n\n    async def acount(self):\n        return await sync_to_async(self.count)()\n\n    def get(self, *args, **kwargs):\n        \"\"\"\n        Perform the query and return a single object matching the given\n        keyword arguments.\n        \"\"\"\n        if self.query.combinator and (args or kwargs):\n            raise NotSupportedError(\n                \"Calling QuerySet.get(...) with filters after %s() is not \"\n                \"supported.\" % self.query.combinator\n            )\n        clone = self._chain() if self.query.combinator else self.filter(*args, **kwargs)\n        if self.query.can_filter() and not self.query.distinct_fields:\n            clone = clone.order_by()\n        limit = None\n        if (\n            not clone.query.select_for_update\n            or connections[clone.db].features.supports_select_for_update_with_limit\n        ):\n            limit = MAX_GET_RESULTS\n            clone.query.set_limits(high=limit)\n        num = len(clone)\n        if num == 1:\n            return clone._result_cache[0]\n        if not num:\n            raise self.model.DoesNotExist(\n                \"%s matching query does not exist.\" % self.model._meta.object_name\n            )\n        raise self.model.MultipleObjectsReturned(\n            \"get() returned more than one %s -- it returned %s!\"\n            % (\n                self.model._meta.object_name,\n                num if not limit or num < limit else \"more than %s\" % (limit - 1),\n            )\n        )\n\n    async def aget(self, *args, **kwargs):\n        return await sync_to_async(self.get)(*args, **kwargs)\n\n    def create(self, **kwargs):\n        \"\"\"\n        Create a new object with the given kwargs, saving it to the database\n        and returning the created object.\n        \"\"\"\n        obj = self.model(**kwargs)\n        self._for_write = True\n        obj.save(force_insert=True, using=self.db)\n        return obj\n\n    async def acreate(self, **kwargs):\n        return await sync_to_async(self.create)(**kwargs)\n\n    def _prepare_for_bulk_create(self, objs):\n        from django.db.models.expressions import DatabaseDefault\n\n        connection = connections[self.db]\n        for obj in objs:\n            if obj.pk is None:\n                # Populate new PK values.\n                obj.pk = obj._meta.pk.get_pk_value_on_save(obj)\n            if not connection.features.supports_default_keyword_in_bulk_insert:\n                for field in obj._meta.fields:\n                    value = getattr(obj, field.attname)\n                    if isinstance(value, DatabaseDefault):\n                        setattr(obj, field.attname, field.db_default)\n\n            obj._prepare_related_fields_for_save(operation_name=\"bulk_create\")\n\n    def _check_bulk_create_options(\n        self, ignore_conflicts, update_conflicts, update_fields, unique_fields\n    ):\n        if ignore_conflicts and update_conflicts:\n            raise ValueError(\n                \"ignore_conflicts and update_conflicts are mutually exclusive.\"\n            )\n        db_features = connections[self.db].features\n        if ignore_conflicts:\n            if not db_features.supports_ignore_conflicts:\n                raise NotSupportedError(\n                    \"This database backend does not support ignoring conflicts.\"\n                )\n            return OnConflict.IGNORE\n        elif update_conflicts:\n            if not db_features.supports_update_conflicts:\n                raise NotSupportedError(\n                    \"This database backend does not support updating conflicts.\"\n                )\n            if not update_fields:\n                raise ValueError(\n                    \"Fields that will be updated when a row insertion fails \"\n                    \"on conflicts must be provided.\"\n                )\n            if unique_fields and not db_features.supports_update_conflicts_with_target:\n                raise NotSupportedError(\n                    \"This database backend does not support updating \"\n                    \"conflicts with specifying unique fields that can trigger \"\n                    \"the upsert.\"\n                )\n            if not unique_fields and db_features.supports_update_conflicts_with_target:\n                raise ValueError(\n                    \"Unique fields that can trigger the upsert must be provided.\"\n                )\n            # Updating primary keys and non-concrete fields is forbidden.\n            if any(not f.concrete or f.many_to_many for f in update_fields):\n                raise ValueError(\n                    \"bulk_create() can only be used with concrete fields in \"\n                    \"update_fields.\"\n                )\n            if any(f.primary_key for f in update_fields):\n                raise ValueError(\n                    \"bulk_create() cannot be used with primary keys in \"\n                    \"update_fields.\"\n                )\n            if unique_fields:\n                if any(not f.concrete or f.many_to_many for f in unique_fields):\n                    raise ValueError(\n                        \"bulk_create() can only be used with concrete fields \"\n                        \"in unique_fields.\"\n                    )\n            return OnConflict.UPDATE\n        return None\n\n    def bulk_create(\n        self,\n        objs,\n        batch_size=None,\n        ignore_conflicts=False,\n        update_conflicts=False,\n        update_fields=None,\n        unique_fields=None,\n    ):\n        \"\"\"\n        Insert each of the instances into the database. Do *not* call\n        save() on each of the instances, do not send any pre/post_save\n        signals, and do not set the primary key attribute if it is an\n        autoincrement field (except if features.can_return_rows_from_bulk_insert=True).\n        Multi-table models are not supported.\n        \"\"\"\n        # When you bulk insert you don't get the primary keys back (if it's an\n        # autoincrement, except if can_return_rows_from_bulk_insert=True), so\n        # you can't insert into the child tables which references this. There\n        # are two workarounds:\n        # 1) This could be implemented if you didn't have an autoincrement pk\n        # 2) You could do it by doing O(n) normal inserts into the parent\n        #    tables to get the primary keys back and then doing a single bulk\n        #    insert into the childmost table.\n        # We currently set the primary keys on the objects when using\n        # PostgreSQL via the RETURNING ID clause. It should be possible for\n        # Oracle as well, but the semantics for extracting the primary keys is\n        # trickier so it's not done yet.\n        if batch_size is not None and batch_size <= 0:\n            raise ValueError(\"Batch size must be a positive integer.\")\n        # Check that the parents share the same concrete model with the our\n        # model to detect the inheritance pattern ConcreteGrandParent ->\n        # MultiTableParent -> ProxyChild. Simply checking self.model._meta.proxy\n        # would not identify that case as involving multiple tables.\n        for parent in self.model._meta.get_parent_list():\n            if parent._meta.concrete_model is not self.model._meta.concrete_model:\n                raise ValueError(\"Can't bulk create a multi-table inherited model\")\n        if not objs:\n            return objs\n        opts = self.model._meta\n        if unique_fields:\n            # Primary key is allowed in unique_fields.\n            unique_fields = [\n                self.model._meta.get_field(opts.pk.name if name == \"pk\" else name)\n                for name in unique_fields\n            ]\n        if update_fields:\n            update_fields = [self.model._meta.get_field(name) for name in update_fields]\n        on_conflict = self._check_bulk_create_options(\n            ignore_conflicts,\n            update_conflicts,\n            update_fields,\n            unique_fields,\n        )\n        self._for_write = True\n        fields = opts.concrete_fields\n        objs = list(objs)\n        self._prepare_for_bulk_create(objs)\n        with transaction.atomic(using=self.db, savepoint=False):\n            objs_with_pk, objs_without_pk = partition(lambda o: o.pk is None, objs)\n            if objs_with_pk:\n                returned_columns = self._batched_insert(\n                    objs_with_pk,\n                    fields,\n                    batch_size,\n                    on_conflict=on_conflict,\n                    update_fields=update_fields,\n                    unique_fields=unique_fields,\n                )\n                for obj_with_pk, results in zip(objs_with_pk, returned_columns):\n                    for result, field in zip(results, opts.db_returning_fields):\n                        if field != opts.pk:\n                            setattr(obj_with_pk, field.attname, result)\n                for obj_with_pk in objs_with_pk:\n                    obj_with_pk._state.adding = False\n                    obj_with_pk._state.db = self.db\n            if objs_without_pk:\n                fields = [f for f in fields if not isinstance(f, AutoField)]\n                returned_columns = self._batched_insert(\n                    objs_without_pk,\n                    fields,\n                    batch_size,\n                    on_conflict=on_conflict,\n                    update_fields=update_fields,\n                    unique_fields=unique_fields,\n                )\n                connection = connections[self.db]\n                if (\n                    connection.features.can_return_rows_from_bulk_insert\n                    and on_conflict is None\n                ):\n                    assert len(returned_columns) == len(objs_without_pk)\n                for obj_without_pk, results in zip(objs_without_pk, returned_columns):\n                    for result, field in zip(results, opts.db_returning_fields):\n                        setattr(obj_without_pk, field.attname, result)\n                    obj_without_pk._state.adding = False\n                    obj_without_pk._state.db = self.db\n\n        return objs\n\n    async def abulk_create(\n        self,\n        objs,\n        batch_size=None,\n        ignore_conflicts=False,\n        update_conflicts=False,\n        update_fields=None,\n        unique_fields=None,\n    ):\n        return await sync_to_async(self.bulk_create)(\n            objs=objs,\n            batch_size=batch_size,\n            ignore_conflicts=ignore_conflicts,\n            update_conflicts=update_conflicts,\n            update_fields=update_fields,\n            unique_fields=unique_fields,\n        )\n\n    def bulk_update(self, objs, fields, batch_size=None):\n        \"\"\"\n        Update the given fields in each of the given objects in the database.\n        \"\"\"\n        if batch_size is not None and batch_size <= 0:\n            raise ValueError(\"Batch size must be a positive integer.\")\n        if not fields:\n            raise ValueError(\"Field names must be given to bulk_update().\")\n        objs = tuple(objs)\n        if any(obj.pk is None for obj in objs):\n            raise ValueError(\"All bulk_update() objects must have a primary key set.\")\n        fields = [self.model._meta.get_field(name) for name in fields]\n        if any(not f.concrete or f.many_to_many for f in fields):\n            raise ValueError(\"bulk_update() can only be used with concrete fields.\")\n        if any(f.primary_key for f in fields):\n            raise ValueError(\"bulk_update() cannot be used with primary key fields.\")\n        if not objs:\n            return 0\n        for obj in objs:\n            obj._prepare_related_fields_for_save(\n                operation_name=\"bulk_update\", fields=fields\n            )\n        # PK is used twice in the resulting update query, once in the filter\n        # and once in the WHEN. Each field will also have one CAST.\n        self._for_write = True\n        connection = connections[self.db]\n        max_batch_size = connection.ops.bulk_batch_size([\"pk\", \"pk\"] + fields, objs)\n        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n        requires_casting = connection.features.requires_casted_case_in_updates\n        batches = (objs[i : i + batch_size] for i in range(0, len(objs), batch_size))\n        updates = []\n        for batch_objs in batches:\n            update_kwargs = {}\n            for field in fields:\n                when_statements = []\n                for obj in batch_objs:\n                    attr = getattr(obj, field.attname)\n                    if not hasattr(attr, \"resolve_expression\"):\n                        attr = Value(attr, output_field=field)\n                    when_statements.append(When(pk=obj.pk, then=attr))\n                case_statement = Case(*when_statements, output_field=field)\n                if requires_casting:\n                    case_statement = Cast(case_statement, output_field=field)\n                update_kwargs[field.attname] = case_statement\n            updates.append(([obj.pk for obj in batch_objs], update_kwargs))\n        rows_updated = 0\n        queryset = self.using(self.db)\n        with transaction.atomic(using=self.db, savepoint=False):\n            for pks, update_kwargs in updates:\n                rows_updated += queryset.filter(pk__in=pks).update(**update_kwargs)\n        return rows_updated\n\n    bulk_update.alters_data = True\n\n    async def abulk_update(self, objs, fields, batch_size=None):\n        return await sync_to_async(self.bulk_update)(\n            objs=objs,\n            fields=fields,\n            batch_size=batch_size,\n        )\n\n    abulk_update.alters_data = True\n\n    def get_or_create(self, defaults=None, **kwargs):\n        \"\"\"\n        Look up an object with the given kwargs, creating one if necessary.\n        Return a tuple of (object, created), where created is a boolean\n        specifying whether an object was created.\n        \"\"\"\n        # The get() needs to be targeted at the write database in order\n        # to avoid potential transaction consistency problems.\n        self._for_write = True\n        try:\n            return self.get(**kwargs), False\n        except self.model.DoesNotExist:\n            params = self._extract_model_params(defaults, **kwargs)\n            # Try to create an object using passed params.\n            try:\n                with transaction.atomic(using=self.db):\n                    params = dict(resolve_callables(params))\n                    return self.create(**params), True\n            except IntegrityError:\n                try:\n                    return self.get(**kwargs), False\n                except self.model.DoesNotExist:\n                    pass\n                raise\n\n    async def aget_or_create(self, defaults=None, **kwargs):\n        return await sync_to_async(self.get_or_create)(\n            defaults=defaults,\n            **kwargs,\n        )\n\n    def update_or_create(self, defaults=None, create_defaults=None, **kwargs):\n        \"\"\"\n        Look up an object with the given kwargs, updating one with defaults\n        if it exists, otherwise create a new one. Optionally, an object can\n        be created with different values than defaults by using\n        create_defaults.\n        Return a tuple (object, created), where created is a boolean\n        specifying whether an object was created.\n        \"\"\"\n        if create_defaults is None:\n            update_defaults = create_defaults = defaults or {}\n        else:\n            update_defaults = defaults or {}\n        self._for_write = True\n        with transaction.atomic(using=self.db):\n            # Lock the row so that a concurrent update is blocked until\n            # update_or_create() has performed its save.\n            obj, created = self.select_for_update().get_or_create(\n                create_defaults, **kwargs\n            )\n            if created:\n                return obj, created\n            for k, v in resolve_callables(update_defaults):\n                setattr(obj, k, v)\n\n            update_fields = set(update_defaults)\n            concrete_field_names = self.model._meta._non_pk_concrete_field_names\n            # update_fields does not support non-concrete fields.\n            if concrete_field_names.issuperset(update_fields):\n                # Add fields which are set on pre_save(), e.g. auto_now fields.\n                # This is to maintain backward compatibility as these fields\n                # are not updated unless explicitly specified in the\n                # update_fields list.\n                for field in self.model._meta.local_concrete_fields:\n                    if not (\n                        field.primary_key or field.__class__.pre_save is Field.pre_save\n                    ):\n                        update_fields.add(field.name)\n                        if field.name != field.attname:\n                            update_fields.add(field.attname)\n                obj.save(using=self.db, update_fields=update_fields)\n            else:\n                obj.save(using=self.db)\n        return obj, False\n\n    async def aupdate_or_create(self, defaults=None, create_defaults=None, **kwargs):\n        return await sync_to_async(self.update_or_create)(\n            defaults=defaults,\n            create_defaults=create_defaults,\n            **kwargs,\n        )\n\n    def _extract_model_params(self, defaults, **kwargs):\n        \"\"\"\n        Prepare `params` for creating a model instance based on the given\n        kwargs; for use by get_or_create().\n        \"\"\"\n        defaults = defaults or {}\n        params = {k: v for k, v in kwargs.items() if LOOKUP_SEP not in k}\n        params.update(defaults)\n        property_names = self.model._meta._property_names\n        invalid_params = []\n        for param in params:\n            try:\n                self.model._meta.get_field(param)\n            except exceptions.FieldDoesNotExist:\n                # It's okay to use a model's property if it has a setter.\n                if not (param in property_names and getattr(self.model, param).fset):\n                    invalid_params.append(param)\n        if invalid_params:\n            raise exceptions.FieldError(\n                \"Invalid field name(s) for model %s: '%s'.\"\n                % (\n                    self.model._meta.object_name,\n                    \"', '\".join(sorted(invalid_params)),\n                )\n            )\n        return params\n\n    def _earliest(self, *fields):\n        \"\"\"\n        Return the earliest object according to fields (if given) or by the\n        model's Meta.get_latest_by.\n        \"\"\"\n        if fields:\n            order_by = fields\n        else:\n            order_by = getattr(self.model._meta, \"get_latest_by\")\n            if order_by and not isinstance(order_by, (tuple, list)):\n                order_by = (order_by,)\n        if order_by is None:\n            raise ValueError(\n                \"earliest() and latest() require either fields as positional \"\n                \"arguments or 'get_latest_by' in the model's Meta.\"\n            )\n        obj = self._chain()\n        obj.query.set_limits(high=1)\n        obj.query.clear_ordering(force=True)\n        obj.query.add_ordering(*order_by)\n        return obj.get()\n\n    def earliest(self, *fields):\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot change a query once a slice has been taken.\")\n        return self._earliest(*fields)\n\n    async def aearliest(self, *fields):\n        return await sync_to_async(self.earliest)(*fields)\n\n    def latest(self, *fields):\n        \"\"\"\n        Return the latest object according to fields (if given) or by the\n        model's Meta.get_latest_by.\n        \"\"\"\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot change a query once a slice has been taken.\")\n        return self.reverse()._earliest(*fields)\n\n    async def alatest(self, *fields):\n        return await sync_to_async(self.latest)(*fields)\n\n    def first(self):\n        \"\"\"Return the first object of a query or None if no match is found.\"\"\"\n        if self.ordered:\n            queryset = self\n        else:\n            self._check_ordering_first_last_queryset_aggregation(method=\"first\")\n            queryset = self.order_by(\"pk\")\n        for obj in queryset[:1]:\n            return obj\n\n    async def afirst(self):\n        return await sync_to_async(self.first)()\n\n    def last(self):\n        \"\"\"Return the last object of a query or None if no match is found.\"\"\"\n        if self.ordered:\n            queryset = self.reverse()\n        else:\n            self._check_ordering_first_last_queryset_aggregation(method=\"last\")\n            queryset = self.order_by(\"-pk\")\n        for obj in queryset[:1]:\n            return obj\n\n    async def alast(self):\n        return await sync_to_async(self.last)()\n\n    def in_bulk(self, id_list=None, *, field_name=\"pk\"):\n        \"\"\"\n        Return a dictionary mapping each of the given IDs to the object with\n        that ID. If `id_list` isn't provided, evaluate the entire QuerySet.\n        \"\"\"\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot use 'limit' or 'offset' with in_bulk().\")\n        opts = self.model._meta\n        unique_fields = [\n            constraint.fields[0]\n            for constraint in opts.total_unique_constraints\n            if len(constraint.fields) == 1\n        ]\n        if (\n            field_name != \"pk\"\n            and not opts.get_field(field_name).unique\n            and field_name not in unique_fields\n            and self.query.distinct_fields != (field_name,)\n        ):\n            raise ValueError(\n                \"in_bulk()'s field_name must be a unique field but %r isn't.\"\n                % field_name\n            )\n        if id_list is not None:\n            if not id_list:\n                return {}\n            filter_key = \"{}__in\".format(field_name)\n            batch_size = connections[self.db].features.max_query_params\n            id_list = tuple(id_list)\n            # If the database has a limit on the number of query parameters\n            # (e.g. SQLite), retrieve objects in batches if necessary.\n            if batch_size and batch_size < len(id_list):\n                qs = ()\n                for offset in range(0, len(id_list), batch_size):\n                    batch = id_list[offset : offset + batch_size]\n                    qs += tuple(self.filter(**{filter_key: batch}))\n            else:\n                qs = self.filter(**{filter_key: id_list})\n        else:\n            qs = self._chain()\n        return {getattr(obj, field_name): obj for obj in qs}\n\n    async def ain_bulk(self, id_list=None, *, field_name=\"pk\"):\n        return await sync_to_async(self.in_bulk)(\n            id_list=id_list,\n            field_name=field_name,\n        )\n\n    def delete(self):\n        \"\"\"Delete the records in the current QuerySet.\"\"\"\n        self._not_support_combined_queries(\"delete\")\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot use 'limit' or 'offset' with delete().\")\n        if self.query.distinct or self.query.distinct_fields:\n            raise TypeError(\"Cannot call delete() after .distinct().\")\n        if self._fields is not None:\n            raise TypeError(\"Cannot call delete() after .values() or .values_list()\")\n\n        del_query = self._chain()\n\n        # The delete is actually 2 queries - one to find related objects,\n        # and one to delete. Make sure that the discovery of related\n        # objects is performed on the same database as the deletion.\n        del_query._for_write = True\n\n        # Disable non-supported fields.\n        del_query.query.select_for_update = False\n        del_query.query.select_related = False\n        del_query.query.clear_ordering(force=True)\n\n        collector = Collector(using=del_query.db, origin=self)\n        collector.collect(del_query)\n        deleted, _rows_count = collector.delete()\n\n        # Clear the result cache, in case this QuerySet gets reused.\n        self._result_cache = None\n        return deleted, _rows_count\n\n    delete.alters_data = True\n    delete.queryset_only = True\n\n    async def adelete(self):\n        return await sync_to_async(self.delete)()\n\n    adelete.alters_data = True\n    adelete.queryset_only = True\n\n    def _raw_delete(self, using):\n        \"\"\"\n        Delete objects found from the given queryset in single direct SQL\n        query. No signals are sent and there is no protection for cascades.\n        \"\"\"\n        query = self.query.clone()\n        query.__class__ = sql.DeleteQuery\n        cursor = query.get_compiler(using).execute_sql(CURSOR)\n        if cursor:\n            with cursor:\n                return cursor.rowcount\n        return 0\n\n    _raw_delete.alters_data = True\n\n    def update(self, **kwargs):\n        \"\"\"\n        Update all elements in the current QuerySet, setting all the given\n        fields to the appropriate values.\n        \"\"\"\n        self._not_support_combined_queries(\"update\")\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot update a query once a slice has been taken.\")\n        self._for_write = True\n        query = self.query.chain(sql.UpdateQuery)\n        query.add_update_values(kwargs)\n\n        # Inline annotations in order_by(), if possible.\n        new_order_by = []\n        for col in query.order_by:\n            alias = col\n            descending = False\n            if isinstance(alias, str) and alias.startswith(\"-\"):\n                alias = alias.removeprefix(\"-\")\n                descending = True\n            if annotation := query.annotations.get(alias):\n                if getattr(annotation, \"contains_aggregate\", False):\n                    raise exceptions.FieldError(\n                        f\"Cannot update when ordering by an aggregate: {annotation}\"\n                    )\n                if descending:\n                    annotation = annotation.desc()\n                new_order_by.append(annotation)\n            else:\n                new_order_by.append(col)\n        query.order_by = tuple(new_order_by)\n\n        # Clear any annotations so that they won't be present in subqueries.\n        query.annotations = {}\n        with transaction.mark_for_rollback_on_error(using=self.db):\n            rows = query.get_compiler(self.db).execute_sql(CURSOR)\n        self._result_cache = None\n        return rows\n\n    update.alters_data = True\n\n    async def aupdate(self, **kwargs):\n        return await sync_to_async(self.update)(**kwargs)\n\n    aupdate.alters_data = True\n\n    def _update(self, values):\n        \"\"\"\n        A version of update() that accepts field objects instead of field names.\n        Used primarily for model saving and not intended for use by general\n        code (it requires too much poking around at model internals to be\n        useful at that level).\n        \"\"\"\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot update a query once a slice has been taken.\")\n        query = self.query.chain(sql.UpdateQuery)\n        query.add_update_fields(values)\n        # Clear any annotations so that they won't be present in subqueries.\n        query.annotations = {}\n        self._result_cache = None\n        return query.get_compiler(self.db).execute_sql(CURSOR)\n\n    _update.alters_data = True\n    _update.queryset_only = False\n\n    def exists(self):\n        \"\"\"\n        Return True if the QuerySet would have any results, False otherwise.\n        \"\"\"\n        if self._result_cache is None:\n            return self.query.has_results(using=self.db)\n        return bool(self._result_cache)\n\n    async def aexists(self):\n        return await sync_to_async(self.exists)()\n\n    def contains(self, obj):\n        \"\"\"\n        Return True if the QuerySet contains the provided obj,\n        False otherwise.\n        \"\"\"\n        self._not_support_combined_queries(\"contains\")\n        if self._fields is not None:\n            raise TypeError(\n                \"Cannot call QuerySet.contains() after .values() or .values_list().\"\n            )\n        try:\n            if obj._meta.concrete_model != self.model._meta.concrete_model:\n                return False\n        except AttributeError:\n            raise TypeError(\"'obj' must be a model instance.\")\n        if obj.pk is None:\n            raise ValueError(\"QuerySet.contains() cannot be used on unsaved objects.\")\n        if self._result_cache is not None:\n            return obj in self._result_cache\n        return self.filter(pk=obj.pk).exists()\n\n    async def acontains(self, obj):\n        return await sync_to_async(self.contains)(obj=obj)\n\n    def _prefetch_related_objects(self):\n        # This method can only be called once the result cache has been filled.\n        prefetch_related_objects(self._result_cache, *self._prefetch_related_lookups)\n        self._prefetch_done = True\n\n    def explain(self, *, format=None, **options):\n        \"\"\"\n        Runs an EXPLAIN on the SQL query this QuerySet would perform, and\n        returns the results.\n        \"\"\"\n        return self.query.explain(using=self.db, format=format, **options)\n\n    async def aexplain(self, *, format=None, **options):\n        return await sync_to_async(self.explain)(format=format, **options)\n\n    ##################################################\n    # PUBLIC METHODS THAT RETURN A QUERYSET SUBCLASS #\n    ##################################################\n\n    def raw(self, raw_query, params=(), translations=None, using=None):\n        if using is None:\n            using = self.db\n        qs = RawQuerySet(\n            raw_query,\n            model=self.model,\n            params=params,\n            translations=translations,\n            using=using,\n        )\n        qs._prefetch_related_lookups = self._prefetch_related_lookups[:]\n        return qs\n\n    def _values(self, *fields, **expressions):\n        clone = self._chain()\n        if expressions:\n            clone = clone.annotate(**expressions)\n        clone._fields = fields\n        clone.query.set_values(fields)\n        return clone\n\n    def values(self, *fields, **expressions):\n        fields += tuple(expressions)\n        clone = self._values(*fields, **expressions)\n        clone._iterable_class = ValuesIterable\n        return clone\n\n    def values_list(self, *fields, flat=False, named=False):\n        if flat and named:\n            raise TypeError(\"'flat' and 'named' can't be used together.\")\n        if flat and len(fields) > 1:\n            raise TypeError(\n                \"'flat' is not valid when values_list is called with more than one \"\n                \"field.\"\n            )\n\n        field_names = {f for f in fields if not hasattr(f, \"resolve_expression\")}\n        _fields = []\n        expressions = {}\n        counter = 1\n        for field in fields:\n            if hasattr(field, \"resolve_expression\"):\n                field_id_prefix = getattr(\n                    field, \"default_alias\", field.__class__.__name__.lower()\n                )\n                while True:\n                    field_id = field_id_prefix + str(counter)\n                    counter += 1\n                    if field_id not in field_names:\n                        break\n                expressions[field_id] = field\n                _fields.append(field_id)\n            else:\n                _fields.append(field)\n\n        clone = self._values(*_fields, **expressions)\n        clone._iterable_class = (\n            NamedValuesListIterable\n            if named\n            else FlatValuesListIterable\n            if flat\n            else ValuesListIterable\n        )\n        return clone\n\n    def dates(self, field_name, kind, order=\"ASC\"):\n        \"\"\"\n        Return a list of date objects representing all available dates for\n        the given field_name, scoped to 'kind'.\n        \"\"\"\n        if kind not in (\"year\", \"month\", \"week\", \"day\"):\n            raise ValueError(\"'kind' must be one of 'year', 'month', 'week', or 'day'.\")\n        if order not in (\"ASC\", \"DESC\"):\n            raise ValueError(\"'order' must be either 'ASC' or 'DESC'.\")\n        return (\n            self.annotate(\n                datefield=Trunc(field_name, kind, output_field=DateField()),\n                plain_field=F(field_name),\n            )\n            .values_list(\"datefield\", flat=True)\n            .distinct()\n            .filter(plain_field__isnull=False)\n            .order_by((\"-\" if order == \"DESC\" else \"\") + \"datefield\")\n        )\n\n    def datetimes(self, field_name, kind, order=\"ASC\", tzinfo=None):\n        \"\"\"\n        Return a list of datetime objects representing all available\n        datetimes for the given field_name, scoped to 'kind'.\n        \"\"\"\n        if kind not in (\"year\", \"month\", \"week\", \"day\", \"hour\", \"minute\", \"second\"):\n            raise ValueError(\n                \"'kind' must be one of 'year', 'month', 'week', 'day', \"\n                \"'hour', 'minute', or 'second'.\"\n            )\n        if order not in (\"ASC\", \"DESC\"):\n            raise ValueError(\"'order' must be either 'ASC' or 'DESC'.\")\n        if settings.USE_TZ:\n            if tzinfo is None:\n                tzinfo = timezone.get_current_timezone()\n        else:\n            tzinfo = None\n        return (\n            self.annotate(\n                datetimefield=Trunc(\n                    field_name,\n                    kind,\n                    output_field=DateTimeField(),\n                    tzinfo=tzinfo,\n                ),\n                plain_field=F(field_name),\n            )\n            .values_list(\"datetimefield\", flat=True)\n            .distinct()\n            .filter(plain_field__isnull=False)\n            .order_by((\"-\" if order == \"DESC\" else \"\") + \"datetimefield\")\n        )\n\n    def none(self):\n        \"\"\"Return an empty QuerySet.\"\"\"\n        clone = self._chain()\n        clone.query.set_empty()\n        return clone\n\n    ##################################################################\n    # PUBLIC METHODS THAT ALTER ATTRIBUTES AND RETURN A NEW QUERYSET #\n    ##################################################################\n\n    def all(self):\n        \"\"\"\n        Return a new QuerySet that is a copy of the current one. This allows a\n        QuerySet to proxy for a model manager in some cases.\n        \"\"\"\n        return self._chain()\n\n    def filter(self, *args, **kwargs):\n        \"\"\"\n        Return a new QuerySet instance with the args ANDed to the existing\n        set.\n        \"\"\"\n        self._not_support_combined_queries(\"filter\")\n        return self._filter_or_exclude(False, args, kwargs)\n\n    def exclude(self, *args, **kwargs):\n        \"\"\"\n        Return a new QuerySet instance with NOT (args) ANDed to the existing\n        set.\n        \"\"\"\n        self._not_support_combined_queries(\"exclude\")\n        return self._filter_or_exclude(True, args, kwargs)\n\n    def _filter_or_exclude(self, negate, args, kwargs):\n        if (args or kwargs) and self.query.is_sliced:\n            raise TypeError(\"Cannot filter a query once a slice has been taken.\")\n        clone = self._chain()\n        if self._defer_next_filter:\n            self._defer_next_filter = False\n            clone._deferred_filter = negate, args, kwargs\n        else:\n            clone._filter_or_exclude_inplace(negate, args, kwargs)\n        return clone\n\n    def _filter_or_exclude_inplace(self, negate, args, kwargs):\n        if negate:\n            self._query.add_q(~Q(*args, **kwargs))\n        else:\n            self._query.add_q(Q(*args, **kwargs))\n\n    def complex_filter(self, filter_obj):\n        \"\"\"\n        Return a new QuerySet instance with filter_obj added to the filters.\n\n        filter_obj can be a Q object or a dictionary of keyword lookup\n        arguments.\n\n        This exists to support framework features such as 'limit_choices_to',\n        and usually it will be more natural to use other methods.\n        \"\"\"\n        if isinstance(filter_obj, Q):\n            clone = self._chain()\n            clone.query.add_q(filter_obj)\n            return clone\n        else:\n            return self._filter_or_exclude(False, args=(), kwargs=filter_obj)\n\n    def _combinator_query(self, combinator, *other_qs, all=False):\n        # Clone the query to inherit the select list and everything\n        clone = self._chain()\n        # Clear limits and ordering so they can be reapplied\n        clone.query.clear_ordering(force=True)\n        clone.query.clear_limits()\n        clone.query.combined_queries = (self.query,) + tuple(\n            qs.query for qs in other_qs\n        )\n        clone.query.combinator = combinator\n        clone.query.combinator_all = all\n        return clone\n\n    def union(self, *other_qs, all=False):\n        # If the query is an EmptyQuerySet, combine all nonempty querysets.\n        if isinstance(self, EmptyQuerySet):\n            qs = [q for q in other_qs if not isinstance(q, EmptyQuerySet)]\n            if not qs:\n                return self\n            if len(qs) == 1:\n                return qs[0]\n            return qs[0]._combinator_query(\"union\", *qs[1:], all=all)\n        return self._combinator_query(\"union\", *other_qs, all=all)\n\n    def intersection(self, *other_qs):\n        # If any query is an EmptyQuerySet, return it.\n        if isinstance(self, EmptyQuerySet):\n            return self\n        for other in other_qs:\n            if isinstance(other, EmptyQuerySet):\n                return other\n        return self._combinator_query(\"intersection\", *other_qs)\n\n    def difference(self, *other_qs):\n        # If the query is an EmptyQuerySet, return it.\n        if isinstance(self, EmptyQuerySet):\n            return self\n        return self._combinator_query(\"difference\", *other_qs)\n\n    def select_for_update(self, nowait=False, skip_locked=False, of=(), no_key=False):\n        \"\"\"\n        Return a new QuerySet instance that will select objects with a\n        FOR UPDATE lock.\n        \"\"\"\n        if nowait and skip_locked:\n            raise ValueError(\"The nowait option cannot be used with skip_locked.\")\n        obj = self._chain()\n        obj._for_write = True\n        obj.query.select_for_update = True\n        obj.query.select_for_update_nowait = nowait\n        obj.query.select_for_update_skip_locked = skip_locked\n        obj.query.select_for_update_of = of\n        obj.query.select_for_no_key_update = no_key\n        return obj\n\n    def select_related(self, *fields):\n        \"\"\"\n        Return a new QuerySet instance that will select related objects.\n\n        If fields are specified, they must be ForeignKey fields and only those\n        related objects are included in the selection.\n\n        If select_related(None) is called, clear the list.\n        \"\"\"\n        self._not_support_combined_queries(\"select_related\")\n        if self._fields is not None:\n            raise TypeError(\n                \"Cannot call select_related() after .values() or .values_list()\"\n            )\n\n        obj = self._chain()\n        if fields == (None,):\n            obj.query.select_related = False\n        elif fields:\n            obj.query.add_select_related(fields)\n        else:\n            obj.query.select_related = True\n        return obj\n\n    def prefetch_related(self, *lookups):\n        \"\"\"\n        Return a new QuerySet instance that will prefetch the specified\n        Many-To-One and Many-To-Many related objects when the QuerySet is\n        evaluated.\n\n        When prefetch_related() is called more than once, append to the list of\n        prefetch lookups. If prefetch_related(None) is called, clear the list.\n        \"\"\"\n        self._not_support_combined_queries(\"prefetch_related\")\n        clone = self._chain()\n        if lookups == (None,):\n            clone._prefetch_related_lookups = ()\n        else:\n            for lookup in lookups:\n                if isinstance(lookup, Prefetch):\n                    lookup = lookup.prefetch_to\n                lookup = lookup.split(LOOKUP_SEP, 1)[0]\n                if lookup in self.query._filtered_relations:\n                    raise ValueError(\n                        \"prefetch_related() is not supported with FilteredRelation.\"\n                    )\n            clone._prefetch_related_lookups = clone._prefetch_related_lookups + lookups\n        return clone\n\n    def annotate(self, *args, **kwargs):\n        \"\"\"\n        Return a query set in which the returned objects have been annotated\n        with extra data or aggregations.\n        \"\"\"\n        self._not_support_combined_queries(\"annotate\")\n        return self._annotate(args, kwargs, select=True)\n\n    def alias(self, *args, **kwargs):\n        \"\"\"\n        Return a query set with added aliases for extra data or aggregations.\n        \"\"\"\n        self._not_support_combined_queries(\"alias\")\n        return self._annotate(args, kwargs, select=False)\n\n    def _annotate(self, args, kwargs, select=True):\n        self._validate_values_are_expressions(\n            args + tuple(kwargs.values()), method_name=\"annotate\"\n        )\n        annotations = {}\n        for arg in args:\n            # The default_alias property may raise a TypeError.\n            try:\n                if arg.default_alias in kwargs:\n                    raise ValueError(\n                        \"The named annotation '%s' conflicts with the \"\n                        \"default name for another annotation.\" % arg.default_alias\n                    )\n            except TypeError:\n                raise TypeError(\"Complex annotations require an alias\")\n            annotations[arg.default_alias] = arg\n        annotations.update(kwargs)\n\n        clone = self._chain()\n        names = self._fields\n        if names is None:\n            names = set(\n                chain.from_iterable(\n                    (field.name, field.attname)\n                    if hasattr(field, \"attname\")\n                    else (field.name,)\n                    for field in self.model._meta.get_fields()\n                )\n            )\n\n        for alias, annotation in annotations.items():\n            if alias in names:\n                raise ValueError(\n                    \"The annotation '%s' conflicts with a field on \"\n                    \"the model.\" % alias\n                )\n            if isinstance(annotation, FilteredRelation):\n                clone.query.add_filtered_relation(annotation, alias)\n            else:\n                clone.query.add_annotation(\n                    annotation,\n                    alias,\n                    select=select,\n                )\n        for alias, annotation in clone.query.annotations.items():\n            if alias in annotations and annotation.contains_aggregate:\n                if clone._fields is None:\n                    clone.query.group_by = True\n                else:\n                    clone.query.set_group_by()\n                break\n\n        return clone\n\n    def order_by(self, *field_names):\n        \"\"\"Return a new QuerySet instance with the ordering changed.\"\"\"\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot reorder a query once a slice has been taken.\")\n        obj = self._chain()\n        obj.query.clear_ordering(force=True, clear_default=False)\n        obj.query.add_ordering(*field_names)\n        return obj\n\n    def distinct(self, *field_names):\n        \"\"\"\n        Return a new QuerySet instance that will select only distinct results.\n        \"\"\"\n        self._not_support_combined_queries(\"distinct\")\n        if self.query.is_sliced:\n            raise TypeError(\n                \"Cannot create distinct fields once a slice has been taken.\"\n            )\n        obj = self._chain()\n        obj.query.add_distinct_fields(*field_names)\n        return obj\n\n    def extra(\n        self,\n        select=None,\n        where=None,\n        params=None,\n        tables=None,\n        order_by=None,\n        select_params=None,\n    ):\n        \"\"\"Add extra SQL fragments to the query.\"\"\"\n        self._not_support_combined_queries(\"extra\")\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot change a query once a slice has been taken.\")\n        clone = self._chain()\n        clone.query.add_extra(select, select_params, where, params, tables, order_by)\n        return clone\n\n    def reverse(self):\n        \"\"\"Reverse the ordering of the QuerySet.\"\"\"\n        if self.query.is_sliced:\n            raise TypeError(\"Cannot reverse a query once a slice has been taken.\")\n        clone = self._chain()\n        clone.query.standard_ordering = not clone.query.standard_ordering\n        return clone\n\n    def defer(self, *fields):\n        \"\"\"\n        Defer the loading of data for certain fields until they are accessed.\n        Add the set of deferred fields to any existing set of deferred fields.\n        The only exception to this is if None is passed in as the only\n        parameter, in which case removal all deferrals.\n        \"\"\"\n        self._not_support_combined_queries(\"defer\")\n        if self._fields is not None:\n            raise TypeError(\"Cannot call defer() after .values() or .values_list()\")\n        clone = self._chain()\n        if fields == (None,):\n            clone.query.clear_deferred_loading()\n        else:\n            clone.query.add_deferred_loading(fields)\n        return clone\n\n    def only(self, *fields):\n        \"\"\"\n        Essentially, the opposite of defer(). Only the fields passed into this\n        method and that are not already specified as deferred are loaded\n        immediately when the queryset is evaluated.\n        \"\"\"\n        self._not_support_combined_queries(\"only\")\n        if self._fields is not None:\n            raise TypeError(\"Cannot call only() after .values() or .values_list()\")\n        if fields == (None,):\n            # Can only pass None to defer(), not only(), as the rest option.\n            # That won't stop people trying to do this, so let's be explicit.\n            raise TypeError(\"Cannot pass None as an argument to only().\")\n        for field in fields:\n            field = field.split(LOOKUP_SEP, 1)[0]\n            if field in self.query._filtered_relations:\n                raise ValueError(\"only() is not supported with FilteredRelation.\")\n        clone = self._chain()\n        clone.query.add_immediate_loading(fields)\n        return clone\n\n    def using(self, alias):\n        \"\"\"Select which database this QuerySet should execute against.\"\"\"\n        clone = self._chain()\n        clone._db = alias\n        return clone\n\n    ###################################\n    # PUBLIC INTROSPECTION ATTRIBUTES #\n    ###################################\n\n    @property\n    def ordered(self):\n        \"\"\"\n        Return True if the QuerySet is ordered -- i.e. has an order_by()\n        clause or a default ordering on the model (or is empty).\n        \"\"\"\n        if isinstance(self, EmptyQuerySet):\n            return True\n        if self.query.extra_order_by or self.query.order_by:\n            return True\n        elif (\n            self.query.default_ordering\n            and self.query.get_meta().ordering\n            and\n            # A default ordering doesn't affect GROUP BY queries.\n            not self.query.group_by\n        ):\n            return True\n        else:\n            return False\n\n    @property\n    def db(self):\n        \"\"\"Return the database used if this query is executed now.\"\"\"\n        if self._for_write:\n            return self._db or router.db_for_write(self.model, **self._hints)\n        return self._db or router.db_for_read(self.model, **self._hints)\n\n    ###################\n    # PRIVATE METHODS #\n    ###################\n\n    def _insert(\n        self,\n        objs,\n        fields,\n        returning_fields=None,\n        raw=False,\n        using=None,\n        on_conflict=None,\n        update_fields=None,\n        unique_fields=None,\n    ):\n        \"\"\"\n        Insert a new record for the given model. This provides an interface to\n        the InsertQuery class and is how Model.save() is implemented.\n        \"\"\"\n        self._for_write = True\n        if using is None:\n            using = self.db\n        query = sql.InsertQuery(\n            self.model,\n            on_conflict=on_conflict,\n            update_fields=update_fields,\n            unique_fields=unique_fields,\n        )\n        query.insert_values(fields, objs, raw=raw)\n        return query.get_compiler(using=using).execute_sql(returning_fields)\n\n    _insert.alters_data = True\n    _insert.queryset_only = False\n\n    def _batched_insert(\n        self,\n        objs,\n        fields,\n        batch_size,\n        on_conflict=None,\n        update_fields=None,\n        unique_fields=None,\n    ):\n        \"\"\"\n        Helper method for bulk_create() to insert objs one batch at a time.\n        \"\"\"\n        connection = connections[self.db]\n        ops = connection.ops\n        max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)\n        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size\n        inserted_rows = []\n        bulk_return = connection.features.can_return_rows_from_bulk_insert\n        for item in [objs[i : i + batch_size] for i in range(0, len(objs), batch_size)]:\n            if bulk_return and on_conflict is None:\n                inserted_rows.extend(\n                    self._insert(\n                        item,\n                        fields=fields,\n                        using=self.db,\n                        returning_fields=self.model._meta.db_returning_fields,\n                    )\n                )\n            else:\n                self._insert(\n                    item,\n                    fields=fields,\n                    using=self.db,\n                    on_conflict=on_conflict,\n                    update_fields=update_fields,\n                    unique_fields=unique_fields,\n                )\n        return inserted_rows\n\n    def _chain(self):\n        \"\"\"\n        Return a copy of the current QuerySet that's ready for another\n        operation.\n        \"\"\"\n        obj = self._clone()\n        if obj._sticky_filter:\n            obj.query.filter_is_sticky = True\n            obj._sticky_filter = False\n        return obj\n\n    def _clone(self):\n        \"\"\"\n        Return a copy of the current QuerySet. A lightweight alternative\n        to deepcopy().\n        \"\"\"\n        c = self.__class__(\n            model=self.model,\n            query=self.query.chain(),\n            using=self._db,\n            hints=self._hints,\n        )\n        c._sticky_filter = self._sticky_filter\n        c._for_write = self._for_write\n        c._prefetch_related_lookups = self._prefetch_related_lookups[:]\n        c._known_related_objects = self._known_related_objects\n        c._iterable_class = self._iterable_class\n        c._fields = self._fields\n        return c\n\n    def _fetch_all(self):\n        if self._result_cache is None:\n            self._result_cache = list(self._iterable_class(self))\n        if self._prefetch_related_lookups and not self._prefetch_done:\n            self._prefetch_related_objects()\n\n    def _next_is_sticky(self):\n        \"\"\"\n        Indicate that the next filter call and the one following that should\n        be treated as a single filter. This is only important when it comes to\n        determining when to reuse tables for many-to-many filters. Required so\n        that we can filter naturally on the results of related managers.\n\n        This doesn't return a clone of the current QuerySet (it returns\n        \"self\"). The method is only used internally and should be immediately\n        followed by a filter() that does create a clone.\n        \"\"\"\n        self._sticky_filter = True\n        return self\n\n    def _merge_sanity_check(self, other):\n        \"\"\"Check that two QuerySet classes may be merged.\"\"\"\n        if self._fields is not None and (\n            set(self.query.values_select) != set(other.query.values_select)\n            or set(self.query.extra_select) != set(other.query.extra_select)\n            or set(self.query.annotation_select) != set(other.query.annotation_select)\n        ):\n            raise TypeError(\n                \"Merging '%s' classes must involve the same values in each case.\"\n                % self.__class__.__name__\n            )\n\n    def _merge_known_related_objects(self, other):\n        \"\"\"\n        Keep track of all known related objects from either QuerySet instance.\n        \"\"\"\n        for field, objects in other._known_related_objects.items():\n            self._known_related_objects.setdefault(field, {}).update(objects)\n\n    def resolve_expression(self, *args, **kwargs):\n        if self._fields and len(self._fields) > 1:\n            # values() queryset can only be used as nested queries\n            # if they are set up to select only a single field.\n            raise TypeError(\"Cannot use multi-field values as a filter value.\")\n        query = self.query.resolve_expression(*args, **kwargs)\n        query._db = self._db\n        return query\n\n    resolve_expression.queryset_only = True\n\n    def _add_hints(self, **hints):\n        \"\"\"\n        Update hinting information for use by routers. Add new key/values or\n        overwrite existing key/values.\n        \"\"\"\n        self._hints.update(hints)\n\n    def _has_filters(self):\n        \"\"\"\n        Check if this QuerySet has any filtering going on. This isn't\n        equivalent with checking if all objects are present in results, for\n        example, qs[1:]._has_filters() -> False.\n        \"\"\"\n        return self.query.has_filters()\n\n    @staticmethod\n    def _validate_values_are_expressions(values, method_name):\n        invalid_args = sorted(\n            str(arg) for arg in values if not hasattr(arg, \"resolve_expression\")\n        )\n        if invalid_args:\n            raise TypeError(\n                \"QuerySet.%s() received non-expression(s): %s.\"\n                % (\n                    method_name,\n                    \", \".join(invalid_args),\n                )\n            )\n\n    def _not_support_combined_queries(self, operation_name):\n        if self.query.combinator:\n            raise NotSupportedError(\n                \"Calling QuerySet.%s() after %s() is not supported.\"\n                % (operation_name, self.query.combinator)\n            )\n\n    def _check_operator_queryset(self, other, operator_):\n        if self.query.combinator or other.query.combinator:\n            raise TypeError(f\"Cannot use {operator_} operator with combined queryset.\")\n\n    def _check_ordering_first_last_queryset_aggregation(self, method):\n        if isinstance(self.query.group_by, tuple) and not any(\n            col.output_field is self.model._meta.pk for col in self.query.group_by\n        ):\n            raise TypeError(\n                f\"Cannot use QuerySet.{method}() on an unordered queryset performing \"\n                f\"aggregation. Add an ordering with order_by().\"\n            )\n\n\nclass InstanceCheckMeta(type):\n    def __instancecheck__(self, instance):\n        return isinstance(instance, QuerySet) and instance.query.is_empty()\n\n\nclass EmptyQuerySet(metaclass=InstanceCheckMeta):\n    \"\"\"\n    Marker class to checking if a queryset is empty by .none():\n        isinstance(qs.none(), EmptyQuerySet) -> True\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        raise TypeError(\"EmptyQuerySet can't be instantiated\")\n\n\nclass RawQuerySet:\n    \"\"\"\n    Provide an iterator which converts the results of raw SQL queries into\n    annotated model instances.\n    \"\"\"\n\n    def __init__(\n        self,\n        raw_query,\n        model=None,\n        query=None,\n        params=(),\n        translations=None,\n        using=None,\n        hints=None,\n    ):\n        self.raw_query = raw_query\n        self.model = model\n        self._db = using\n        self._hints = hints or {}\n        self.query = query or sql.RawQuery(sql=raw_query, using=self.db, params=params)\n        self.params = params\n        self.translations = translations or {}\n        self._result_cache = None\n        self._prefetch_related_lookups = ()\n        self._prefetch_done = False\n\n    def resolve_model_init_order(self):\n        \"\"\"Resolve the init field names and value positions.\"\"\"\n        converter = connections[self.db].introspection.identifier_converter\n        model_init_fields = [\n            f for f in self.model._meta.fields if converter(f.column) in self.columns\n        ]\n        annotation_fields = [\n            (column, pos)\n            for pos, column in enumerate(self.columns)\n            if column not in self.model_fields\n        ]\n        model_init_order = [\n            self.columns.index(converter(f.column)) for f in model_init_fields\n        ]\n        model_init_names = [f.attname for f in model_init_fields]\n        return model_init_names, model_init_order, annotation_fields\n\n    def prefetch_related(self, *lookups):\n        \"\"\"Same as QuerySet.prefetch_related()\"\"\"\n        clone = self._clone()\n        if lookups == (None,):\n            clone._prefetch_related_lookups = ()\n        else:\n            clone._prefetch_related_lookups = clone._prefetch_related_lookups + lookups\n        return clone\n\n    def _prefetch_related_objects(self):\n        prefetch_related_objects(self._result_cache, *self._prefetch_related_lookups)\n        self._prefetch_done = True\n\n    def _clone(self):\n        \"\"\"Same as QuerySet._clone()\"\"\"\n        c = self.__class__(\n            self.raw_query,\n            model=self.model,\n            query=self.query,\n            params=self.params,\n            translations=self.translations,\n            using=self._db,\n            hints=self._hints,\n        )\n        c._prefetch_related_lookups = self._prefetch_related_lookups[:]\n        return c\n\n    def _fetch_all(self):\n        if self._result_cache is None:\n            self._result_cache = list(self.iterator())\n        if self._prefetch_related_lookups and not self._prefetch_done:\n            self._prefetch_related_objects()\n\n    def __len__(self):\n        self._fetch_all()\n        return len(self._result_cache)\n\n    def __bool__(self):\n        self._fetch_all()\n        return bool(self._result_cache)\n\n    def __iter__(self):\n        self._fetch_all()\n        return iter(self._result_cache)\n\n    def __aiter__(self):\n        # Remember, __aiter__ itself is synchronous, it's the thing it returns\n        # that is async!\n        async def generator():\n            await sync_to_async(self._fetch_all)()\n            for item in self._result_cache:\n                yield item\n\n        return generator()\n\n    def iterator(self):\n        yield from RawModelIterable(self)\n\n    def __repr__(self):\n        return \"<%s: %s>\" % (self.__class__.__name__, self.query)\n\n    def __getitem__(self, k):\n        return list(self)[k]\n\n    @property\n    def db(self):\n        \"\"\"Return the database used if this query is executed now.\"\"\"\n        return self._db or router.db_for_read(self.model, **self._hints)\n\n    def using(self, alias):\n        \"\"\"Select the database this RawQuerySet should execute against.\"\"\"\n        return RawQuerySet(\n            self.raw_query,\n            model=self.model,\n            query=self.query.chain(using=alias),\n            params=self.params,\n            translations=self.translations,\n            using=alias,\n        )\n\n    @cached_property\n    def columns(self):\n        \"\"\"\n        A list of model field names in the order they'll appear in the\n        query results.\n        \"\"\"\n        columns = self.query.get_columns()\n        # Adjust any column names which don't match field names\n        for query_name, model_name in self.translations.items():\n            # Ignore translations for nonexistent column names\n            try:\n                index = columns.index(query_name)\n            except ValueError:\n                pass\n            else:\n                columns[index] = model_name\n        return columns\n\n    @cached_property\n    def model_fields(self):\n        \"\"\"A dict mapping column names to model field names.\"\"\"\n        converter = connections[self.db].introspection.identifier_converter\n        model_fields = {}\n        for field in self.model._meta.fields:\n            name, column = field.get_attname_column()\n            model_fields[converter(column)] = field\n        return model_fields\n\n\nclass Prefetch:\n    def __init__(self, lookup, queryset=None, to_attr=None):\n        # `prefetch_through` is the path we traverse to perform the prefetch.\n        self.prefetch_through = lookup\n        # `prefetch_to` is the path to the attribute that stores the result.\n        self.prefetch_to = lookup\n        if queryset is not None and (\n            isinstance(queryset, RawQuerySet)\n            or (\n                hasattr(queryset, \"_iterable_class\")\n                and not issubclass(queryset._iterable_class, ModelIterable)\n            )\n        ):\n            raise ValueError(\n                \"Prefetch querysets cannot use raw(), values(), and values_list().\"\n            )\n        if to_attr:\n            self.prefetch_to = LOOKUP_SEP.join(\n                lookup.split(LOOKUP_SEP)[:-1] + [to_attr]\n            )\n\n        self.queryset = queryset\n        self.to_attr = to_attr\n\n    def __getstate__(self):\n        obj_dict = self.__dict__.copy()\n        if self.queryset is not None:\n            queryset = self.queryset._chain()\n            # Prevent the QuerySet from being evaluated\n            queryset._result_cache = []\n            queryset._prefetch_done = True\n            obj_dict[\"queryset\"] = queryset\n        return obj_dict\n\n    def add_prefix(self, prefix):\n        self.prefetch_through = prefix + LOOKUP_SEP + self.prefetch_through\n        self.prefetch_to = prefix + LOOKUP_SEP + self.prefetch_to\n\n    def get_current_prefetch_to(self, level):\n        return LOOKUP_SEP.join(self.prefetch_to.split(LOOKUP_SEP)[: level + 1])\n\n    def get_current_to_attr(self, level):\n        parts = self.prefetch_to.split(LOOKUP_SEP)\n        to_attr = parts[level]\n        as_attr = self.to_attr and level == len(parts) - 1\n        return to_attr, as_attr\n\n    def get_current_queryset(self, level):\n        if self.get_current_prefetch_to(level) == self.prefetch_to:\n            return self.queryset\n        return None\n\n    def __eq__(self, other):\n        if not isinstance(other, Prefetch):\n            return NotImplemented\n        return self.prefetch_to == other.prefetch_to\n\n    def __hash__(self):\n        return hash((self.__class__, self.prefetch_to))\n\n\ndef normalize_prefetch_lookups(lookups, prefix=None):\n    \"\"\"Normalize lookups into Prefetch objects.\"\"\"\n    ret = []\n    for lookup in lookups:\n        if not isinstance(lookup, Prefetch):\n            lookup = Prefetch(lookup)\n        if prefix:\n            lookup.add_prefix(prefix)\n        ret.append(lookup)\n    return ret\n\n\ndef prefetch_related_objects(model_instances, *related_lookups):\n    \"\"\"\n    Populate prefetched object caches for a list of model instances based on\n    the lookups/Prefetch instances given.\n    \"\"\"\n    if not model_instances:\n        return  # nothing to do\n\n    # We need to be able to dynamically add to the list of prefetch_related\n    # lookups that we look up (see below).  So we need some book keeping to\n    # ensure we don't do duplicate work.\n    done_queries = {}  # dictionary of things like 'foo__bar': [results]\n\n    auto_lookups = set()  # we add to this as we go through.\n    followed_descriptors = set()  # recursion protection\n\n    all_lookups = normalize_prefetch_lookups(reversed(related_lookups))\n    while all_lookups:\n        lookup = all_lookups.pop()\n        if lookup.prefetch_to in done_queries:\n            if lookup.queryset is not None:\n                raise ValueError(\n                    \"'%s' lookup was already seen with a different queryset. \"\n                    \"You may need to adjust the ordering of your lookups.\"\n                    % lookup.prefetch_to\n                )\n\n            continue\n\n        # Top level, the list of objects to decorate is the result cache\n        # from the primary QuerySet. It won't be for deeper levels.\n        obj_list = model_instances\n\n        through_attrs = lookup.prefetch_through.split(LOOKUP_SEP)\n        for level, through_attr in enumerate(through_attrs):\n            # Prepare main instances\n            if not obj_list:\n                break\n\n            prefetch_to = lookup.get_current_prefetch_to(level)\n            if prefetch_to in done_queries:\n                # Skip any prefetching, and any object preparation\n                obj_list = done_queries[prefetch_to]\n                continue\n\n            # Prepare objects:\n            good_objects = True\n            for obj in obj_list:\n                # Since prefetching can re-use instances, it is possible to have\n                # the same instance multiple times in obj_list, so obj might\n                # already be prepared.\n                if not hasattr(obj, \"_prefetched_objects_cache\"):\n                    try:\n                        obj._prefetched_objects_cache = {}\n                    except (AttributeError, TypeError):\n                        # Must be an immutable object from\n                        # values_list(flat=True), for example (TypeError) or\n                        # a QuerySet subclass that isn't returning Model\n                        # instances (AttributeError), either in Django or a 3rd\n                        # party. prefetch_related() doesn't make sense, so quit.\n                        good_objects = False\n                        break\n            if not good_objects:\n                break\n\n            # Descend down tree\n\n            # We assume that objects retrieved are homogeneous (which is the premise\n            # of prefetch_related), so what applies to first object applies to all.\n            first_obj = obj_list[0]\n            to_attr = lookup.get_current_to_attr(level)[0]\n            prefetcher, descriptor, attr_found, is_fetched = get_prefetcher(\n                first_obj, through_attr, to_attr\n            )\n\n            if not attr_found:\n                raise AttributeError(\n                    \"Cannot find '%s' on %s object, '%s' is an invalid \"\n                    \"parameter to prefetch_related()\"\n                    % (\n                        through_attr,\n                        first_obj.__class__.__name__,\n                        lookup.prefetch_through,\n                    )\n                )\n\n            if level == len(through_attrs) - 1 and prefetcher is None:\n                # Last one, this *must* resolve to something that supports\n                # prefetching, otherwise there is no point adding it and the\n                # developer asking for it has made a mistake.\n                raise ValueError(\n                    \"'%s' does not resolve to an item that supports \"\n                    \"prefetching - this is an invalid parameter to \"\n                    \"prefetch_related().\" % lookup.prefetch_through\n                )\n\n            obj_to_fetch = None\n            if prefetcher is not None:\n                obj_to_fetch = [obj for obj in obj_list if not is_fetched(obj)]\n\n            if obj_to_fetch:\n                obj_list, additional_lookups = prefetch_one_level(\n                    obj_to_fetch,\n                    prefetcher,\n                    lookup,\n                    level,\n                )\n                # We need to ensure we don't keep adding lookups from the\n                # same relationships to stop infinite recursion. So, if we\n                # are already on an automatically added lookup, don't add\n                # the new lookups from relationships we've seen already.\n                if not (\n                    prefetch_to in done_queries\n                    and lookup in auto_lookups\n                    and descriptor in followed_descriptors\n                ):\n                    done_queries[prefetch_to] = obj_list\n                    new_lookups = normalize_prefetch_lookups(\n                        reversed(additional_lookups), prefetch_to\n                    )\n                    auto_lookups.update(new_lookups)\n                    all_lookups.extend(new_lookups)\n                followed_descriptors.add(descriptor)\n            else:\n                # Either a singly related object that has already been fetched\n                # (e.g. via select_related), or hopefully some other property\n                # that doesn't support prefetching but needs to be traversed.\n\n                # We replace the current list of parent objects with the list\n                # of related objects, filtering out empty or missing values so\n                # that we can continue with nullable or reverse relations.\n                new_obj_list = []\n                for obj in obj_list:\n                    if through_attr in getattr(obj, \"_prefetched_objects_cache\", ()):\n                        # If related objects have been prefetched, use the\n                        # cache rather than the object's through_attr.\n                        new_obj = list(obj._prefetched_objects_cache.get(through_attr))\n                    else:\n                        try:\n                            new_obj = getattr(obj, through_attr)\n                        except exceptions.ObjectDoesNotExist:\n                            continue\n                    if new_obj is None:\n                        continue\n                    # We special-case `list` rather than something more generic\n                    # like `Iterable` because we don't want to accidentally match\n                    # user models that define __iter__.\n                    if isinstance(new_obj, list):\n                        new_obj_list.extend(new_obj)\n                    else:\n                        new_obj_list.append(new_obj)\n                obj_list = new_obj_list\n\n\ndef get_prefetcher(instance, through_attr, to_attr):\n    \"\"\"\n    For the attribute 'through_attr' on the given instance, find\n    an object that has a get_prefetch_queryset().\n    Return a 4 tuple containing:\n    (the object with get_prefetch_queryset (or None),\n     the descriptor object representing this relationship (or None),\n     a boolean that is False if the attribute was not found at all,\n     a function that takes an instance and returns a boolean that is True if\n     the attribute has already been fetched for that instance)\n    \"\"\"\n\n    def has_to_attr_attribute(instance):\n        return hasattr(instance, to_attr)\n\n    prefetcher = None\n    is_fetched = has_to_attr_attribute\n\n    # For singly related objects, we have to avoid getting the attribute\n    # from the object, as this will trigger the query. So we first try\n    # on the class, in order to get the descriptor object.\n    rel_obj_descriptor = getattr(instance.__class__, through_attr, None)\n    if rel_obj_descriptor is None:\n        attr_found = hasattr(instance, through_attr)\n    else:\n        attr_found = True\n        if rel_obj_descriptor:\n            # singly related object, descriptor object has the\n            # get_prefetch_queryset() method.\n            if hasattr(rel_obj_descriptor, \"get_prefetch_queryset\"):\n                prefetcher = rel_obj_descriptor\n                is_fetched = rel_obj_descriptor.is_cached\n            else:\n                # descriptor doesn't support prefetching, so we go ahead and get\n                # the attribute on the instance rather than the class to\n                # support many related managers\n                rel_obj = getattr(instance, through_attr)\n                if hasattr(rel_obj, \"get_prefetch_queryset\"):\n                    prefetcher = rel_obj\n                if through_attr != to_attr:\n                    # Special case cached_property instances because hasattr\n                    # triggers attribute computation and assignment.\n                    if isinstance(\n                        getattr(instance.__class__, to_attr, None), cached_property\n                    ):\n\n                        def has_cached_property(instance):\n                            return to_attr in instance.__dict__\n\n                        is_fetched = has_cached_property\n                else:\n\n                    def in_prefetched_cache(instance):\n                        return through_attr in instance._prefetched_objects_cache\n\n                    is_fetched = in_prefetched_cache\n    return prefetcher, rel_obj_descriptor, attr_found, is_fetched\n\n\ndef prefetch_one_level(instances, prefetcher, lookup, level):\n    \"\"\"\n    Helper function for prefetch_related_objects().\n\n    Run prefetches on all instances using the prefetcher object,\n    assigning results to relevant caches in instance.\n\n    Return the prefetched objects along with any additional prefetches that\n    must be done due to prefetch_related lookups found from default managers.\n    \"\"\"\n    # prefetcher must have a method get_prefetch_queryset() which takes a list\n    # of instances, and returns a tuple:\n\n    # (queryset of instances of self.model that are related to passed in instances,\n    #  callable that gets value to be matched for returned instances,\n    #  callable that gets value to be matched for passed in instances,\n    #  boolean that is True for singly related objects,\n    #  cache or field name to assign to,\n    #  boolean that is True when the previous argument is a cache name vs a field name).\n\n    # The 'values to be matched' must be hashable as they will be used\n    # in a dictionary.\n\n    (\n        rel_qs,\n        rel_obj_attr,\n        instance_attr,\n        single,\n        cache_name,\n        is_descriptor,\n    ) = prefetcher.get_prefetch_queryset(instances, lookup.get_current_queryset(level))\n    # We have to handle the possibility that the QuerySet we just got back\n    # contains some prefetch_related lookups. We don't want to trigger the\n    # prefetch_related functionality by evaluating the query. Rather, we need\n    # to merge in the prefetch_related lookups.\n    # Copy the lookups in case it is a Prefetch object which could be reused\n    # later (happens in nested prefetch_related).\n    additional_lookups = [\n        copy.copy(additional_lookup)\n        for additional_lookup in getattr(rel_qs, \"_prefetch_related_lookups\", ())\n    ]\n    if additional_lookups:\n        # Don't need to clone because the manager should have given us a fresh\n        # instance, so we access an internal instead of using public interface\n        # for performance reasons.\n        rel_qs._prefetch_related_lookups = ()\n\n    all_related_objects = list(rel_qs)\n\n    rel_obj_cache = {}\n    for rel_obj in all_related_objects:\n        rel_attr_val = rel_obj_attr(rel_obj)\n        rel_obj_cache.setdefault(rel_attr_val, []).append(rel_obj)\n\n    to_attr, as_attr = lookup.get_current_to_attr(level)\n    # Make sure `to_attr` does not conflict with a field.\n    if as_attr and instances:\n        # We assume that objects retrieved are homogeneous (which is the premise\n        # of prefetch_related), so what applies to first object applies to all.\n        model = instances[0].__class__\n        try:\n            model._meta.get_field(to_attr)\n        except exceptions.FieldDoesNotExist:\n            pass\n        else:\n            msg = \"to_attr={} conflicts with a field on the {} model.\"\n            raise ValueError(msg.format(to_attr, model.__name__))\n\n    # Whether or not we're prefetching the last part of the lookup.\n    leaf = len(lookup.prefetch_through.split(LOOKUP_SEP)) - 1 == level\n\n    for obj in instances:\n        instance_attr_val = instance_attr(obj)\n        vals = rel_obj_cache.get(instance_attr_val, [])\n\n        if single:\n            val = vals[0] if vals else None\n            if as_attr:\n                # A to_attr has been given for the prefetch.\n                setattr(obj, to_attr, val)\n            elif is_descriptor:\n                # cache_name points to a field name in obj.\n                # This field is a descriptor for a related object.\n                setattr(obj, cache_name, val)\n            else:\n                # No to_attr has been given for this prefetch operation and the\n                # cache_name does not point to a descriptor. Store the value of\n                # the field in the object's field cache.\n                obj._state.fields_cache[cache_name] = val\n        else:\n            if as_attr:\n                setattr(obj, to_attr, vals)\n            else:\n                manager = getattr(obj, to_attr)\n                if leaf and lookup.queryset is not None:\n                    qs = manager._apply_rel_filters(lookup.queryset)\n                else:\n                    qs = manager.get_queryset()\n                qs._result_cache = vals\n                # We don't want the individual qs doing prefetch_related now,\n                # since we have merged this into the current work.\n                qs._prefetch_done = True\n                obj._prefetched_objects_cache[cache_name] = qs\n    return all_related_objects, additional_lookups\n\n\nclass RelatedPopulator:\n    \"\"\"\n    RelatedPopulator is used for select_related() object instantiation.\n\n    The idea is that each select_related() model will be populated by a\n    different RelatedPopulator instance. The RelatedPopulator instances get\n    klass_info and select (computed in SQLCompiler) plus the used db as\n    input for initialization. That data is used to compute which columns\n    to use, how to instantiate the model, and how to populate the links\n    between the objects.\n\n    The actual creation of the objects is done in populate() method. This\n    method gets row and from_obj as input and populates the select_related()\n    model instance.\n    \"\"\"\n\n    def __init__(self, klass_info, select, db):\n        self.db = db\n        # Pre-compute needed attributes. The attributes are:\n        #  - model_cls: the possibly deferred model class to instantiate\n        #  - either:\n        #    - cols_start, cols_end: usually the columns in the row are\n        #      in the same order model_cls.__init__ expects them, so we\n        #      can instantiate by model_cls(*row[cols_start:cols_end])\n        #    - reorder_for_init: When select_related descends to a child\n        #      class, then we want to reuse the already selected parent\n        #      data. However, in this case the parent data isn't necessarily\n        #      in the same order that Model.__init__ expects it to be, so\n        #      we have to reorder the parent data. The reorder_for_init\n        #      attribute contains a function used to reorder the field data\n        #      in the order __init__ expects it.\n        #  - pk_idx: the index of the primary key field in the reordered\n        #    model data. Used to check if a related object exists at all.\n        #  - init_list: the field attnames fetched from the database. For\n        #    deferred models this isn't the same as all attnames of the\n        #    model's fields.\n        #  - related_populators: a list of RelatedPopulator instances if\n        #    select_related() descends to related models from this model.\n        #  - local_setter, remote_setter: Methods to set cached values on\n        #\n... File content truncated due to length ... \n\n</file>\n<last_try>\n<last_terminal_session>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 14 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..............\n----------------------------------------------------------------------\nRan 14 tests in 0.032s\n\nOK\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.032s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.040s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.034s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.041s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.047s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.036s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.031s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.038s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.039s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.039s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.043s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<bash_command_executed command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\">\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.045s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'...\n</bash_command_executed>\n<latest_failures>\n<failure>The string to replace '    def get_related_selections(self, select, select_mask):\n        \"\"\"\n        Fill in the information needed for a select_related query.\n        \"\"\"\n\n        def _get_field_choices():\n            direct_choices = (f.name for f in opts.fields if f.is_relation)\n            reverse_choices = (\n                f.field.related_query_name()\n                for f in opts.related_objects\n                if f.field.unique\n            )\n            return chain(\n                direct_choices, reverse_choices, self.query._filtered_relations\n            )\n\n        related_klass_infos = []\n        opts = self.query.get_meta()\n        \n        if not opts:\n            return related_klass_infos' was not found in the file. Please check your old_string: Indentation really matters! When editing a file, make sure to insert appropriate indentation before each line!</failure>\n</latest_failures>\n</last_terminal_session>\n<git_diff>diff --git a/tests/select_related/tests.py b/tests/select_related/tests.py\nindex 68fe7a906f..b4a6478f3f 100644\n--- a/tests/select_related/tests.py\n+++ b/tests/select_related/tests.py\n@@ -194,6 +194,30 @@ class SelectRelatedTests(TestCase):\n         with self.assertNumQueries(1):\n             self.assertEqual(species.genus.species_set.first().name, \"melanogaster\")\n \n+    def test_only_with_reverse_one_to_one(self):\n+        \"\"\"\n+        Test that only() works correctly with select_related() on reverse one-to-one relations.\n+        \"\"\"\n+        # Create a hybrid species with a parent\n+        parent_1, parent_2 = Species.objects.all()[:2]\n+        hybrid = HybridSpecies.objects.create(\n+            name=\"hybrid\", parent_1=parent_1, parent_2=parent_2\n+        )\n+        \n+        # Query using only() with select_related() on the reverse relation\n+        qs = Species.objects.filter(pk=parent_1.pk).select_related(\n+            \"child_1\"\n+        ).only(\"name\", \"child_1__name\")\n+        \n+        # Check that the query returns the correct object\n+        obj = qs.get()\n+        self.assertEqual(obj.name, parent_1.name)\n+        self.assertEqual(obj.child_1.name, \"hybrid\")\n+        \n+        # Verify that other fields are deferred\n+        self.assertIs(obj.child_1.__class__, HybridSpecies)\n+        self.assertIs(type(obj.child_1.parent_2_id), int)  # Should be deferred but FK still accessible\n+\n     def test_select_related_after_values(self):\n         \"\"\"\n         Running select_related() after calling values() raises a TypeError\n@@ -281,4 +305,4 @@ class SelectRelatedValidationTests(SimpleTestCase):\n         with self.assertRaisesMessage(\n             FieldError, self.invalid_error % (\"content_object\", \"content_type\")\n         ):\n-            list(TaggedItem.objects.select_related(\"content_object\"))\n+            list(TaggedItem.objects.select_related(\"content_object\"))\n\\ No newline at end of file</git_diff>\n</last_try>\n</workspace>\n\n\nNow, review the following XML tools that you'll use to interact with the workspace:\n\n<xml_tools>\n{\n  \"SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS\": \"\\n        <!-- Repository Tool: SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS -->\\n        <!-- Use when all tests of last_try pass and the issue is resolved -->\\n\\n        <!-- No Parameters Required -->\\n\\n        <!-- Mark the PR as solved -->\\n        <SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS />\\n\\n        <!-- Important Notes:\\n             - Only use when all test files of last_try are working perfectly\\n             - Ensure edge cases are covered and existing tests pass\\n             - Use this tool only when the implementation works perfectly and all tests pass\\n        -->\\n        \",\n  \"create_file\": \"\\n        <!-- Create File Tool -->\\n        <!-- Create a new file with specified content -->\\n\\n        <!-- Parameters:\\n             - path: The file path to create (REQUIRED)\\n             - content: The content to write into the file (REQUIRED)\\n        -->\\n        <create_file path=\\\"/testbed/.../new_file.py\\\">\\nprint(\\\"Hello, World!\\\")\\n        </create_file>\\n        \",\n  \"edit_file\": \"\\n        <!-- Edit File Tool -->\\n        <!-- Edit an existing file by replacing specified strings -->\\n\\n        <!-- Parameters:\\n            - path: The file path to edit (REQUIRED)\\n            - replacements: List of string replacements (REQUIRED)\\n        -->\\n\\n        <!-- Note: For accurate replacements, ensure you match the exact indentation of the exact strings. -->\\n\\n        <edit_file path=\\\"/testbed/.../example.py\\\">\\n            <replacements>\\n                <replacement>\\n                    <old_string>foo</old_string>\\n                    <new_string>bar</new_string>\\n                </replacement>\\n                <replacement>\\n                    <old_string>hello</old_string>\\n                    <new_string>world</new_string>\\n                </replacement>\\n            </replacements>\\n        </edit_file>\\n        \",\n  \"open_file\": \"\\n        <!-- Open File Tool -->\\n        <!-- Add a file to the workspace to view its content -->\\n\\n        <!-- Parameters:\\n             - path: The file path to add to the workspace (REQUIRED)\\n        -->\\n        <!-- It's recommended to open multiple relevant files in the same time like this -->\\n        <open_file path=\\\"/testbed/.../example.py\\\" />\\n        <open_file path=\\\"/testbed/.../example2.py\\\" />\\n        <open_file path=\\\"/testbed/.../example3.py\\\" />\\n        \",\n  \"run_bash\": \"\\n        <!-- Run Bash Command Tool -->\\n        <!-- Please AVOID commands that can produce lengthy output -->\\n\\n        <!-- Examples -->\\n        <!-- Avoid -v for verbose output; instead use the recommended options like the following -->\\n        <run_bash command=\\\"python -m pytest /testbed/.../test_example.py -q -vv --tb=short --no-header -rFE\\\" />\\n\\n        <!-- For Django-like recommended command-->\\n        <run_bash command=\\\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite --parallel 1 example.test_example \\\" />\\n\\n        \",\n  \"track_implementation\": \"\\n        <!-- Track Implementation Tool -->\\n        <!-- Track implementation trials with IDs, statuses, and notes -->\\n\\n        <!-- Example Usage -->\\n        <track_implementation id=\\\"A\\\" status=\\\"currently implementing;waiting for test\\\">\\n        [Approach Title]\\n        `file:/testbed/.../example.py\\n        [Short update snippet]\\n        `\\n        `file:/testbed/.../example2.py\\n        [Short update snippet]\\n        `\\n        [Analysis] \\n        [Log based on last try]\\n        [Test results summary]\\n        </track_implementation>\\n        \\n        <track_implementation id=\\\"B\\\" status=\\\"tried; not working, bad resolution\\\">\\n        [...example content...]\\n        </track_implementation>\\n\\n        <track_implementation id=\\\"C\\\" status=\\\"not tried\\\">\\n        [...example content...]\\n        </track_implementation>\\n        \",\n  \"view_folder\": \"\\n        <!-- Repository View Folder Tool -->\\n        <!-- Add directory to workspace to view its contents -->\\n\\n        <!-- Parameters Description:\\n             - path: Directory path to add to workspace (REQUIRED)\\n             - depth: Maximum directory depth to search for contents (optional)\\n        -->\\n\\n        <!-- Add directory to workspace with depth -->\\n        <view_folder path=\\\"/testbed\\\" depth=\\\"2\\\" />\\n\\n        <!-- Important Notes:\\n             - Path should be absolute path from repository root\\n             - Hidden files and directories are automatically excluded\\n        -->\\n        \"\n}\n</xml_tools>\n\nA Python code repository has been uploaded to the `/testbed` directory. Consider the following PR description:\n\n<pr_description>\nQuerySet.only() doesn't work with select_related() on a reverse OneToOneField relation.\nDescription\n\t\nOn Django 4.2 calling only() with select_related() on a query using the reverse lookup for a OneToOne relation does not generate the correct query.\nAll the fields from the related model are still included in the generated SQL.\nSample models:\nclass Main(models.Model):\n\tmain_field_1 = models.CharField(blank=True, max_length=45)\n\tmain_field_2 = models.CharField(blank=True, max_length=45)\n\tmain_field_3 = models.CharField(blank=True, max_length=45)\nclass Secondary(models.Model):\n\tmain = models.OneToOneField(Main, primary_key=True, related_name='secondary', on_delete=models.CASCADE)\n\tsecondary_field_1 = models.CharField(blank=True, max_length=45)\n\tsecondary_field_2 = models.CharField(blank=True, max_length=45)\n\tsecondary_field_3 = models.CharField(blank=True, max_length=45)\nSample code:\nMain.objects.select_related('secondary').only('main_field_1', 'secondary__secondary_field_1')\nGenerated query on Django 4.2.1:\nSELECT \"bugtest_main\".\"id\", \"bugtest_main\".\"main_field_1\", \"bugtest_secondary\".\"main_id\", \"bugtest_secondary\".\"secondary_field_1\", \"bugtest_secondary\".\"secondary_field_2\", \"bugtest_secondary\".\"secondary_field_3\" FROM \"bugtest_main\" LEFT OUTER JOIN \"bugtest_secondary\" ON (\"bugtest_main\".\"id\" = \"bugtest_secondary\".\"main_id\")\nGenerated query on Django 4.1.9:\nSELECT \"bugtest_main\".\"id\", \"bugtest_main\".\"main_field_1\", \"bugtest_secondary\".\"main_id\", \"bugtest_secondary\".\"secondary_field_1\" FROM \"bugtest_main\" LEFT OUTER JOIN \"bugtest_secondary\" ON (\"bugtest_main\".\"id\" = \"bugtest_secondary\".\"main_id\")\n\n</pr_description>\n\nFollow this systematic approach to address the issue:\n\n1. Initial Assessment\n   - Review workspace files and the PR description.\n   - Identify key components and their relationships.\n   - Document your initial observations and concerns.\n   - Ensure relevant files and existing tests are opened.\n   - Understand their functionality in relation to the PR description.\n\n2. Detailed Analysis\n   - Examine relevant files in depth.\n   - Map out dependencies and interactions between components.\n   - Identify areas that may be impacted by changes.\n   - If available, review the last attempt and analyze test outputs if it failed.\n\n3. Solution Exploration\n   - Aim to make minimal changes to solve the problem efficiently.\n   - Consider multiple approaches to solve the problem.\n   - For each approach, document:\n     - Pros and cons\n     - Potential drawbacks\n     - Possible failure modes\n   - Think through edge cases and maintenance implications.\n   - Propose multiple solutions.\n   - If <IMPLEMENTATION_TRAILS> are available:\n     - Review existing trials\n     - Update their status based on the last attempt results\n     - Analyze what worked and what didn't\n     - Modify approaches based on your learnings\n   - Use the `track_implementation` tool within <PROPOSE_SOLUTIONS> to:\n     - Add new trials if necessary\n     - Update existing trials\n     - Include detailed notes.\n     - Update status appropriately\n   - Ensure comprehensive coverage of the solution space.\n   - If the current implementation fails multiple times:\n     - Document the failure in detail\n     - Try the next best solution approach\n     - Keep iterating until you find a working solution\n   - Never settle for partial success - all tests must pass.\n\n4. Implementation Strategy\n   - Break down the changes into logical steps.\n   - Focus on minimal and precise modifications.\n   - Plan verification points throughout the implementation.\n   - Consider potential rollback scenarios.\n   - Choose the best solution that:\n     - Fully addresses the root cause of the issue\n     - Maintains existing functionalities\n     - Does not introduce regressions\n     - Prioritizes correctness and robustness over simplicity when necessary\n\nImportant Guidelines:\n- Base all reasoning on the provided workspace; avoid making assumptions.\n- Only modify files that are opened in the workspace.\n- Deeply understand the context before making any changes.\n- Consider potential side effects of each modification.\n- Check test directories to ensure test paths exist.\n- Append new tests for PR by modifying existing tests files only, but never edit existing testcases.\n- Keep iterating with different approaches until all tests pass.\n- Do not give up if tests fail; always try alternative solutions.\n\nDocument your complete reasoning process by wrapping your analysis in these tags:\n- <PREVIOUS_ATTEMPT_ANALYSIS>: Review previous attempt results, including what worked, what failed, and potential reasons for failure.\n- <OBSERVE_WORKSPACE>: Analyze the current workspace state, listing key files, their purposes, and notable dependencies between them.\n- <REASON>: Detail your step-by-step thinking, including consideration of edge cases and potential side effects.\n- <PROPOSE_SOLUTIONS>: List multiple best approaches, minimal or complex, to solve the problem, including code snippets and analysis.\n- <POSSIBLE_FIX>: Document the selected solution rationale.\n\nImplementation Guidelines:\n- Execute multiple actions as needed.\n- Always run tests after modifications and add new tests to confirm the PR.\n- Wait for action results before proceeding.\n- Modify existing tests only.\n- Use `track_implementation` in <PROPOSE_SOLUTIONS>.\n\nCritical Reminders:\n- Think deeply about each step.\n- Consider all implications before making changes.\n- Document your reasoning thoroughly.\n- Validate your assumptions.\n- Consider long-term maintainability.\n- If tests are not found, examine the relevant `tests` directory to locate correct test paths.\n- Update trial status and notes based on previous attempts.\n- Ensure new tests for this PR are created and executed.\n- Only propose solutions, edit file when all relevant files are already opened in the workspace.\n- Only run tests after having the correct test paths.\n- Use the `<SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS>` tool only when the output of last attempt show all tests pass and you are confident that the issue is fully resolved.\n\nYou will operate autonomously from this point forward.\nBegin your analysis and problem-solving process with the `<PREVIOUS_ATTEMPT_ANALYSIS>` tag, followed by `<OBSERVE_WORKSPACE>`, `<REASON>`, `<PROPOSE_SOLUTIONS>`, and `<POSSIBLE_FIX>` tags to document your thought process. \nFinally, list all actions within the `<EXECUTE_ACTIONS>` tag and await the results. \n\nThink deeply and proceed step-by-step through each stage of the process. Your thinking should be thorough, and it's fine if it's very long.\n"}, {"role": "assistant", "content": "I'll analyze the issue and propose a solution following the systematic approach.\n\n<PREVIOUS_ATTEMPT_ANALYSIS>\nFrom the last terminal session, I observe:\n\n1. Test failures:\n- The test `test_only_with_reverse_one_to_one` is failing\n- Error: `FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus`\n- This indicates that the reverse one-to-one relation 'child_1' is not being recognized as a valid field for select_related()\n\n2. Previous implementation attempts:\n- Multiple attempts focused on modifying get_related_selections()\n- The core issue appears to be that reverse one-to-one relations are not properly handled in field validation\n- The error suggests that only forward relations (like 'genus') are being considered valid\n\n3. Key insights:\n- The field validation is failing before the query generation\n- The implementation needs to properly recognize reverse one-to-one relations\n- The field choices need to include reverse relations in validation\n</PREVIOUS_ATTEMPT_ANALYSIS>\n\n<OBSERVE_WORKSPACE>\nKey files in workspace:\n\n1. /testbed/django/db/models/sql/compiler.py\n- Contains SQLCompiler class with get_related_selections() method\n- Handles query compilation and field validation\n- Critical for select_related() functionality\n\n2. /testbed/tests/select_related/tests.py\n- Contains test cases including the failing test_only_with_reverse_one_to_one\n- Tests the interaction between only() and select_related()\n- Models defined: Species, HybridSpecies with one-to-one relations\n\n3. /testbed/tests/select_related/models.py\n- Contains test models including Species and HybridSpecies\n- HybridSpecies has OneToOneField to Species with related_name='child_1'\n\n4. /testbed/django/db/models/fields/related.py\n- Contains related field implementations including OneToOneField\n- Defines field descriptors and relation handling\n\nThe issue appears to be in the validation and handling of reverse one-to-one relations in select_related() when combined with only().\n</OBSERVE_WORKSPACE>\n\n<REASON>\n1. Root Cause Analysis:\n- The get_related_selections() method in SQLCompiler is not properly handling reverse one-to-one relations\n- Field validation is only checking forward relations (like 'genus')\n- The _get_field_choices() function needs to include reverse relations\n- The error occurs during validation before query generation\n\n2. Key Requirements:\n- Must properly validate reverse one-to-one relations\n- Need to handle field masking with only() correctly\n- Maintain compatibility with existing select_related behavior\n- Support proper query optimization\n\n3. Solution Requirements:\n- Update field validation to recognize reverse relations\n- Properly handle field selection with only()\n- Maintain existing behavior for forward relations\n- Ensure efficient query generation\n\n4. Edge Cases:\n- Multiple reverse relations\n- Nested relations\n- Mixed forward and reverse relations\n- Deferred fields\n- Non-existent fields\n</REASON>\n\n<PROPOSE_SOLUTIONS>\n<track_implementation id=\"O\" status=\"currently implementing\">\n[Approach: Enhanced Reverse Relation Recognition]\n\nKey changes:\n1. Modify get_related_selections() to properly handle reverse relations:\n```python\ndef get_related_selections(self, select, select_mask):\n    \"\"\"\n    Fill in the information needed for a select_related query.\n    \"\"\"\n    def _get_field_choices():\n        direct_choices = (f.name for f in opts.fields if f.is_relation)\n        reverse_choices = (\n            f.get_accessor_name()  # Use accessor name for reverse relations\n            for f in opts.related_objects\n            if f.field.unique or f.one_to_one  # Include one-to-one fields\n        )\n        return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n    related_klass_infos = []\n    opts = self.query.get_meta()\n    \n    if not opts:\n        return related_klass_infos\n\n    if restricted:\n        fields_found = set()\n        for name in self.query.select_related:\n            # Handle reverse relations\n            related_field = None\n            for f in opts.related_objects:\n                if f.get_accessor_name() == name:\n                    related_field = f\n                    break\n                    \n            if related_field:\n                fields_found.add(name)\n                related_select_mask = select_mask.get(name) if select_mask else None\n                klass_info = {\n                    'model': related_field.related_model,\n                    'field': related_field.field,\n                    'reverse': True,\n                    'local_setter': related_field.field.set_cached_value,\n                    'remote_setter': related_field.field.remote_field.set_cached_value,\n                    'from_parent': False\n                }\n                related_klass_infos.append(klass_info)\n                \n                # Handle field selection for only()\n                select_fields = []\n                if related_select_mask:\n                    for field in related_field.related_model._meta.concrete_fields:\n                        if field.attname in related_select_mask:\n                            select_fields.append(len(select))\n                            select.append((field.get_col(related_field.field.db_table), None))\n                klass_info['select_fields'] = select_fields\n\n            # Handle forward relations as before\n            else:\n                field = opts.get_field(name)\n                if hasattr(field, 'get_path_info'):\n                    klass_info = self.get_related_klass_info(select, field, field.remote_field.model)\n                    related_klass_infos.append(klass_info)\n\n    return related_klass_infos\n```\n\nPros:\n- Properly handles reverse one-to-one relations\n- Maintains existing behavior for forward relations\n- Correctly applies field selection from only()\n- Handles edge cases properly\n\nCons:\n- More complex implementation\n- Potential performance impact for complex queries\n\nAnalysis:\nThis approach fixes the core issue by:\n1. Using get_accessor_name() for reverse relations\n2. Including one-to-one fields in valid choices\n3. Properly handling field selection\n4. Maintaining existing behavior for other relations\n</track_implementation>\n</PROPOSE_SOLUTIONS>\n\n<POSSIBLE_FIX>\nBased on the analysis, I recommend implementing the \"Enhanced Reverse Relation Recognition\" approach because:\n\n1. It directly addresses the root cause by properly handling reverse one-to-one relations\n2. Maintains compatibility with existing functionality\n3. Correctly implements field selection with only()\n4. Handles edge cases appropriately\n5. Follows Django's design patterns\n\nThe implementation will:\n1. Update get_related_selections() to properly handle reverse relations\n2. Use correct accessor names for reverse relations\n3. Support field selection through only()\n4. Maintain existing behavior for forward relations\n</POSSIBLE_FIX>\n\n<EXECUTE_ACTIONS>\n1. First, let's edit the compiler.py file:\n\n<edit_file path=\"/testbed/django/db/models/sql/compiler.py\">\n    <replacements>\n        <replacement>\n            <old_string>    def get_related_selections(self, select, select_mask):\n        \"\"\"\n        Fill in the information needed for a select_related query.\n        \"\"\"\n\n        def _get_field_choices():\n            direct_choices = (f.name for f in opts.fields if f.is_relation)\n            reverse_choices = (\n                f.field.related_query_name()\n                for f in opts.related_objects\n                if f.field.unique\n            )\n            return chain(\n                direct_choices, reverse_choices, self.query._filtered_relations\n            )\n\n        related_klass_infos = []\n        opts = self.query.get_meta()\n        \n        if not opts:\n            return related_klass_infos</old_string>\n            <new_string>    def get_related_selections(self, select, select_mask):\n        \"\"\"\n        Fill in the information needed for a select_related query.\n        \"\"\"\n        def _get_field_choices():\n            direct_choices = (f.name for f in opts.fields if f.is_relation)\n            reverse_choices = (\n                f.get_accessor_name()  # Use accessor name for reverse relations\n                for f in opts.related_objects\n                if f.field.unique or f.one_to_one  # Include one-to-one fields\n            )\n            return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n\n        related_klass_infos = []\n        opts = self.query.get_meta()\n        \n        if not opts:\n            return related_klass_infos</new_string>\n        </replacement>\n    </replacements>\n</edit_file>\n\n2. Let's run the tests to verify the changes:\n\n<run_bash command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\" />\n\n"}, {"role": "user", "content": "Result for <track_implementation id=\"O\" status=\"currently implementing\">:\nImplementation trial 'O' status updated to 'currently implementing'."}, {"role": "user", "content": "Result for <edit_file path=\"/testbed/django/db/models/sql/compiler.py\">:\nThe string to replace '    def get_related_selections(self, select, select_mask):\n        \"\"\"\n        Fill in the information needed for a select_related query.\n        \"\"\"\n\n        def _get_field_choices():\n            direct_choices = (f.name for f in opts.fields if f.is_relation)\n            reverse_choices = (\n                f.field.related_query_name()\n                for f in opts.related_objects\n                if f.field.unique\n            )\n            return chain(\n                direct_choices, reverse_choices, self.query._filtered_relations\n            )\n\n        related_klass_infos = []\n        opts = self.query.get_meta()\n        \n        if not opts:\n            return related_klass_infos' was not found in the file. Please check your old_string: Indentation really matters! When editing a file, make sure to insert appropriate indentation before each line!"}, {"role": "user", "content": "Result for <run_bash command=\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite select_related.tests.SelectRelatedTests\" />:\nCommand executed:\nTesting against Django installed in '/testbed/django' with up to 8 processes\nFound 15 test(s).\nSystem check identified no issues (0 silenced).Creating test database for alias 'default'...\n..........E....\n======================================================================\nERROR: test_only_with_reverse_one_to_one (select_related.tests.SelectRelatedTests.test_only_with_reverse_one_to_one)\nTest that only() works correctly with select_related() on reverse one-to-one relations.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"/testbed/tests/select_related/tests.py\", line 213, in test_only_with_reverse_one_to_one\n    obj = qs.get()\n          ^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 625, in get\n    num = len(clone)\n          ^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 379, in __len__\n    self._fetch_all()\n  File \"/testbed/django/db/models/query.py\", line 1892, in _fetch_all\n    self._result_cache = list(self._iterable_class(self))\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/query.py\", line 90, in __iter__\n    results = compiler.execute_sql(\n              ^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1549, in execute_sql\n    sql, params = self.as_sql()\n                  ^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 736, in as_sql\n    extra_select, order_by, group_by = self.pre_sql_setup(\n                                       ^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 84, in pre_sql_setup\n    self.setup_query(with_col_aliases=with_col_aliases)\n  File \"/testbed/django/db/models/sql/compiler.py\", line 73, in setup_query\n    self.select, self.klass_info, self.annotation_col_map = self.get_select(\n                                                            ^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 279, in get_select\n    related_klass_infos = self.get_related_selections(select, select_mask)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/testbed/django/db/models/sql/compiler.py\", line 1367, in get_related_selections\n    raise FieldError(\ndjango.core.exceptions.FieldError: Invalid field name(s) given in select_related: 'child_1'. Choices are: genus\n\n----------------------------------------------------------------------\nRan 15 tests in 0.043s\n\nFAILED (errors=1)\nDestroying test database for alias 'default'..."}]}