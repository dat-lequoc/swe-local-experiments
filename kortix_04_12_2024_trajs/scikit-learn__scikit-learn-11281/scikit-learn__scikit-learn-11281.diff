diff --git a/sklearn/mixture/base.py b/sklearn/mixture/base.py
index a9f66740f..b4708ab99 100644
--- a/sklearn/mixture/base.py
+++ b/sklearn/mixture/base.py
@@ -13,10 +13,9 @@ from time import time
 import numpy as np
 
 from .. import cluster
-from ..base import BaseEstimator
-from ..base import DensityMixin
+from ..base import BaseEstimator, DensityMixin, ClusterMixin
 from ..externals import six
-from ..exceptions import ConvergenceWarning
+from ..exceptions import ConvergenceWarning, NotFittedError, NotFittedError
 from ..utils import check_array, check_random_state
 from ..utils.fixes import logsumexp
 
@@ -64,7 +63,7 @@ def _check_X(X, n_components=None, n_features=None, ensure_min_samples=1):
     return X
 
 
-class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):
+class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, ClusterMixin, BaseEstimator)):
     """Base class for mixture models.
 
     This abstract class specifies an interface for all mixture classes and
@@ -169,6 +168,40 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):
         """
         pass
 
+    @property
+    def n_clusters(self):
+        """Number of clusters (alias for n_components)."""
+        return self.n_components
+
+    @property
+    def labels_(self):
+        """Get cluster labels for training data.
+        
+        Returns
+        -------
+        labels : array, shape (n_samples,)
+            Component labels.
+        """
+        if not hasattr(self, 'means_'):
+            raise NotFittedError("This %s instance is not fitted yet" % type(self).__name__)
+        return self._last_labels if hasattr(self, '_last_labels') else None
+
+    def fit_predict(self, X, y=None):
+        """Fit the model and predict labels for X.
+        
+        Parameters
+        ----------
+        X : array-like, shape (n_samples, n_features)
+            List of n_features-dimensional data points.
+            Each row corresponds to a single data point.
+        
+        Returns
+        -------
+        labels : array, shape (n_samples,)
+            Component labels.
+        """
+        return self.fit(X).predict(X)
+
     def fit(self, X, y=None):
         """Estimate model parameters with the EM algorithm.
 
@@ -239,6 +272,9 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):
 
         self._set_parameters(best_params)
         self.n_iter_ = best_n_iter
+        
+        # Store labels for the training data
+        self._last_labels = self.predict(X)
 
         return self
 
@@ -500,4 +536,4 @@ class BaseMixture(six.with_metaclass(ABCMeta, DensityMixin, BaseEstimator)):
             print("Initialization converged: %s" % self.converged_)
         elif self.verbose >= 2:
             print("Initialization converged: %s\t time lapse %.5fs\t ll %.5f" %
-                  (self.converged_, time() - self._init_prev_time, ll))
+                  (self.converged_, time() - self._init_prev_time, ll))
\ No newline at end of file
diff --git a/sklearn/mixture/tests/test_gaussian_mixture.py b/sklearn/mixture/tests/test_gaussian_mixture.py
index 08a083abf..e404b3512 100644
--- a/sklearn/mixture/tests/test_gaussian_mixture.py
+++ b/sklearn/mixture/tests/test_gaussian_mixture.py
@@ -671,6 +671,30 @@ def test_multiple_init():
         assert_greater_equal(train2, train1)
 
 
+def test_gaussian_mixture_clustering_interface():
+    # Test clustering interface compatibility
+    rng = np.random.RandomState(0)
+    n_samples, n_features = 50, 2
+    X = rng.randn(n_samples, n_features)
+    
+    gmm = GaussianMixture(n_components=2, random_state=rng)
+    
+    # Test n_clusters property
+    assert_equal(gmm.n_clusters, 2)
+    
+    # Test labels_ property before fit
+    assert_raise_message(NotFittedError,
+                        "This GaussianMixture instance is not fitted yet",
+                        lambda: gmm.labels_)
+    
+    # Test fit_predict
+    labels = gmm.fit_predict(X)
+    assert_equal(labels.shape, (n_samples,))
+    assert_array_equal(labels, gmm.predict(X))
+    
+    # Test labels_ after fit
+    assert_array_equal(gmm.labels_, labels)
+
 def test_gaussian_mixture_n_parameters():
     # Test that the right number of parameters is estimated
     rng = np.random.RandomState(0)
@@ -980,4 +1004,4 @@ def test_init():
     gmm2 = GaussianMixture(n_components=n_components, n_init=100,
                            max_iter=1, random_state=random_state).fit(X)
 
-    assert_greater(gmm2.lower_bound_, gmm1.lower_bound_)
+    assert_greater(gmm2.lower_bound_, gmm1.lower_bound_)
\ No newline at end of file
