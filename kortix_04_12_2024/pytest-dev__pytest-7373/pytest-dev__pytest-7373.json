{
  "instance_id": "pytest-dev__pytest-7373",
  "model_patch": "diff --git a/src/_pytest/mark/evaluate.py b/src/_pytest/mark/evaluate.py\nindex 759191668..695ab9951 100644\n--- a/src/_pytest/mark/evaluate.py\n+++ b/src/_pytest/mark/evaluate.py\n@@ -15,20 +15,13 @@ from _pytest.nodes import Item\n from _pytest.store import StoreKey\n \n \n-evalcache_key = StoreKey[Dict[str, Any]]()\n+# Removed cache key as caching is no longer used\n \n \n-def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n-    default = {}  # type: Dict[str, object]\n-    evalcache = config._store.setdefault(evalcache_key, default)\n-    try:\n-        return evalcache[expr]\n-    except KeyError:\n-        import _pytest._code\n-\n-        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n-        evalcache[expr] = x = eval(exprcode, d)\n-        return x\n+def _eval_expr(expr: str, d: Dict[str, object]) -> Any:\n+    import _pytest._code\n+    exprcode = _pytest._code.compile(expr, mode=\"eval\")\n+    return eval(exprcode, d)\n \n \n class MarkEvaluator:\n@@ -98,7 +91,7 @@ class MarkEvaluator:\n                     self.expr = expr\n                     if isinstance(expr, str):\n                         d = self._getglobals()\n-                        result = cached_eval(self.item.config, expr, d)\n+                        result = _eval_expr(expr, d)\n                     else:\n                         if \"reason\" not in mark.kwargs:\n                             # XXX better be checked at collection time\n@@ -132,4 +125,4 @@ class MarkEvaluator:\n                 return \"\"\n             else:\n                 return \"condition: \" + str(self.expr)\n-        return expl\n+        return expl\n\\ No newline at end of file\ndiff --git a/testing/test_mark.py b/testing/test_mark.py\nindex cdd4df9dd..547c3a253 100644\n--- a/testing/test_mark.py\n+++ b/testing/test_mark.py\n@@ -1008,6 +1008,28 @@ def test_addmarker_order():\n \n \n @pytest.mark.filterwarnings(\"ignore\")\n+def test_skipif_with_globals(testdir):\n+    \"\"\"Verify that skipif conditions are correctly evaluated with module globals.\"\"\"\n+    testdir.makepyfile(test_module1=\"\"\"\n+        import pytest\n+        skip = True\n+        @pytest.mark.skipif(\"skip\")\n+        def test_should_skip():\n+            assert False\n+    \"\"\")\n+    testdir.makepyfile(test_module2=\"\"\"\n+        import pytest\n+        skip = False\n+        @pytest.mark.skipif(\"skip\")\n+        def test_should_not_skip():\n+            assert False\n+    \"\"\")\n+    result = testdir.runpytest(\"test_module1.py\", \"test_module2.py\")\n+    result.stdout.fnmatch_lines([\n+        \"collected 2 items\",\n+        \"*= 1 failed, 1 skipped in*\",\n+    ])\n+\n def test_markers_from_parametrize(testdir):\n     \"\"\"#3605\"\"\"\n     testdir.makepyfile(\n@@ -1071,4 +1093,4 @@ def test_marker_expr_eval_failure_handling(testdir, expr):\n     expected = \"ERROR: Wrong expression passed to '-m': {}: *\".format(expr)\n     result = testdir.runpytest(foo, \"-m\", expr)\n     result.stderr.fnmatch_lines([expected])\n-    assert result.ret == ExitCode.USAGE_ERROR\n+    assert result.ret == ExitCode.USAGE_ERROR\n\\ No newline at end of file\n",
  "model_name_or_path": "KortixAI"
}