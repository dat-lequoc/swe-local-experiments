{"messages": [{"role": "user", "content": "First, examine the current state of the workspace:\n<workspace>\n<directory path=\"/testbed\">\n/testbed/AUTHORS\n/testbed/CITATION\n/testbed/LICENSE\n/testbed/azure-pipelines.yml\n/testbed/bench\n/testbed/changelog\n/testbed/doc\n/testbed/extra\n/testbed/pyproject.toml\n/testbed/scripts\n/testbed/setup.cfg\n/testbed/setup.py\n/testbed/src\n/testbed/testing\n/testbed/tox.ini\n</directory>\n<directory path=\"/testbed/src\">\n/testbed/src/__pycache__\n/testbed/src/_pytest\n/testbed/src/_pytest/__init__.py\n/testbed/src/_pytest/__pycache__\n/testbed/src/_pytest/_argcomplete.py\n/testbed/src/_pytest/_code\n/testbed/src/_pytest/_io\n/testbed/src/_pytest/_version.py\n/testbed/src/_pytest/assertion\n/testbed/src/_pytest/cacheprovider.py\n/testbed/src/_pytest/capture.py\n/testbed/src/_pytest/compat.py\n/testbed/src/_pytest/config\n/testbed/src/_pytest/debugging.py\n/testbed/src/_pytest/deprecated.py\n/testbed/src/_pytest/doctest.py\n/testbed/src/_pytest/faulthandler.py\n/testbed/src/_pytest/fixtures.py\n/testbed/src/_pytest/freeze_support.py\n/testbed/src/_pytest/helpconfig.py\n/testbed/src/_pytest/hookspec.py\n/testbed/src/_pytest/junitxml.py\n/testbed/src/_pytest/logging.py\n/testbed/src/_pytest/main.py\n/testbed/src/_pytest/mark\n/testbed/src/_pytest/monkeypatch.py\n/testbed/src/_pytest/nodes.py\n/testbed/src/_pytest/nose.py\n/testbed/src/_pytest/outcomes.py\n/testbed/src/_pytest/pastebin.py\n/testbed/src/_pytest/pathlib.py\n/testbed/src/_pytest/pytester.py\n/testbed/src/_pytest/python.py\n/testbed/src/_pytest/python_api.py\n/testbed/src/_pytest/recwarn.py\n/testbed/src/_pytest/reports.py\n/testbed/src/_pytest/resultlog.py\n/testbed/src/_pytest/runner.py\n/testbed/src/_pytest/setuponly.py\n/testbed/src/_pytest/setupplan.py\n/testbed/src/_pytest/skipping.py\n/testbed/src/_pytest/stepwise.py\n/testbed/src/_pytest/terminal.py\n/testbed/src/_pytest/tmpdir.py\n/testbed/src/_pytest/unittest.py\n/testbed/src/_pytest/warning_types.py\n/testbed/src/_pytest/warnings.py\n/testbed/src/pytest.py\n</directory>\n<directory path=\"/testbed/testing\">\n/testbed/testing/__pycache__\n/testbed/testing/acceptance_test.py\n/testbed/testing/code\n/testbed/testing/code/test_code.py\n/testbed/testing/code/test_excinfo.py\n/testbed/testing/code/test_source.py\n/testbed/testing/conftest.py\n/testbed/testing/deprecated_test.py\n/testbed/testing/example_scripts\n/testbed/testing/example_scripts/acceptance\n/testbed/testing/example_scripts/collect\n/testbed/testing/example_scripts/config\n/testbed/testing/example_scripts/conftest_usageerror\n/testbed/testing/example_scripts/dataclasses\n/testbed/testing/example_scripts/deprecated\n/testbed/testing/example_scripts/fixtures\n/testbed/testing/example_scripts/issue88_initial_file_multinodes\n/testbed/testing/example_scripts/issue_519.py\n/testbed/testing/example_scripts/marks\n/testbed/testing/example_scripts/perf_examples\n/testbed/testing/example_scripts/tmpdir\n/testbed/testing/example_scripts/unittest\n/testbed/testing/example_scripts/warnings\n/testbed/testing/examples\n/testbed/testing/examples/test_issue519.py\n/testbed/testing/freeze\n/testbed/testing/freeze/create_executable.py\n/testbed/testing/freeze/runtests_script.py\n/testbed/testing/freeze/tests\n/testbed/testing/freeze/tox_run.py\n/testbed/testing/io\n/testbed/testing/io/test_saferepr.py\n/testbed/testing/logging\n/testbed/testing/logging/test_fixture.py\n/testbed/testing/logging/test_formatter.py\n/testbed/testing/logging/test_reporting.py\n/testbed/testing/python\n/testbed/testing/python/approx.py\n/testbed/testing/python/collect.py\n/testbed/testing/python/fixtures.py\n/testbed/testing/python/integration.py\n/testbed/testing/python/metafunc.py\n/testbed/testing/python/raises.py\n/testbed/testing/python/setup_only.py\n/testbed/testing/python/setup_plan.py\n/testbed/testing/python/show_fixtures_per_test.py\n/testbed/testing/test_argcomplete.py\n/testbed/testing/test_assertion.py\n/testbed/testing/test_assertrewrite.py\n/testbed/testing/test_cacheprovider.py\n/testbed/testing/test_capture.py\n/testbed/testing/test_collection.py\n/testbed/testing/test_compat.py\n/testbed/testing/test_config.py\n/testbed/testing/test_conftest.py\n/testbed/testing/test_doctest.py\n/testbed/testing/test_entry_points.py\n/testbed/testing/test_faulthandler.py\n/testbed/testing/test_helpconfig.py\n/testbed/testing/test_junitxml.py\n/testbed/testing/test_mark.py\n/testbed/testing/test_modimport.py\n/testbed/testing/test_monkeypatch.py\n/testbed/testing/test_nodes.py\n/testbed/testing/test_nose.py\n/testbed/testing/test_parseopt.py\n/testbed/testing/test_pastebin.py\n/testbed/testing/test_pathlib.py\n/testbed/testing/test_pdb.py\n/testbed/testing/test_pluginmanager.py\n/testbed/testing/test_pytester.py\n/testbed/testing/test_recwarn.py\n/testbed/testing/test_reports.py\n/testbed/testing/test_resultlog.py\n/testbed/testing/test_runner.py\n/testbed/testing/test_runner_xunit.py\n/testbed/testing/test_session.py\n/testbed/testing/test_skipping.py\n/testbed/testing/test_stepwise.py\n/testbed/testing/test_terminal.py\n/testbed/testing/test_tmpdir.py\n/testbed/testing/test_unittest.py\n/testbed/testing/test_warning_types.py\n/testbed/testing/test_warnings.py\n</directory>\n<IMPLEMENTATION_TRAILS>\n<implementation_trial id=\"A\" status=\"implementing with fixed indentation\">\n[Enhanced Byte String Representation with Proper Indentation]\n- Show both character and ASCII value for bytes\n- Use hex for non-printable characters\n- Maintain existing behavior for non-byte types\n- Exact indentation matching\n\nKey improvements:\n1. Better readability by showing character representation\n2. Clear ASCII value context\n3. Hex format for non-printable chars\n4. Preserved existing behavior for other types\n\nCode structure with proper indentation:\n```python\ndef _compare_eq_sequence(left, right, verbose=0):\n    explanation = []\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            if isinstance(left, bytes) and isinstance(right, bytes):\n                left_chr = chr(left[i]) if 32 <= left[i] <= 126 else '\\\\x{:02x}'.format(left[i])\n                right_chr = chr(right[i]) if 32 <= right[i] <= 126 else '\\\\x{:02x}'.format(right[i])\n                explanation += [\n                    \"At index {} diff: b'{}' (ASCII {}) != b'{}' (ASCII {})\".format(\n                        i, left_chr, left[i], right_chr, right[i]\n                    )\n                ]\n            else:\n                explanation += [\n                    \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n                ]\n            break\n```\n\nPros:\n+ Clear representation of both character and value\n+ Consistent formatting throughout\n+ Handles all edge cases\n+ Maintains existing functionality\n+ Proper indentation matching\n+ Improved readability\n\nImplementation notes:\n- Will use exact string matching for replacements\n- Careful attention to indentation\n- Comprehensive test coverage\n</implementation_trial>\n<implementation_trial id=\"B\" status=\"not recommended\">\n[Minimal ASCII Value Approach]\n- Show only ASCII values\n- Simpler implementation but less user-friendly\n- Loses character representation context\n\nCons:\n- Less intuitive for debugging\n- Missing visual character representation\n- Not as helpful for users\n</implementation_trial>\n<implementation_trial id=\"C\" status=\"not recommended\">\n[Hybrid Format Approach]\n- Different formats for printable/non-printable\n- Inconsistent presentation\n- More complex logic\n\nCons:\n- Inconsistent user experience\n- More complex maintenance\n- Potential confusion\n</implementation_trial>\n</IMPLEMENTATION_TRAILS>\n<file path=\"/testbed/src/_pytest/python_api.py\">\nimport inspect\nimport math\nimport pprint\nimport sys\nimport warnings\nfrom collections.abc import Iterable\nfrom collections.abc import Mapping\nfrom collections.abc import Sized\nfrom decimal import Decimal\nfrom itertools import filterfalse\nfrom numbers import Number\n\nfrom more_itertools.more import always_iterable\n\nimport _pytest._code\nfrom _pytest import deprecated\nfrom _pytest.compat import STRING_TYPES\nfrom _pytest.outcomes import fail\n\nBASE_TYPE = (type, STRING_TYPES)\n\n\ndef _non_numeric_type_error(value, at):\n    at_str = \" at {}\".format(at) if at else \"\"\n    return TypeError(\n        \"cannot make approximate comparisons to non-numeric values: {!r} {}\".format(\n            value, at_str\n        )\n    )\n\n\n# builtin pytest.approx helper\n\n\nclass ApproxBase:\n    \"\"\"\n    Provide shared utilities for making approximate comparisons between numbers\n    or sequences of numbers.\n    \"\"\"\n\n    # Tell numpy to use our `__eq__` operator instead of its.\n    __array_ufunc__ = None\n    __array_priority__ = 100\n\n    def __init__(self, expected, rel=None, abs=None, nan_ok=False):\n        __tracebackhide__ = True\n        self.expected = expected\n        self.abs = abs\n        self.rel = rel\n        self.nan_ok = nan_ok\n        self._check_type()\n\n    def __repr__(self):\n        raise NotImplementedError\n\n    def __eq__(self, actual):\n        return all(\n            a == self._approx_scalar(x) for a, x in self._yield_comparisons(actual)\n        )\n\n    __hash__ = None\n\n    def __ne__(self, actual):\n        return not (actual == self)\n\n    def _approx_scalar(self, x):\n        return ApproxScalar(x, rel=self.rel, abs=self.abs, nan_ok=self.nan_ok)\n\n    def _yield_comparisons(self, actual):\n        \"\"\"\n        Yield all the pairs of numbers to be compared.  This is used to\n        implement the `__eq__` method.\n        \"\"\"\n        raise NotImplementedError\n\n    def _check_type(self):\n        \"\"\"\n        Raise a TypeError if the expected value is not a valid type.\n        \"\"\"\n        # This is only a concern if the expected value is a sequence.  In every\n        # other case, the approx() function ensures that the expected value has\n        # a numeric type.  For this reason, the default is to do nothing.  The\n        # classes that deal with sequences should reimplement this method to\n        # raise if there are any non-numeric elements in the sequence.\n        pass\n\n\ndef _recursive_list_map(f, x):\n    if isinstance(x, list):\n        return list(_recursive_list_map(f, xi) for xi in x)\n    else:\n        return f(x)\n\n\nclass ApproxNumpy(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is numpy array.\n    \"\"\"\n\n    def __repr__(self):\n        list_scalars = _recursive_list_map(self._approx_scalar, self.expected.tolist())\n        return \"approx({!r})\".format(list_scalars)\n\n    def __eq__(self, actual):\n        import numpy as np\n\n        # self.expected is supposed to always be an array here\n\n        if not np.isscalar(actual):\n            try:\n                actual = np.asarray(actual)\n            except:  # noqa\n                raise TypeError(\"cannot compare '{}' to numpy.ndarray\".format(actual))\n\n        if not np.isscalar(actual) and actual.shape != self.expected.shape:\n            return False\n\n        return ApproxBase.__eq__(self, actual)\n\n    def _yield_comparisons(self, actual):\n        import numpy as np\n\n        # `actual` can either be a numpy array or a scalar, it is treated in\n        # `__eq__` before being passed to `ApproxBase.__eq__`, which is the\n        # only method that calls this one.\n\n        if np.isscalar(actual):\n            for i in np.ndindex(self.expected.shape):\n                yield actual, self.expected[i].item()\n        else:\n            for i in np.ndindex(self.expected.shape):\n                yield actual[i].item(), self.expected[i].item()\n\n\nclass ApproxMapping(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a mapping with\n    numeric values (the keys can be anything).\n    \"\"\"\n\n    def __repr__(self):\n        return \"approx({!r})\".format(\n            {k: self._approx_scalar(v) for k, v in self.expected.items()}\n        )\n\n    def __eq__(self, actual):\n        if set(actual.keys()) != set(self.expected.keys()):\n            return False\n\n        return ApproxBase.__eq__(self, actual)\n\n    def _yield_comparisons(self, actual):\n        for k in self.expected.keys():\n            yield actual[k], self.expected[k]\n\n    def _check_type(self):\n        __tracebackhide__ = True\n        for key, value in self.expected.items():\n            if isinstance(value, type(self.expected)):\n                msg = \"pytest.approx() does not support nested dictionaries: key={!r} value={!r}\\n  full mapping={}\"\n                raise TypeError(msg.format(key, value, pprint.pformat(self.expected)))\n            elif not isinstance(value, Number):\n                raise _non_numeric_type_error(self.expected, at=\"key={!r}\".format(key))\n\n\nclass ApproxSequencelike(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a sequence of\n    numbers.\n    \"\"\"\n\n    def __repr__(self):\n        seq_type = type(self.expected)\n        if seq_type not in (tuple, list, set):\n            seq_type = list\n        return \"approx({!r})\".format(\n            seq_type(self._approx_scalar(x) for x in self.expected)\n        )\n\n    def __eq__(self, actual):\n        if len(actual) != len(self.expected):\n            return False\n        return ApproxBase.__eq__(self, actual)\n\n    def _yield_comparisons(self, actual):\n        return zip(actual, self.expected)\n\n    def _check_type(self):\n        __tracebackhide__ = True\n        for index, x in enumerate(self.expected):\n            if isinstance(x, type(self.expected)):\n                msg = \"pytest.approx() does not support nested data structures: {!r} at index {}\\n  full sequence: {}\"\n                raise TypeError(msg.format(x, index, pprint.pformat(self.expected)))\n            elif not isinstance(x, Number):\n                raise _non_numeric_type_error(\n                    self.expected, at=\"index {}\".format(index)\n                )\n\n\nclass ApproxScalar(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a single number.\n    \"\"\"\n\n    DEFAULT_ABSOLUTE_TOLERANCE = 1e-12\n    DEFAULT_RELATIVE_TOLERANCE = 1e-6\n\n    def __repr__(self):\n        \"\"\"\n        Return a string communicating both the expected value and the tolerance\n        for the comparison being made, e.g. '1.0 +- 1e-6'.  Use the unicode\n        plus/minus symbol if this is python3 (it's too hard to get right for\n        python2).\n        \"\"\"\n        if isinstance(self.expected, complex):\n            return str(self.expected)\n\n        # Infinities aren't compared using tolerances, so don't show a\n        # tolerance.\n        if math.isinf(self.expected):\n            return str(self.expected)\n\n        # If a sensible tolerance can't be calculated, self.tolerance will\n        # raise a ValueError.  In this case, display '???'.\n        try:\n            vetted_tolerance = \"{:.1e}\".format(self.tolerance)\n        except ValueError:\n            vetted_tolerance = \"???\"\n\n        return \"{} \\u00b1 {}\".format(self.expected, vetted_tolerance)\n\n    def __eq__(self, actual):\n        \"\"\"\n        Return true if the given value is equal to the expected value within\n        the pre-specified tolerance.\n        \"\"\"\n        if _is_numpy_array(actual):\n            # Call ``__eq__()`` manually to prevent infinite-recursion with\n            # numpy<1.13.  See #3748.\n            return all(self.__eq__(a) for a in actual.flat)\n\n        # Short-circuit exact equality.\n        if actual == self.expected:\n            return True\n\n        # Allow the user to control whether NaNs are considered equal to each\n        # other or not.  The abs() calls are for compatibility with complex\n        # numbers.\n        if math.isnan(abs(self.expected)):\n            return self.nan_ok and math.isnan(abs(actual))\n\n        # Infinity shouldn't be approximately equal to anything but itself, but\n        # if there's a relative tolerance, it will be infinite and infinity\n        # will seem approximately equal to everything.  The equal-to-itself\n        # case would have been short circuited above, so here we can just\n        # return false if the expected value is infinite.  The abs() call is\n        # for compatibility with complex numbers.\n        if math.isinf(abs(self.expected)):\n            return False\n\n        # Return true if the two numbers are within the tolerance.\n        return abs(self.expected - actual) <= self.tolerance\n\n    __hash__ = None\n\n    @property\n    def tolerance(self):\n        \"\"\"\n        Return the tolerance for the comparison.  This could be either an\n        absolute tolerance or a relative tolerance, depending on what the user\n        specified or which would be larger.\n        \"\"\"\n\n        def set_default(x, default):\n            return x if x is not None else default\n\n        # Figure out what the absolute tolerance should be.  ``self.abs`` is\n        # either None or a value specified by the user.\n        absolute_tolerance = set_default(self.abs, self.DEFAULT_ABSOLUTE_TOLERANCE)\n\n        if absolute_tolerance < 0:\n            raise ValueError(\n                \"absolute tolerance can't be negative: {}\".format(absolute_tolerance)\n            )\n        if math.isnan(absolute_tolerance):\n            raise ValueError(\"absolute tolerance can't be NaN.\")\n\n        # If the user specified an absolute tolerance but not a relative one,\n        # just return the absolute tolerance.\n        if self.rel is None:\n            if self.abs is not None:\n                return absolute_tolerance\n\n        # Figure out what the relative tolerance should be.  ``self.rel`` is\n        # either None or a value specified by the user.  This is done after\n        # we've made sure the user didn't ask for an absolute tolerance only,\n        # because we don't want to raise errors about the relative tolerance if\n        # we aren't even going to use it.\n        relative_tolerance = set_default(\n            self.rel, self.DEFAULT_RELATIVE_TOLERANCE\n        ) * abs(self.expected)\n\n        if relative_tolerance < 0:\n            raise ValueError(\n                \"relative tolerance can't be negative: {}\".format(absolute_tolerance)\n            )\n        if math.isnan(relative_tolerance):\n            raise ValueError(\"relative tolerance can't be NaN.\")\n\n        # Return the larger of the relative and absolute tolerances.\n        return max(relative_tolerance, absolute_tolerance)\n\n\nclass ApproxDecimal(ApproxScalar):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a decimal.\n    \"\"\"\n\n    DEFAULT_ABSOLUTE_TOLERANCE = Decimal(\"1e-12\")\n    DEFAULT_RELATIVE_TOLERANCE = Decimal(\"1e-6\")\n\n\ndef approx(expected, rel=None, abs=None, nan_ok=False):\n    \"\"\"\n    Assert that two numbers (or two sets of numbers) are equal to each other\n    within some tolerance.\n\n    Due to the `intricacies of floating-point arithmetic`__, numbers that we\n    would intuitively expect to be equal are not always so::\n\n        >>> 0.1 + 0.2 == 0.3\n        False\n\n    __ https://docs.python.org/3/tutorial/floatingpoint.html\n\n    This problem is commonly encountered when writing tests, e.g. when making\n    sure that floating-point values are what you expect them to be.  One way to\n    deal with this problem is to assert that two floating-point numbers are\n    equal to within some appropriate tolerance::\n\n        >>> abs((0.1 + 0.2) - 0.3) < 1e-6\n        True\n\n    However, comparisons like this are tedious to write and difficult to\n    understand.  Furthermore, absolute comparisons like the one above are\n    usually discouraged because there's no tolerance that works well for all\n    situations.  ``1e-6`` is good for numbers around ``1``, but too small for\n    very big numbers and too big for very small ones.  It's better to express\n    the tolerance as a fraction of the expected value, but relative comparisons\n    like that are even more difficult to write correctly and concisely.\n\n    The ``approx`` class performs floating-point comparisons using a syntax\n    that's as intuitive as possible::\n\n        >>> from pytest import approx\n        >>> 0.1 + 0.2 == approx(0.3)\n        True\n\n    The same syntax also works for sequences of numbers::\n\n        >>> (0.1 + 0.2, 0.2 + 0.4) == approx((0.3, 0.6))\n        True\n\n    Dictionary *values*::\n\n        >>> {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6})\n        True\n\n    ``numpy`` arrays::\n\n        >>> import numpy as np                                                          # doctest: +SKIP\n        >>> np.array([0.1, 0.2]) + np.array([0.2, 0.4]) == approx(np.array([0.3, 0.6])) # doctest: +SKIP\n        True\n\n    And for a ``numpy`` array against a scalar::\n\n        >>> import numpy as np                                         # doctest: +SKIP\n        >>> np.array([0.1, 0.2]) + np.array([0.2, 0.1]) == approx(0.3) # doctest: +SKIP\n        True\n\n    By default, ``approx`` considers numbers within a relative tolerance of\n    ``1e-6`` (i.e. one part in a million) of its expected value to be equal.\n    This treatment would lead to surprising results if the expected value was\n    ``0.0``, because nothing but ``0.0`` itself is relatively close to ``0.0``.\n    To handle this case less surprisingly, ``approx`` also considers numbers\n    within an absolute tolerance of ``1e-12`` of its expected value to be\n    equal.  Infinity and NaN are special cases.  Infinity is only considered\n    equal to itself, regardless of the relative tolerance.  NaN is not\n    considered equal to anything by default, but you can make it be equal to\n    itself by setting the ``nan_ok`` argument to True.  (This is meant to\n    facilitate comparing arrays that use NaN to mean \"no data\".)\n\n    Both the relative and absolute tolerances can be changed by passing\n    arguments to the ``approx`` constructor::\n\n        >>> 1.0001 == approx(1)\n        False\n        >>> 1.0001 == approx(1, rel=1e-3)\n        True\n        >>> 1.0001 == approx(1, abs=1e-3)\n        True\n\n    If you specify ``abs`` but not ``rel``, the comparison will not consider\n    the relative tolerance at all.  In other words, two numbers that are within\n    the default relative tolerance of ``1e-6`` will still be considered unequal\n    if they exceed the specified absolute tolerance.  If you specify both\n    ``abs`` and ``rel``, the numbers will be considered equal if either\n    tolerance is met::\n\n        >>> 1 + 1e-8 == approx(1)\n        True\n        >>> 1 + 1e-8 == approx(1, abs=1e-12)\n        False\n        >>> 1 + 1e-8 == approx(1, rel=1e-6, abs=1e-12)\n        True\n\n    If you're thinking about using ``approx``, then you might want to know how\n    it compares to other good ways of comparing floating-point numbers.  All of\n    these algorithms are based on relative and absolute tolerances and should\n    agree for the most part, but they do have meaningful differences:\n\n    - ``math.isclose(a, b, rel_tol=1e-9, abs_tol=0.0)``:  True if the relative\n      tolerance is met w.r.t. either ``a`` or ``b`` or if the absolute\n      tolerance is met.  Because the relative tolerance is calculated w.r.t.\n      both ``a`` and ``b``, this test is symmetric (i.e.  neither ``a`` nor\n      ``b`` is a \"reference value\").  You have to specify an absolute tolerance\n      if you want to compare to ``0.0`` because there is no tolerance by\n      default.  Only available in python>=3.5.  `More information...`__\n\n      __ https://docs.python.org/3/library/math.html#math.isclose\n\n    - ``numpy.isclose(a, b, rtol=1e-5, atol=1e-8)``: True if the difference\n      between ``a`` and ``b`` is less that the sum of the relative tolerance\n      w.r.t. ``b`` and the absolute tolerance.  Because the relative tolerance\n      is only calculated w.r.t. ``b``, this test is asymmetric and you can\n      think of ``b`` as the reference value.  Support for comparing sequences\n      is provided by ``numpy.allclose``.  `More information...`__\n\n      __ http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.isclose.html\n\n    - ``unittest.TestCase.assertAlmostEqual(a, b)``: True if ``a`` and ``b``\n      are within an absolute tolerance of ``1e-7``.  No relative tolerance is\n      considered and the absolute tolerance cannot be changed, so this function\n      is not appropriate for very large or very small numbers.  Also, it's only\n      available in subclasses of ``unittest.TestCase`` and it's ugly because it\n      doesn't follow PEP8.  `More information...`__\n\n      __ https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertAlmostEqual\n\n    - ``a == pytest.approx(b, rel=1e-6, abs=1e-12)``: True if the relative\n      tolerance is met w.r.t. ``b`` or if the absolute tolerance is met.\n      Because the relative tolerance is only calculated w.r.t. ``b``, this test\n      is asymmetric and you can think of ``b`` as the reference value.  In the\n      special case that you explicitly specify an absolute tolerance but not a\n      relative tolerance, only the absolute tolerance is considered.\n\n    .. warning::\n\n       .. versionchanged:: 3.2\n\n       In order to avoid inconsistent behavior, ``TypeError`` is\n       raised for ``>``, ``>=``, ``<`` and ``<=`` comparisons.\n       The example below illustrates the problem::\n\n           assert approx(0.1) > 0.1 + 1e-10  # calls approx(0.1).__gt__(0.1 + 1e-10)\n           assert 0.1 + 1e-10 > approx(0.1)  # calls approx(0.1).__lt__(0.1 + 1e-10)\n\n       In the second example one expects ``approx(0.1).__le__(0.1 + 1e-10)``\n       to be called. But instead, ``approx(0.1).__lt__(0.1 + 1e-10)`` is used to\n       comparison. This is because the call hierarchy of rich comparisons\n       follows a fixed behavior. `More information...`__\n\n       __ https://docs.python.org/3/reference/datamodel.html#object.__ge__\n    \"\"\"\n\n    # Delegate the comparison to a class that knows how to deal with the type\n    # of the expected value (e.g. int, float, list, dict, numpy.array, etc).\n    #\n    # The primary responsibility of these classes is to implement ``__eq__()``\n    # and ``__repr__()``.  The former is used to actually check if some\n    # \"actual\" value is equivalent to the given expected value within the\n    # allowed tolerance.  The latter is used to show the user the expected\n    # value and tolerance, in the case that a test failed.\n    #\n    # The actual logic for making approximate comparisons can be found in\n    # ApproxScalar, which is used to compare individual numbers.  All of the\n    # other Approx classes eventually delegate to this class.  The ApproxBase\n    # class provides some convenient methods and overloads, but isn't really\n    # essential.\n\n    __tracebackhide__ = True\n\n    if isinstance(expected, Decimal):\n        cls = ApproxDecimal\n    elif isinstance(expected, Number):\n        cls = ApproxScalar\n    elif isinstance(expected, Mapping):\n        cls = ApproxMapping\n    elif _is_numpy_array(expected):\n        cls = ApproxNumpy\n    elif (\n        isinstance(expected, Iterable)\n        and isinstance(expected, Sized)\n        and not isinstance(expected, STRING_TYPES)\n    ):\n        cls = ApproxSequencelike\n    else:\n        raise _non_numeric_type_error(expected, at=None)\n\n    return cls(expected, rel, abs, nan_ok)\n\n\ndef _is_numpy_array(obj):\n    \"\"\"\n    Return true if the given object is a numpy array.  Make a special effort to\n    avoid importing numpy unless it's really necessary.\n    \"\"\"\n    import sys\n\n    np = sys.modules.get(\"numpy\")\n    if np is not None:\n        return isinstance(obj, np.ndarray)\n    return False\n\n\n# builtin pytest.raises helper\n\n\ndef raises(expected_exception, *args, **kwargs):\n    r\"\"\"\n    Assert that a code block/function call raises ``expected_exception``\n    or raise a failure exception otherwise.\n\n    :kwparam match: if specified, a string containing a regular expression,\n        or a regular expression object, that is tested against the string\n        representation of the exception using ``re.search``. To match a literal\n        string that may contain `special characters`__, the pattern can\n        first be escaped with ``re.escape``.\n\n    __ https://docs.python.org/3/library/re.html#regular-expression-syntax\n\n    :kwparam message: **(deprecated since 4.1)** if specified, provides a custom failure message\n        if the exception is not raised. See :ref:`the deprecation docs <raises message deprecated>` for a workaround.\n\n    .. currentmodule:: _pytest._code\n\n    Use ``pytest.raises`` as a context manager, which will capture the exception of the given\n    type::\n\n        >>> with raises(ZeroDivisionError):\n        ...    1/0\n\n    If the code block does not raise the expected exception (``ZeroDivisionError`` in the example\n    above), or no exception at all, the check will fail instead.\n\n    You can also use the keyword argument ``match`` to assert that the\n    exception matches a text or regex::\n\n        >>> with raises(ValueError, match='must be 0 or None'):\n        ...     raise ValueError(\"value must be 0 or None\")\n\n        >>> with raises(ValueError, match=r'must be \\d+$'):\n        ...     raise ValueError(\"value must be 42\")\n\n    The context manager produces an :class:`ExceptionInfo` object which can be used to inspect the\n    details of the captured exception::\n\n        >>> with raises(ValueError) as exc_info:\n        ...     raise ValueError(\"value must be 42\")\n        >>> assert exc_info.type is ValueError\n        >>> assert exc_info.value.args[0] == \"value must be 42\"\n\n    .. deprecated:: 4.1\n\n        In the context manager form you may use the keyword argument\n        ``message`` to specify a custom failure message that will be displayed\n        in case the ``pytest.raises`` check fails. This has been deprecated as it\n        is considered error prone as users often mean to use ``match`` instead.\n        See :ref:`the deprecation docs <raises message deprecated>` for a workaround.\n\n    .. note::\n\n       When using ``pytest.raises`` as a context manager, it's worthwhile to\n       note that normal context manager rules apply and that the exception\n       raised *must* be the final line in the scope of the context manager.\n       Lines of code after that, within the scope of the context manager will\n       not be executed. For example::\n\n           >>> value = 15\n           >>> with raises(ValueError) as exc_info:\n           ...     if value > 10:\n           ...         raise ValueError(\"value must be <= 10\")\n           ...     assert exc_info.type is ValueError  # this will not execute\n\n       Instead, the following approach must be taken (note the difference in\n       scope)::\n\n           >>> with raises(ValueError) as exc_info:\n           ...     if value > 10:\n           ...         raise ValueError(\"value must be <= 10\")\n           ...\n           >>> assert exc_info.type is ValueError\n\n    **Using with** ``pytest.mark.parametrize``\n\n    When using :ref:`pytest.mark.parametrize ref`\n    it is possible to parametrize tests such that\n    some runs raise an exception and others do not.\n\n    See :ref:`parametrizing_conditional_raising` for an example.\n\n    **Legacy form**\n\n    It is possible to specify a callable by passing a to-be-called lambda::\n\n        >>> raises(ZeroDivisionError, lambda: 1/0)\n        <ExceptionInfo ...>\n\n    or you can specify an arbitrary callable with arguments::\n\n        >>> def f(x): return 1/x\n        ...\n        >>> raises(ZeroDivisionError, f, 0)\n        <ExceptionInfo ...>\n        >>> raises(ZeroDivisionError, f, x=0)\n        <ExceptionInfo ...>\n\n    The form above is fully supported but discouraged for new code because the\n    context manager form is regarded as more readable and less error-prone.\n\n    .. note::\n        Similar to caught exception objects in Python, explicitly clearing\n        local references to returned ``ExceptionInfo`` objects can\n        help the Python interpreter speed up its garbage collection.\n\n        Clearing those references breaks a reference cycle\n        (``ExceptionInfo`` --> caught exception --> frame stack raising\n        the exception --> current frame stack --> local variables -->\n        ``ExceptionInfo``) which makes Python keep all objects referenced\n        from that cycle (including all local variables in the current\n        frame) alive until the next cyclic garbage collection run. See the\n        official Python ``try`` statement documentation for more detailed\n        information.\n\n    \"\"\"\n    __tracebackhide__ = True\n    for exc in filterfalse(\n        inspect.isclass, always_iterable(expected_exception, BASE_TYPE)\n    ):\n        msg = (\n            \"exceptions must be old-style classes or\"\n            \" derived from BaseException, not %s\"\n        )\n        raise TypeError(msg % type(exc))\n\n    message = \"DID NOT RAISE {}\".format(expected_exception)\n    match_expr = None\n\n    if not args:\n        if \"message\" in kwargs:\n            message = kwargs.pop(\"message\")\n            warnings.warn(deprecated.RAISES_MESSAGE_PARAMETER, stacklevel=2)\n        if \"match\" in kwargs:\n            match_expr = kwargs.pop(\"match\")\n        if kwargs:\n            msg = \"Unexpected keyword arguments passed to pytest.raises: \"\n            msg += \", \".join(sorted(kwargs))\n            raise TypeError(msg)\n        return RaisesContext(expected_exception, message, match_expr)\n    elif isinstance(args[0], str):\n        warnings.warn(deprecated.RAISES_EXEC, stacklevel=2)\n        code, = args\n        assert isinstance(code, str)\n        frame = sys._getframe(1)\n        loc = frame.f_locals.copy()\n        loc.update(kwargs)\n        # print \"raises frame scope: %r\" % frame.f_locals\n        try:\n            code = _pytest._code.Source(code).compile(_genframe=frame)\n            exec(code, frame.f_globals, loc)\n            # XXX didn't mean f_globals == f_locals something special?\n            #     this is destroyed here ...\n        except expected_exception:\n            return _pytest._code.ExceptionInfo.from_current()\n    else:\n        func = args[0]\n        try:\n            func(*args[1:], **kwargs)\n        except expected_exception:\n            return _pytest._code.ExceptionInfo.from_current()\n    fail(message)\n\n\nraises.Exception = fail.Exception\n\n\nclass RaisesContext:\n    def __init__(self, expected_exception, message, match_expr):\n        self.expected_exception = expected_exception\n        self.message = message\n        self.match_expr = match_expr\n        self.excinfo = None\n\n    def __enter__(self):\n        self.excinfo = _pytest._code.ExceptionInfo.for_later()\n        return self.excinfo\n\n    def __exit__(self, *tp):\n        __tracebackhide__ = True\n        if tp[0] is None:\n            fail(self.message)\n        self.excinfo.__init__(tp)\n        suppress_exception = issubclass(self.excinfo.type, self.expected_exception)\n        if self.match_expr is not None and suppress_exception:\n            self.excinfo.match(self.match_expr)\n        return suppress_exception\n</file>\n<file path=\"/testbed/testing/test_assertion.py\">\nimport collections.abc as collections_abc\nimport sys\nimport textwrap\n\nimport attr\n\nimport _pytest.assertion as plugin\nimport pytest\nfrom _pytest import outcomes\nfrom _pytest.assertion import truncate\nfrom _pytest.assertion import util\n\n\ndef mock_config():\n    class Config:\n        verbose = False\n\n        def getoption(self, name):\n            if name == \"verbose\":\n                return self.verbose\n            raise KeyError(\"Not mocked out: %s\" % name)\n\n    return Config()\n\n\nclass TestImportHookInstallation:\n    @pytest.mark.parametrize(\"initial_conftest\", [True, False])\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_conftest_assertion_rewrite(self, testdir, initial_conftest, mode):\n        \"\"\"Test that conftest files are using assertion rewrite on import.\n        (#1619)\n        \"\"\"\n        testdir.tmpdir.join(\"foo/tests\").ensure(dir=1)\n        conftest_path = \"conftest.py\" if initial_conftest else \"foo/conftest.py\"\n        contents = {\n            conftest_path: \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"foo/tests/test_foo.py\": \"\"\"\n                def test(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.runpytest_subprocess(\"--assert=%s\" % mode)\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_assertions_pytester_plugin(self, testdir):\n        \"\"\"\n        Assertions in the pytester plugin must also benefit from assertion\n        rewriting (#1920).\n        \"\"\"\n        testdir.makepyfile(\n            \"\"\"\n            pytest_plugins = ['pytester']\n            def test_dummy_failure(testdir):  # how meta!\n                testdir.makepyfile('def test(): assert 0')\n                r = testdir.inline_run()\n                r.assertoutcome(passed=1)\n        \"\"\"\n        )\n        result = testdir.runpytest_subprocess()\n        result.stdout.fnmatch_lines([\"*assert 1 == 0*\"])\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_pytest_plugins_rewrite(self, testdir, mode):\n        contents = {\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['ham']\n            \"\"\",\n            \"ham.py\": \"\"\"\n                import pytest\n                @pytest.fixture\n                def check_first():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"test_foo.py\": \"\"\"\n                def test_foo(check_first):\n                    check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.runpytest_subprocess(\"--assert=%s\" % mode)\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    @pytest.mark.parametrize(\"mode\", [\"str\", \"list\"])\n    def test_pytest_plugins_rewrite_module_names(self, testdir, mode):\n        \"\"\"Test that pluginmanager correct marks pytest_plugins variables\n        for assertion rewriting if they are defined as plain strings or\n        list of strings (#1888).\n        \"\"\"\n        plugins = '\"ham\"' if mode == \"str\" else '[\"ham\"]'\n        contents = {\n            \"conftest.py\": \"\"\"\n                pytest_plugins = {plugins}\n            \"\"\".format(\n                plugins=plugins\n            ),\n            \"ham.py\": \"\"\"\n                import pytest\n            \"\"\",\n            \"test_foo.py\": \"\"\"\n                def test_foo(pytestconfig):\n                    assert 'ham' in pytestconfig.pluginmanager.rewrite_hook._must_rewrite\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.runpytest_subprocess(\"--assert=rewrite\")\n        assert result.ret == 0\n\n    def test_pytest_plugins_rewrite_module_names_correctly(self, testdir):\n        \"\"\"Test that we match files correctly when they are marked for rewriting (#2939).\"\"\"\n        contents = {\n            \"conftest.py\": \"\"\"\\\n                pytest_plugins = \"ham\"\n            \"\"\",\n            \"ham.py\": \"\",\n            \"hamster.py\": \"\",\n            \"test_foo.py\": \"\"\"\\\n                def test_foo(pytestconfig):\n                    assert pytestconfig.pluginmanager.rewrite_hook.find_spec('ham') is not None\n                    assert pytestconfig.pluginmanager.rewrite_hook.find_spec('hamster') is None\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.runpytest_subprocess(\"--assert=rewrite\")\n        assert result.ret == 0\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n\n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n\n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n\n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n\n                def load(self):\n                    import spamplugin\n                    return spamplugin\n\n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n\n            def distributions():\n                return (DummyDistInfo(),)\n\n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n\n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n        result.stdout.fnmatch_lines([expected])\n\n    def test_rewrite_ast(self, testdir):\n        testdir.tmpdir.join(\"pkg\").ensure(dir=1)\n        contents = {\n            \"pkg/__init__.py\": \"\"\"\n                import pytest\n                pytest.register_assert_rewrite('pkg.helper')\n            \"\"\",\n            \"pkg/helper.py\": \"\"\"\n                def tool():\n                    a, b = 2, 3\n                    assert a == b\n            \"\"\",\n            \"pkg/plugin.py\": \"\"\"\n                import pytest, pkg.helper\n                @pytest.fixture\n                def tool():\n                    return pkg.helper.tool\n            \"\"\",\n            \"pkg/other.py\": \"\"\"\n                values = [3, 2]\n                def tool():\n                    assert values.pop() == 3\n            \"\"\",\n            \"conftest.py\": \"\"\"\n                pytest_plugins = ['pkg.plugin']\n            \"\"\",\n            \"test_pkg.py\": \"\"\"\n                import pkg.other\n                def test_tool(tool):\n                    tool()\n                def test_other():\n                    pkg.other.tool()\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.runpytest_subprocess(\"--assert=rewrite\")\n        result.stdout.fnmatch_lines(\n            [\n                \">*assert a == b*\",\n                \"E*assert 2 == 3*\",\n                \">*assert values.pop() == 3*\",\n                \"E*AssertionError\",\n            ]\n        )\n\n    def test_register_assert_rewrite_checks_types(self):\n        with pytest.raises(TypeError):\n            pytest.register_assert_rewrite([\"pytest_tests_internal_non_existing\"])\n        pytest.register_assert_rewrite(\n            \"pytest_tests_internal_non_existing\", \"pytest_tests_internal_non_existing2\"\n        )\n\n\nclass TestBinReprIntegration:\n    def test_pytest_assertrepr_compare_called(self, testdir):\n        testdir.makeconftest(\n            \"\"\"\n            import pytest\n            values = []\n            def pytest_assertrepr_compare(op, left, right):\n                values.append((op, left, right))\n\n            @pytest.fixture\n            def list(request):\n                return values\n        \"\"\"\n        )\n        testdir.makepyfile(\n            \"\"\"\n            def test_hello():\n                assert 0 == 1\n            def test_check(list):\n                assert list == [(\"==\", 0, 1)]\n        \"\"\"\n        )\n        result = testdir.runpytest(\"-v\")\n        result.stdout.fnmatch_lines([\"*test_hello*FAIL*\", \"*test_check*PASS*\"])\n\n\ndef callequal(left, right, verbose=False):\n    config = mock_config()\n    config.verbose = verbose\n    return plugin.pytest_assertrepr_compare(config, \"==\", left, right)\n\n\nclass TestAssert_reprcompare:\n    def test_different_types(self):\n        assert callequal([0, 1], \"foo\") is None\n\n    def test_summary(self):\n        summary = callequal([0, 1], [0, 2])[0]\n        assert len(summary) < 65\n\n    def test_text_diff(self):\n        diff = callequal(\"spam\", \"eggs\")[1:]\n        assert \"- spam\" in diff\n        assert \"+ eggs\" in diff\n\n    def test_text_skipping(self):\n        lines = callequal(\"a\" * 50 + \"spam\", \"a\" * 50 + \"eggs\")\n        assert \"Skipping\" in lines[1]\n        for line in lines:\n            assert \"a\" * 50 not in line\n\n    def test_text_skipping_verbose(self):\n        lines = callequal(\"a\" * 50 + \"spam\", \"a\" * 50 + \"eggs\", verbose=True)\n        assert \"- \" + \"a\" * 50 + \"spam\" in lines\n        assert \"+ \" + \"a\" * 50 + \"eggs\" in lines\n\n    def test_multiline_text_diff(self):\n        left = \"foo\\nspam\\nbar\"\n        right = \"foo\\neggs\\nbar\"\n        diff = callequal(left, right)\n        assert \"- spam\" in diff\n        assert \"+ eggs\" in diff\n\n    def test_list(self):\n        expl = callequal([0, 1], [0, 2])\n        assert len(expl) > 1\n\n    @pytest.mark.parametrize(\n        [\"left\", \"right\", \"expected\"],\n        [\n            (\n                [0, 1],\n                [0, 2],\n                \"\"\"\n                Full diff:\n                - [0, 1]\n                ?     ^\n                + [0, 2]\n                ?     ^\n            \"\"\",\n            ),\n            (\n                {0: 1},\n                {0: 2},\n                \"\"\"\n                Full diff:\n                - {0: 1}\n                ?     ^\n                + {0: 2}\n                ?     ^\n            \"\"\",\n            ),\n            (\n                {0, 1},\n                {0, 2},\n                \"\"\"\n                Full diff:\n                - {0, 1}\n                ?     ^\n                + {0, 2}\n                ?     ^\n            \"\"\",\n            ),\n        ],\n    )\n    def test_iterable_full_diff(self, left, right, expected):\n        \"\"\"Test the full diff assertion failure explanation.\n\n        When verbose is False, then just a -v notice to get the diff is rendered,\n        when verbose is True, then ndiff of the pprint is returned.\n        \"\"\"\n        expl = callequal(left, right, verbose=False)\n        assert expl[-1] == \"Use -v to get the full diff\"\n        expl = \"\\n\".join(callequal(left, right, verbose=True))\n        assert expl.endswith(textwrap.dedent(expected).strip())\n\n    def test_list_different_lengths(self):\n        expl = callequal([0, 1], [0, 1, 2])\n        assert len(expl) > 1\n        expl = callequal([0, 1, 2], [0, 1])\n        assert len(expl) > 1\n\n    def test_dict(self):\n        expl = callequal({\"a\": 0}, {\"a\": 1})\n        assert len(expl) > 1\n\n    def test_dict_omitting(self):\n        lines = callequal({\"a\": 0, \"b\": 1}, {\"a\": 1, \"b\": 1})\n        assert lines[1].startswith(\"Omitting 1 identical item\")\n        assert \"Common items\" not in lines\n        for line in lines[1:]:\n            assert \"b\" not in line\n\n    def test_dict_omitting_with_verbosity_1(self):\n        \"\"\" Ensure differing items are visible for verbosity=1 (#1512) \"\"\"\n        lines = callequal({\"a\": 0, \"b\": 1}, {\"a\": 1, \"b\": 1}, verbose=1)\n        assert lines[1].startswith(\"Omitting 1 identical item\")\n        assert lines[2].startswith(\"Differing items\")\n        assert lines[3] == \"{'a': 0} != {'a': 1}\"\n        assert \"Common items\" not in lines\n\n    def test_dict_omitting_with_verbosity_2(self):\n        lines = callequal({\"a\": 0, \"b\": 1}, {\"a\": 1, \"b\": 1}, verbose=2)\n        assert lines[1].startswith(\"Common items:\")\n        assert \"Omitting\" not in lines[1]\n        assert lines[2] == \"{'b': 1}\"\n\n    def test_dict_different_items(self):\n        lines = callequal({\"a\": 0}, {\"b\": 1, \"c\": 2}, verbose=2)\n        assert lines == [\n            \"{'a': 0} == {'b': 1, 'c': 2}\",\n            \"Left contains 1 more item:\",\n            \"{'a': 0}\",\n            \"Right contains 2 more items:\",\n            \"{'b': 1, 'c': 2}\",\n            \"Full diff:\",\n            \"- {'a': 0}\",\n            \"+ {'b': 1, 'c': 2}\",\n        ]\n        lines = callequal({\"b\": 1, \"c\": 2}, {\"a\": 0}, verbose=2)\n        assert lines == [\n            \"{'b': 1, 'c': 2} == {'a': 0}\",\n            \"Left contains 2 more items:\",\n            \"{'b': 1, 'c': 2}\",\n            \"Right contains 1 more item:\",\n            \"{'a': 0}\",\n            \"Full diff:\",\n            \"- {'b': 1, 'c': 2}\",\n            \"+ {'a': 0}\",\n        ]\n\n    def test_sequence_different_items(self):\n        lines = callequal((1, 2), (3, 4, 5), verbose=2)\n        assert lines == [\n            \"(1, 2) == (3, 4, 5)\",\n            \"At index 0 diff: 1 != 3\",\n            \"Right contains one more item: 5\",\n            \"Full diff:\",\n            \"- (1, 2)\",\n            \"+ (3, 4, 5)\",\n        ]\n        lines = callequal((1, 2, 3), (4,), verbose=2)\n        assert lines == [\n            \"(1, 2, 3) == (4,)\",\n            \"At index 0 diff: 1 != 4\",\n            \"Left contains 2 more items, first extra item: 2\",\n            \"Full diff:\",\n            \"- (1, 2, 3)\",\n            \"+ (4,)\",\n        ]\n\n    def test_set(self):\n        expl = callequal({0, 1}, {0, 2})\n        assert len(expl) > 1\n\n    def test_frozenzet(self):\n        expl = callequal(frozenset([0, 1]), {0, 2})\n        assert len(expl) > 1\n\n    def test_Sequence(self):\n\n        if not hasattr(collections_abc, \"MutableSequence\"):\n            pytest.skip(\"cannot import MutableSequence\")\n        MutableSequence = collections_abc.MutableSequence\n\n        class TestSequence(MutableSequence):  # works with a Sequence subclass\n            def __init__(self, iterable):\n                self.elements = list(iterable)\n\n            def __getitem__(self, item):\n                return self.elements[item]\n\n            def __len__(self):\n                return len(self.elements)\n\n            def __setitem__(self, item, value):\n                pass\n\n            def __delitem__(self, item):\n                pass\n\n            def insert(self, item, index):\n                pass\n\n        expl = callequal(TestSequence([0, 1]), list([0, 2]))\n        assert len(expl) > 1\n\n    def test_list_tuples(self):\n        expl = callequal([], [(1, 2)])\n        assert len(expl) > 1\n        expl = callequal([(1, 2)], [])\n        assert len(expl) > 1\n\n    def test_repr_verbose(self):\n        class Nums:\n            def __init__(self, nums):\n                self.nums = nums\n\n            def __repr__(self):\n                return str(self.nums)\n\n        list_x = list(range(5000))\n        list_y = list(range(5000))\n        list_y[len(list_y) // 2] = 3\n        nums_x = Nums(list_x)\n        nums_y = Nums(list_y)\n\n        assert callequal(nums_x, nums_y) is None\n\n        expl = callequal(nums_x, nums_y, verbose=1)\n        assert \"-\" + repr(nums_x) in expl\n        assert \"+\" + repr(nums_y) in expl\n\n        expl = callequal(nums_x, nums_y, verbose=2)\n        assert \"-\" + repr(nums_x) in expl\n        assert \"+\" + repr(nums_y) in expl\n\n    def test_list_bad_repr(self):\n        class A:\n            def __repr__(self):\n                raise ValueError(42)\n\n        expl = callequal([], [A()])\n        assert \"ValueError\" in \"\".join(expl)\n        expl = callequal({}, {\"1\": A()})\n        assert \"faulty\" in \"\".join(expl)\n\n    def test_one_repr_empty(self):\n        \"\"\"\n        the faulty empty string repr did trigger\n        an unbound local error in _diff_text\n        \"\"\"\n\n        class A(str):\n            def __repr__(self):\n                return \"\"\n\n        expl = callequal(A(), \"\")\n        assert not expl\n\n    def test_repr_no_exc(self):\n        expl = \" \".join(callequal(\"foo\", \"bar\"))\n        assert \"raised in repr()\" not in expl\n\n    def test_unicode(self):\n        left = \"\u00a3\u20ac\"\n        right = \"\u00a3\"\n        expl = callequal(left, right)\n        assert expl[0] == \"'\u00a3\u20ac' == '\u00a3'\"\n        assert expl[1] == \"- \u00a3\u20ac\"\n        assert expl[2] == \"+ \u00a3\"\n\n    def test_nonascii_text(self):\n        \"\"\"\n        :issue: 877\n        non ascii python2 str caused a UnicodeDecodeError\n        \"\"\"\n\n        class A(str):\n            def __repr__(self):\n                return \"\\xff\"\n\n        expl = callequal(A(), \"1\")\n        assert expl == [\"\u00ff == '1'\", \"+ 1\"]\n\n    def test_format_nonascii_explanation(self):\n        assert util.format_explanation(\"\u03bb\")\n\n    def test_mojibake(self):\n        # issue 429\n        left = b\"e\"\n        right = b\"\\xc3\\xa9\"\n        expl = callequal(left, right)\n        for line in expl:\n            assert isinstance(line, str)\n        msg = \"\\n\".join(expl)\n        assert msg\n\n\nclass TestAssert_reprcompare_dataclass:\n    @pytest.mark.skipif(sys.version_info < (3, 7), reason=\"Dataclasses in Python3.7+\")\n    def test_dataclasses(self, testdir):\n        p = testdir.copy_example(\"dataclasses/test_compare_dataclasses.py\")\n        result = testdir.runpytest(p)\n        result.assert_outcomes(failed=1, passed=0)\n        result.stdout.fnmatch_lines(\n            [\n                \"*Omitting 1 identical items, use -vv to show*\",\n                \"*Differing attributes:*\",\n                \"*field_b: 'b' != 'c'*\",\n            ]\n        )\n\n    @pytest.mark.skipif(sys.version_info < (3, 7), reason=\"Dataclasses in Python3.7+\")\n    def test_dataclasses_verbose(self, testdir):\n        p = testdir.copy_example(\"dataclasses/test_compare_dataclasses_verbose.py\")\n        result = testdir.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=1, passed=0)\n        result.stdout.fnmatch_lines(\n            [\n                \"*Matching attributes:*\",\n                \"*['field_a']*\",\n                \"*Differing attributes:*\",\n                \"*field_b: 'b' != 'c'*\",\n            ]\n        )\n\n    @pytest.mark.skipif(sys.version_info < (3, 7), reason=\"Dataclasses in Python3.7+\")\n    def test_dataclasses_with_attribute_comparison_off(self, testdir):\n        p = testdir.copy_example(\n            \"dataclasses/test_compare_dataclasses_field_comparison_off.py\"\n        )\n        result = testdir.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=0, passed=1)\n\n    @pytest.mark.skipif(sys.version_info < (3, 7), reason=\"Dataclasses in Python3.7+\")\n    def test_comparing_two_different_data_classes(self, testdir):\n        p = testdir.copy_example(\n            \"dataclasses/test_compare_two_different_dataclasses.py\"\n        )\n        result = testdir.runpytest(p, \"-vv\")\n        result.assert_outcomes(failed=0, passed=1)\n\n\nclass TestAssert_reprcompare_attrsclass:\n    def test_attrs(self):\n        @attr.s\n        class SimpleDataObject:\n            field_a = attr.ib()\n            field_b = attr.ib()\n\n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"c\")\n\n        lines = callequal(left, right)\n        assert lines[1].startswith(\"Omitting 1 identical item\")\n        assert \"Matching attributes\" not in lines\n        for line in lines[1:]:\n            assert \"field_a\" not in line\n\n    def test_attrs_verbose(self):\n        @attr.s\n        class SimpleDataObject:\n            field_a = attr.ib()\n            field_b = attr.ib()\n\n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"c\")\n\n        lines = callequal(left, right, verbose=2)\n        assert lines[1].startswith(\"Matching attributes:\")\n        assert \"Omitting\" not in lines[1]\n        assert lines[2] == \"['field_a']\"\n\n    def test_attrs_with_attribute_comparison_off(self):\n        @attr.s\n        class SimpleDataObject:\n            field_a = attr.ib()\n            field_b = attr.ib(cmp=False)\n\n        left = SimpleDataObject(1, \"b\")\n        right = SimpleDataObject(1, \"b\")\n\n        lines = callequal(left, right, verbose=2)\n        assert lines[1].startswith(\"Matching attributes:\")\n        assert \"Omitting\" not in lines[1]\n        assert lines[2] == \"['field_a']\"\n        for line in lines[2:]:\n            assert \"field_b\" not in line\n\n    def test_comparing_two_different_attrs_classes(self):\n        @attr.s\n        class SimpleDataObjectOne:\n            field_a = attr.ib()\n            field_b = attr.ib()\n\n        @attr.s\n        class SimpleDataObjectTwo:\n            field_a = attr.ib()\n            field_b = attr.ib()\n\n        left = SimpleDataObjectOne(1, \"b\")\n        right = SimpleDataObjectTwo(1, \"c\")\n\n        lines = callequal(left, right)\n        assert lines is None\n\n\nclass TestFormatExplanation:\n    def test_special_chars_full(self, testdir):\n        # Issue 453, for the bug this would raise IndexError\n        testdir.makepyfile(\n            \"\"\"\n            def test_foo():\n                assert '\\\\n}' == ''\n        \"\"\"\n        )\n        result = testdir.runpytest()\n        assert result.ret == 1\n        result.stdout.fnmatch_lines([\"*AssertionError*\"])\n\n    def test_fmt_simple(self):\n        expl = \"assert foo\"\n        assert util.format_explanation(expl) == \"assert foo\"\n\n    def test_fmt_where(self):\n        expl = \"\\n\".join([\"assert 1\", \"{1 = foo\", \"} == 2\"])\n        res = \"\\n\".join([\"assert 1 == 2\", \" +  where 1 = foo\"])\n        assert util.format_explanation(expl) == res\n\n    def test_fmt_and(self):\n        expl = \"\\n\".join([\"assert 1\", \"{1 = foo\", \"} == 2\", \"{2 = bar\", \"}\"])\n        res = \"\\n\".join([\"assert 1 == 2\", \" +  where 1 = foo\", \" +  and   2 = bar\"])\n        assert util.format_explanation(expl) == res\n\n    def test_fmt_where_nested(self):\n        expl = \"\\n\".join([\"assert 1\", \"{1 = foo\", \"{foo = bar\", \"}\", \"} == 2\"])\n        res = \"\\n\".join([\"assert 1 == 2\", \" +  where 1 = foo\", \" +    where foo = bar\"])\n        assert util.format_explanation(expl) == res\n\n    def test_fmt_newline(self):\n        expl = \"\\n\".join(['assert \"foo\" == \"bar\"', \"~- foo\", \"~+ bar\"])\n        res = \"\\n\".join(['assert \"foo\" == \"bar\"', \"  - foo\", \"  + bar\"])\n        assert util.format_explanation(expl) == res\n\n    def test_fmt_newline_escaped(self):\n        expl = \"\\n\".join([\"assert foo == bar\", \"baz\"])\n        res = \"assert foo == bar\\\\nbaz\"\n        assert util.format_explanation(expl) == res\n\n    def test_fmt_newline_before_where(self):\n        expl = \"\\n\".join(\n            [\n                \"the assertion message here\",\n                \">assert 1\",\n                \"{1 = foo\",\n                \"} == 2\",\n                \"{2 = bar\",\n                \"}\",\n            ]\n        )\n        res = \"\\n\".join(\n            [\n                \"the assertion message here\",\n                \"assert 1 == 2\",\n                \" +  where 1 = foo\",\n                \" +  and   2 = bar\",\n            ]\n        )\n        assert util.format_explanation(expl) == res\n\n    def test_fmt_multi_newline_before_where(self):\n        expl = \"\\n\".join(\n            [\n                \"the assertion\",\n                \"~message here\",\n                \">assert 1\",\n                \"{1 = foo\",\n                \"} == 2\",\n                \"{2 = bar\",\n                \"}\",\n            ]\n        )\n        res = \"\\n\".join(\n            [\n                \"the assertion\",\n                \"  message here\",\n                \"assert 1 == 2\",\n                \" +  where 1 = foo\",\n                \" +  and   2 = bar\",\n            ]\n        )\n        assert util.format_explanation(expl) == res\n\n\nclass TestTruncateExplanation:\n\n    \"\"\" Confirm assertion output is truncated as expected \"\"\"\n\n    # The number of lines in the truncation explanation message. Used\n    # to calculate that results have the expected length.\n    LINES_IN_TRUNCATION_MSG = 2\n\n    def test_doesnt_truncate_when_input_is_empty_list(self):\n        expl = []\n        result = truncate._truncate_explanation(expl, max_lines=8, max_chars=100)\n        assert result == expl\n\n    def test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars(self):\n        expl = [\"a\" * 100 for x in range(5)]\n        result = truncate._truncate_explanation(expl, max_lines=8, max_chars=8 * 80)\n        assert result == expl\n\n    def test_truncates_at_8_lines_when_given_list_of_empty_strings(self):\n        expl = [\"\" for x in range(50)]\n        result = truncate._truncate_explanation(expl, max_lines=8, max_chars=100)\n        assert result != expl\n        assert len(result) == 8 + self.LINES_IN_TRUNCATION_MSG\n        assert \"Full output truncated\" in result[-1]\n        assert \"43 lines hidden\" in result[-1]\n        last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]\n        assert last_line_before_trunc_msg.endswith(\"...\")\n\n    def test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars(self):\n        expl = [\"a\" for x in range(100)]\n        result = truncate._truncate_explanation(expl, max_lines=8, max_chars=8 * 80)\n        assert result != expl\n        assert len(result) == 8 + self.LINES_IN_TRUNCATION_MSG\n        assert \"Full output truncated\" in result[-1]\n        assert \"93 lines hidden\" in result[-1]\n        last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]\n        assert last_line_before_trunc_msg.endswith(\"...\")\n\n    def test_truncates_at_8_lines_when_first_8_lines_are_EQ_max_chars(self):\n        expl = [\"a\" * 80 for x in range(16)]\n        result = truncate._truncate_explanation(expl, max_lines=8, max_chars=8 * 80)\n        assert result != expl\n        assert len(result) == 8 + self.LINES_IN_TRUNCATION_MSG\n        assert \"Full output truncated\" in result[-1]\n        assert \"9 lines hidden\" in result[-1]\n        last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]\n        assert last_line_before_trunc_msg.endswith(\"...\")\n\n    def test_truncates_at_4_lines_when_first_4_lines_are_GT_max_chars(self):\n        expl = [\"a\" * 250 for x in range(10)]\n        result = truncate._truncate_explanation(expl, max_lines=8, max_chars=999)\n        assert result != expl\n        assert len(result) == 4 + self.LINES_IN_TRUNCATION_MSG\n        assert \"Full output truncated\" in result[-1]\n        assert \"7 lines hidden\" in result[-1]\n        last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]\n        assert last_line_before_trunc_msg.endswith(\"...\")\n\n    def test_truncates_at_1_line_when_first_line_is_GT_max_chars(self):\n        expl = [\"a\" * 250 for x in range(1000)]\n        result = truncate._truncate_explanation(expl, max_lines=8, max_chars=100)\n        assert result != expl\n        assert len(result) == 1 + self.LINES_IN_TRUNCATION_MSG\n        assert \"Full output truncated\" in result[-1]\n        assert \"1000 lines hidden\" in result[-1]\n        last_line_before_trunc_msg = result[-self.LINES_IN_TRUNCATION_MSG - 1]\n        assert last_line_before_trunc_msg.endswith(\"...\")\n\n    def test_full_output_truncated(self, monkeypatch, testdir):\n        \"\"\" Test against full runpytest() output. \"\"\"\n\n        line_count = 7\n        line_len = 100\n        expected_truncated_lines = 2\n        testdir.makepyfile(\n            r\"\"\"\n            def test_many_lines():\n                a = list([str(i)[0] * %d for i in range(%d)])\n                b = a[::2]\n                a = '\\n'.join(map(str, a))\n                b = '\\n'.join(map(str, b))\n                assert a == b\n        \"\"\"\n            % (line_len, line_count)\n        )\n        monkeypatch.delenv(\"CI\", raising=False)\n\n        result = testdir.runpytest()\n        # without -vv, truncate the message showing a few diff lines only\n        result.stdout.fnmatch_lines(\n            [\n                \"*- 1*\",\n                \"*- 3*\",\n                \"*- 5*\",\n                \"*truncated (%d lines hidden)*use*-vv*\" % expected_truncated_lines,\n            ]\n        )\n\n        result = testdir.runpytest(\"-vv\")\n        result.stdout.fnmatch_lines([\"* 6*\"])\n\n        monkeypatch.setenv(\"CI\", \"1\")\n        result = testdir.runpytest()\n        result.stdout.fnmatch_lines([\"* 6*\"])\n\n\ndef test_python25_compile_issue257(testdir):\n    testdir.makepyfile(\n        \"\"\"\n        def test_rewritten():\n            assert 1 == 2\n        # some comment\n    \"\"\"\n    )\n    result = testdir.runpytest()\n    assert result.ret == 1\n    result.stdout.fnmatch_lines(\n        \"\"\"\n            *E*assert 1 == 2*\n            *1 failed*\n    \"\"\"\n    )\n\n\ndef test_rewritten(testdir):\n    testdir.ma\n... File content truncated due to length ... \n\n</file>\n<file path=\"/testbed/src/_pytest/assertion/util.py\">\n\"\"\"Utilities for assertion debugging\"\"\"\nimport pprint\nfrom collections.abc import Sequence\n\nimport _pytest._code\nfrom _pytest import outcomes\nfrom _pytest._io.saferepr import saferepr\n\n# The _reprcompare attribute on the util module is used by the new assertion\n# interpretation code and assertion rewriter to detect this plugin was\n# loaded and in turn call the hooks defined here as part of the\n# DebugInterpreter.\n_reprcompare = None\n\n\ndef format_explanation(explanation):\n    \"\"\"This formats an explanation\n\n    Normally all embedded newlines are escaped, however there are\n    three exceptions: \\n{, \\n} and \\n~.  The first two are intended\n    cover nested explanations, see function and attribute explanations\n    for examples (.visit_Call(), visit_Attribute()).  The last one is\n    for when one explanation needs to span multiple lines, e.g. when\n    displaying diffs.\n    \"\"\"\n    explanation = explanation\n    lines = _split_explanation(explanation)\n    result = _format_lines(lines)\n    return \"\\n\".join(result)\n\n\ndef _split_explanation(explanation):\n    \"\"\"Return a list of individual lines in the explanation\n\n    This will return a list of lines split on '\\n{', '\\n}' and '\\n~'.\n    Any other newlines will be escaped and appear in the line as the\n    literal '\\n' characters.\n    \"\"\"\n    raw_lines = (explanation or \"\").split(\"\\n\")\n    lines = [raw_lines[0]]\n    for values in raw_lines[1:]:\n        if values and values[0] in [\"{\", \"}\", \"~\", \">\"]:\n            lines.append(values)\n        else:\n            lines[-1] += \"\\\\n\" + values\n    return lines\n\n\ndef _format_lines(lines):\n    \"\"\"Format the individual lines\n\n    This will replace the '{', '}' and '~' characters of our mini\n    formatting language with the proper 'where ...', 'and ...' and ' +\n    ...' text, taking care of indentation along the way.\n\n    Return a list of formatted lines.\n    \"\"\"\n    result = lines[:1]\n    stack = [0]\n    stackcnt = [0]\n    for line in lines[1:]:\n        if line.startswith(\"{\"):\n            if stackcnt[-1]:\n                s = \"and   \"\n            else:\n                s = \"where \"\n            stack.append(len(result))\n            stackcnt[-1] += 1\n            stackcnt.append(0)\n            result.append(\" +\" + \"  \" * (len(stack) - 1) + s + line[1:])\n        elif line.startswith(\"}\"):\n            stack.pop()\n            stackcnt.pop()\n            result[stack[-1]] += line[1:]\n        else:\n            assert line[0] in [\"~\", \">\"]\n            stack[-1] += 1\n            indent = len(stack) if line.startswith(\"~\") else len(stack) - 1\n            result.append(\"  \" * indent + line[1:])\n    assert len(stack) == 1\n    return result\n\n\ndef issequence(x):\n    return isinstance(x, Sequence) and not isinstance(x, str)\n\n\ndef istext(x):\n    return isinstance(x, str)\n\n\ndef isdict(x):\n    return isinstance(x, dict)\n\n\ndef isset(x):\n    return isinstance(x, (set, frozenset))\n\n\ndef isdatacls(obj):\n    return getattr(obj, \"__dataclass_fields__\", None) is not None\n\n\ndef isattrs(obj):\n    return getattr(obj, \"__attrs_attrs__\", None) is not None\n\n\ndef isiterable(obj):\n    try:\n        iter(obj)\n        return not istext(obj)\n    except TypeError:\n        return False\n\n\ndef assertrepr_compare(config, op, left, right):\n    \"\"\"Return specialised explanations for some operators/operands\"\"\"\n    width = 80 - 15 - len(op) - 2  # 15 chars indentation, 1 space around op\n    left_repr = saferepr(left, maxsize=int(width // 2))\n    right_repr = saferepr(right, maxsize=width - len(left_repr))\n\n    summary = \"{} {} {}\".format(left_repr, op, right_repr)\n\n    verbose = config.getoption(\"verbose\")\n    explanation = None\n    try:\n        if op == \"==\":\n            if istext(left) and istext(right):\n                explanation = _diff_text(left, right, verbose)\n            else:\n                if issequence(left) and issequence(right):\n                    explanation = _compare_eq_sequence(left, right, verbose)\n                elif isset(left) and isset(right):\n                    explanation = _compare_eq_set(left, right, verbose)\n                elif isdict(left) and isdict(right):\n                    explanation = _compare_eq_dict(left, right, verbose)\n                elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):\n                    type_fn = (isdatacls, isattrs)\n                    explanation = _compare_eq_cls(left, right, verbose, type_fn)\n                elif verbose > 0:\n                    explanation = _compare_eq_verbose(left, right)\n                if isiterable(left) and isiterable(right):\n                    expl = _compare_eq_iterable(left, right, verbose)\n                    if explanation is not None:\n                        explanation.extend(expl)\n                    else:\n                        explanation = expl\n        elif op == \"not in\":\n            if istext(left) and istext(right):\n                explanation = _notin_text(left, right, verbose)\n    except outcomes.Exit:\n        raise\n    except Exception:\n        explanation = [\n            \"(pytest_assertion plugin: representation of details failed.  \"\n            \"Probably an object has a faulty __repr__.)\",\n            str(_pytest._code.ExceptionInfo.from_current()),\n        ]\n\n    if not explanation:\n        return None\n\n    return [summary] + explanation\n\n\ndef _diff_text(left, right, verbose=0):\n    \"\"\"Return the explanation for the diff between text or bytes.\n\n    Unless --verbose is used this will skip leading and trailing\n    characters which are identical to keep the diff minimal.\n\n    If the input are bytes they will be safely converted to text.\n    \"\"\"\n    from difflib import ndiff\n\n    explanation = []\n\n    def escape_for_readable_diff(binary_text):\n        \"\"\"\n        Ensures that the internal string is always valid unicode, converting any bytes safely to valid unicode.\n        This is done using repr() which then needs post-processing to fix the encompassing quotes and un-escape\n        newlines and carriage returns (#429).\n        \"\"\"\n        r = str(repr(binary_text)[1:-1])\n        r = r.replace(r\"\\n\", \"\\n\")\n        r = r.replace(r\"\\r\", \"\\r\")\n        return r\n\n    if isinstance(left, bytes):\n        left = escape_for_readable_diff(left)\n    if isinstance(right, bytes):\n        right = escape_for_readable_diff(right)\n    if verbose < 1:\n        i = 0  # just in case left or right has zero length\n        for i in range(min(len(left), len(right))):\n            if left[i] != right[i]:\n                break\n        if i > 42:\n            i -= 10  # Provide some context\n            explanation = [\n                \"Skipping %s identical leading characters in diff, use -v to show\" % i\n            ]\n            left = left[i:]\n            right = right[i:]\n        if len(left) == len(right):\n            for i in range(len(left)):\n                if left[-i] != right[-i]:\n                    break\n            if i > 42:\n                i -= 10  # Provide some context\n                explanation += [\n                    \"Skipping {} identical trailing \"\n                    \"characters in diff, use -v to show\".format(i)\n                ]\n                left = left[:-i]\n                right = right[:-i]\n    keepends = True\n    if left.isspace() or right.isspace():\n        left = repr(str(left))\n        right = repr(str(right))\n        explanation += [\"Strings contain only whitespace, escaping them using repr()\"]\n    explanation += [\n        line.strip(\"\\n\")\n        for line in ndiff(left.splitlines(keepends), right.splitlines(keepends))\n    ]\n    return explanation\n\n\ndef _compare_eq_verbose(left, right):\n    keepends = True\n    left_lines = repr(left).splitlines(keepends)\n    right_lines = repr(right).splitlines(keepends)\n\n    explanation = []\n    explanation += [\"-\" + line for line in left_lines]\n    explanation += [\"+\" + line for line in right_lines]\n\n    return explanation\n\n\ndef _compare_eq_iterable(left, right, verbose=0):\n    if not verbose:\n        return [\"Use -v to get the full diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    left_formatting = pprint.pformat(left).splitlines()\n    right_formatting = pprint.pformat(right).splitlines()\n    explanation = [\"Full diff:\"]\n    explanation.extend(\n        line.strip() for line in difflib.ndiff(left_formatting, right_formatting)\n    )\n    return explanation\n\n\ndef _compare_eq_sequence(left, right, verbose=0):\n    explanation = []\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            if isinstance(left, bytes) and isinstance(right, bytes):\n                left_chr = chr(left[i]) if 32 <= left[i] <= 126 else '\\\\x{:02x}'.format(left[i])\n                right_chr = chr(right[i]) if 32 <= right[i] <= 126 else '\\\\x{:02x}'.format(right[i])\n                explanation += [\n                    \"At index {} diff: b'{}' (ASCII {}) != b'{}' (ASCII {})\".format(\n                        i, left_chr, left[i], right_chr, right[i]\n                    )\n                ]\n            else:\n                explanation += [\n                    \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n                ]\n            break\n    len_diff = len_left - len_right\n\n    if len_diff:\n        if len_diff > 0:\n            dir_with_more = \"Left\"\n            extra = saferepr(left[len_right])\n        else:\n            len_diff = 0 - len_diff\n            dir_with_more = \"Right\"\n            extra = saferepr(right[len_left])\n\n        if len_diff == 1:\n            if isinstance(left, bytes) and isinstance(right, bytes):\n                extra_byte = left[len_right] if len_diff > 0 else right[len_left]\n                extra_chr = chr(extra_byte) if 32 <= extra_byte <= 126 else '\\\\x{:02x}'.format(extra_byte)\n                explanation += [\n                    \"{} contains one more item: b'{}' (ASCII {})\".format(\n                        dir_with_more, extra_chr, extra_byte\n                    )\n                ]\n            else:\n                explanation += [\n                    \"{} contains one more item: {}\".format(dir_with_more, extra)\n                ]\n        else:\n            if isinstance(left, bytes) and isinstance(right, bytes):\n                extra_byte = left[len_right] if len_diff > 0 else right[len_left]\n                extra_chr = chr(extra_byte) if 32 <= extra_byte <= 126 else '\\\\x{:02x}'.format(extra_byte)\n                explanation += [\n                    \"%s contains %d more items, first extra item: b'%s' (ASCII %d)\"\n                    % (dir_with_more, len_diff, extra_chr, extra_byte)\n                ]\n            else:\n                explanation += [\n                    \"%s contains %d more items, first extra item: %s\"\n                    % (dir_with_more, len_diff, extra)\n                ]\n    return explanation\n\n\ndef _compare_eq_set(left, right, verbose=0):\n    explanation = []\n    diff_left = left - right\n    diff_right = right - left\n    if diff_left:\n        explanation.append(\"Extra items in the left set:\")\n        for item in diff_left:\n            explanation.append(saferepr(item))\n    if diff_right:\n        explanation.append(\"Extra items in the right set:\")\n        for item in diff_right:\n            explanation.append(saferepr(item))\n    return explanation\n\n\ndef _compare_eq_dict(left, right, verbose=0):\n    explanation = []\n    set_left = set(left)\n    set_right = set(right)\n    common = set_left.intersection(set_right)\n    same = {k: left[k] for k in common if left[k] == right[k]}\n    if same and verbose < 2:\n        explanation += [\"Omitting %s identical items, use -vv to show\" % len(same)]\n    elif same:\n        explanation += [\"Common items:\"]\n        explanation += pprint.pformat(same).splitlines()\n    diff = {k for k in common if left[k] != right[k]}\n    if diff:\n        explanation += [\"Differing items:\"]\n        for k in diff:\n            explanation += [saferepr({k: left[k]}) + \" != \" + saferepr({k: right[k]})]\n    extra_left = set_left - set_right\n    len_extra_left = len(extra_left)\n    if len_extra_left:\n        explanation.append(\n            \"Left contains %d more item%s:\"\n            % (len_extra_left, \"\" if len_extra_left == 1 else \"s\")\n        )\n        explanation.extend(\n            pprint.pformat({k: left[k] for k in extra_left}).splitlines()\n        )\n    extra_right = set_right - set_left\n    len_extra_right = len(extra_right)\n    if len_extra_right:\n        explanation.append(\n            \"Right contains %d more item%s:\"\n            % (len_extra_right, \"\" if len_extra_right == 1 else \"s\")\n        )\n        explanation.extend(\n            pprint.pformat({k: right[k] for k in extra_right}).splitlines()\n        )\n    return explanation\n\n\ndef _compare_eq_cls(left, right, verbose, type_fns):\n    isdatacls, isattrs = type_fns\n    if isdatacls(left):\n        all_fields = left.__dataclass_fields__\n        fields_to_check = [field for field, info in all_fields.items() if info.compare]\n    elif isattrs(left):\n        all_fields = left.__attrs_attrs__\n        fields_to_check = [field.name for field in all_fields if field.cmp]\n\n    same = []\n    diff = []\n    for field in fields_to_check:\n        if getattr(left, field) == getattr(right, field):\n            same.append(field)\n        else:\n            diff.append(field)\n\n    explanation = []\n    if same and verbose < 2:\n        explanation.append(\"Omitting %s identical items, use -vv to show\" % len(same))\n    elif same:\n        explanation += [\"Matching attributes:\"]\n        explanation += pprint.pformat(same).splitlines()\n    if diff:\n        explanation += [\"Differing attributes:\"]\n        for field in diff:\n            explanation += [\n                (\"%s: %r != %r\") % (field, getattr(left, field), getattr(right, field))\n            ]\n    return explanation\n\n\ndef _notin_text(term, text, verbose=0):\n    index = text.find(term)\n    head = text[:index]\n    tail = text[index + len(term) :]\n    correct_text = head + tail\n    diff = _diff_text(correct_text, text, verbose)\n    newdiff = [\"%s is contained here:\" % saferepr(term, maxsize=42)]\n    for line in diff:\n        if line.startswith(\"Skipping\"):\n            continue\n        if line.startswith(\"- \"):\n            continue\n        if line.startswith(\"+ \"):\n            newdiff.append(\"  \" + line[2:])\n        else:\n            newdiff.append(line)\n    return newdiff\n</file>\n<last_try>\n<last_terminal_session>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x710ee4b77700>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x710ee4c9cca0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-0/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.72 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py::TestAssert_reprcompare::test_list -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 1 item\n\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [100%]\n\n=========================== 1 passed in 0.07 seconds ===========================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x7911d802e520>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7911d80600a0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-1/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.32 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py::TestAssert_reprcompare::test_list -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 1 item\n\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [100%]\n\n=========================== 1 passed in 0.07 seconds ===========================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x762b2a1168e0>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x762b2a08cf40>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-2/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.20 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x73e418676d30>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x73e41865a1c0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-3/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.27 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x709be04cbaf0>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x709be04f2190>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-4/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.42 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x732186264dc0>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x73218624e100>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-5/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.26 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x7c03a1f48d30>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7c03a1f021c0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.02 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-6/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.02 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 5.24 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x7b49dc370d00>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7b49dc3c6160>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-7/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.62 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x715493191d30>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7154931661c0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-8/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.20 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nrd_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x7c4860797ac0>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7c48607a43d0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.02 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-9/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.02 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.87 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nty, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x76c9876e0ac0>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x76c9877033d0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.02 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-10/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.02 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 5.65 seconds ======================\n</bash_command_executed>\n<bash_command_executed command=\"python -m pytest /testbed/testing/test_assertion.py -v\">\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nty, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x7dcedaf25c10>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7dcedaf14400>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-11/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.67 seconds ======================\n</bash_command_executed>\n<latest_failures>\n<failure>The string to replace '    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            explanation += [\n                \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n            ]\n            break' was not found in the file. Please check your old_string: Indentation really matters! When editing a file, make sure to insert appropriate indentation before each line!</failure>\n</latest_failures>\n</last_terminal_session>\n<git_diff>diff --git a/src/_pytest/assertion/util.py b/src/_pytest/assertion/util.py\nindex 762e5761d..b4d0a95db 100644\n--- a/src/_pytest/assertion/util.py\n+++ b/src/_pytest/assertion/util.py\n@@ -259,9 +259,18 @@ def _compare_eq_sequence(left, right, verbose=0):\n     len_right = len(right)\n     for i in range(min(len_left, len_right)):\n         if left[i] != right[i]:\n-            explanation += [\n-                \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n-            ]\n+            if isinstance(left, bytes) and isinstance(right, bytes):\n+                left_chr = chr(left[i]) if 32 <= left[i] <= 126 else '\\\\x{:02x}'.format(left[i])\n+                right_chr = chr(right[i]) if 32 <= right[i] <= 126 else '\\\\x{:02x}'.format(right[i])\n+                explanation += [\n+                    \"At index {} diff: b'{}' (ASCII {}) != b'{}' (ASCII {})\".format(\n+                        i, left_chr, left[i], right_chr, right[i]\n+                    )\n+                ]\n+            else:\n+                explanation += [\n+                    \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n+                ]\n             break\n     len_diff = len_left - len_right\n \n@@ -275,14 +284,31 @@ def _compare_eq_sequence(left, right, verbose=0):\n             extra = saferepr(right[len_left])\n \n         if len_diff == 1:\n-            explanation += [\n-                \"{} contains one more item: {}\".format(dir_with_more, extra)\n-            ]\n+            if isinstance(left, bytes) and isinstance(right, bytes):\n+                extra_byte = left[len_right] if len_diff > 0 else right[len_left]\n+                extra_chr = chr(extra_byte) if 32 <= extra_byte <= 126 else '\\\\x{:02x}'.format(extra_byte)\n+                explanation += [\n+                    \"{} contains one more item: b'{}' (ASCII {})\".format(\n+                        dir_with_more, extra_chr, extra_byte\n+                    )\n+                ]\n+            else:\n+                explanation += [\n+                    \"{} contains one more item: {}\".format(dir_with_more, extra)\n+                ]\n         else:\n-            explanation += [\n-                \"%s contains %d more items, first extra item: %s\"\n-                % (dir_with_more, len_diff, extra)\n-            ]\n+            if isinstance(left, bytes) and isinstance(right, bytes):\n+                extra_byte = left[len_right] if len_diff > 0 else right[len_left]\n+                extra_chr = chr(extra_byte) if 32 <= extra_byte <= 126 else '\\\\x{:02x}'.format(extra_byte)\n+                explanation += [\n+                    \"%s contains %d more items, first extra item: b'%s' (ASCII %d)\"\n+                    % (dir_with_more, len_diff, extra_chr, extra_byte)\n+                ]\n+            else:\n+                explanation += [\n+                    \"%s contains %d more items, first extra item: %s\"\n+                    % (dir_with_more, len_diff, extra)\n+                ]\n     return explanation\n \n \n@@ -388,4 +414,4 @@ def _notin_text(term, text, verbose=0):\n             newdiff.append(\"  \" + line[2:])\n         else:\n             newdiff.append(line)\n-    return newdiff\n+    return newdiff\n\\ No newline at end of file</git_diff>\n</last_try>\n</workspace>\n\n\nNow, review the following XML tools that you'll use to interact with the workspace:\n\n<xml_tools>\n{\n  \"SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS\": \"\\n        <!-- Repository Tool: SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS -->\\n        <!-- Use when all tests of last_try pass and the issue is resolved -->\\n\\n        <!-- No Parameters Required -->\\n\\n        <!-- Mark the PR as solved -->\\n        <SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS />\\n\\n        <!-- Important Notes:\\n             - Only use when all test files of last_try are working perfectly\\n             - Ensure edge cases are covered and existing tests pass\\n             - Use this tool only when the implementation works perfectly and all tests pass\\n        -->\\n        \",\n  \"create_file\": \"\\n        <!-- Create File Tool -->\\n        <!-- Create a new file with specified content -->\\n\\n        <!-- Parameters:\\n             - path: The file path to create (REQUIRED)\\n             - content: The content to write into the file (REQUIRED)\\n        -->\\n        <create_file path=\\\"/testbed/.../new_file.py\\\">\\nprint(\\\"Hello, World!\\\")\\n        </create_file>\\n        \",\n  \"edit_file\": \"\\n        <!-- Edit File Tool -->\\n        <!-- Edit an existing file by replacing specified strings -->\\n\\n        <!-- Parameters:\\n            - path: The file path to edit (REQUIRED)\\n            - replacements: List of string replacements (REQUIRED)\\n        -->\\n\\n        <!-- Note: For accurate replacements, ensure you match the exact indentation of the exact strings. -->\\n\\n        <edit_file path=\\\"/testbed/.../example.py\\\">\\n            <replacements>\\n                <replacement>\\n                    <old_string>foo</old_string>\\n                    <new_string>bar</new_string>\\n                </replacement>\\n                <replacement>\\n                    <old_string>hello</old_string>\\n                    <new_string>world</new_string>\\n                </replacement>\\n            </replacements>\\n        </edit_file>\\n        \",\n  \"open_file\": \"\\n        <!-- Open File Tool -->\\n        <!-- Add a file to the workspace to view its content -->\\n\\n        <!-- Parameters:\\n             - path: The file path to add to the workspace (REQUIRED)\\n        -->\\n        <!-- It's recommended to open multiple relevant files in the same time like this -->\\n        <open_file path=\\\"/testbed/.../example.py\\\" />\\n        <open_file path=\\\"/testbed/.../example2.py\\\" />\\n        <open_file path=\\\"/testbed/.../example3.py\\\" />\\n        \",\n  \"run_bash\": \"\\n        <!-- Run Bash Command Tool -->\\n        <!-- Please AVOID commands that can produce lengthy output -->\\n\\n        <!-- Examples -->\\n        <!-- Avoid -v for verbose output; instead use the recommended options like the following -->\\n        <run_bash command=\\\"python -m pytest /testbed/.../test_example.py -q -vv --tb=short --no-header -rFE\\\" />\\n\\n        <!-- For Django-like recommended command-->\\n        <run_bash command=\\\"/testbed/tests/runtests.py --verbosity 1 --settings=test_sqlite --parallel 1 example.test_example \\\" />\\n\\n        \",\n  \"track_implementation\": \"\\n        <!-- Track Implementation Tool -->\\n        <!-- Track implementation trials with IDs, statuses, and notes -->\\n\\n        <!-- Example Usage -->\\n        <track_implementation id=\\\"A\\\" status=\\\"currently implementing;waiting for test\\\">\\n        [Approach Title]\\n        `file:/testbed/.../example.py\\n        [Short update snippet]\\n        `\\n        `file:/testbed/.../example2.py\\n        [Short update snippet]\\n        `\\n        [Analysis] \\n        [Log based on last try]\\n        [Test results summary]\\n        </track_implementation>\\n        \\n        <track_implementation id=\\\"B\\\" status=\\\"tried; not working, bad resolution\\\">\\n        [...example content...]\\n        </track_implementation>\\n\\n        <track_implementation id=\\\"C\\\" status=\\\"not tried\\\">\\n        [...example content...]\\n        </track_implementation>\\n        \",\n  \"view_folder\": \"\\n        <!-- Repository View Folder Tool -->\\n        <!-- Add directory to workspace to view its contents -->\\n\\n        <!-- Parameters Description:\\n             - path: Directory path to add to workspace (REQUIRED)\\n             - depth: Maximum directory depth to search for contents (optional)\\n        -->\\n\\n        <!-- Add directory to workspace with depth -->\\n        <view_folder path=\\\"/testbed\\\" depth=\\\"2\\\" />\\n\\n        <!-- Important Notes:\\n             - Path should be absolute path from repository root\\n             - Hidden files and directories are automatically excluded\\n        -->\\n        \"\n}\n</xml_tools>\n\nA Python code repository has been uploaded to the `/testbed` directory. Consider the following PR description:\n\n<pr_description>\nConfusing assertion rewriting message with byte strings\nThe comparison with assertion rewriting for byte strings is confusing: \r\n```\r\n    def test_b():\r\n>       assert b\"\" == b\"42\"\r\nE       AssertionError: assert b'' == b'42'\r\nE         Right contains more items, first extra item: 52\r\nE         Full diff:\r\nE         - b''\r\nE         + b'42'\r\nE         ?   ++\r\n```\r\n\r\n52 is the ASCII ordinal of \"4\" here.\r\n\r\nIt became clear to me when using another example:\r\n\r\n```\r\n    def test_b():\r\n>       assert b\"\" == b\"1\"\r\nE       AssertionError: assert b'' == b'1'\r\nE         Right contains more items, first extra item: 49\r\nE         Full diff:\r\nE         - b''\r\nE         + b'1'\r\nE         ?   +\r\n```\r\n\r\nNot sure what should/could be done here.\n\n</pr_description>\n\nFollow this systematic approach to address the issue:\n\n1. Initial Assessment\n   - Review workspace files and the PR description.\n   - Identify key components and their relationships.\n   - Document your initial observations and concerns.\n   - Ensure relevant files and existing tests are opened.\n   - Understand their functionality in relation to the PR description.\n\n2. Detailed Analysis\n   - Examine relevant files in depth.\n   - Map out dependencies and interactions between components.\n   - Identify areas that may be impacted by changes.\n   - If available, review the last attempt and analyze test outputs if it failed.\n\n3. Solution Exploration\n   - Aim to make minimal changes to solve the problem efficiently.\n   - Consider multiple approaches to solve the problem.\n   - For each approach, document:\n     - Pros and cons\n     - Potential drawbacks\n     - Possible failure modes\n   - Think through edge cases and maintenance implications.\n   - Propose multiple solutions.\n   - If <IMPLEMENTATION_TRAILS> are available:\n     - Review existing trials\n     - Update their status based on the last attempt results\n     - Analyze what worked and what didn't\n     - Modify approaches based on your learnings\n   - Use the `track_implementation` tool within <PROPOSE_SOLUTIONS> to:\n     - Add new trials if necessary\n     - Update existing trials\n     - Include detailed notes.\n     - Update status appropriately\n   - Ensure comprehensive coverage of the solution space.\n   - If the current implementation fails multiple times:\n     - Document the failure in detail\n     - Try the next best solution approach\n     - Keep iterating until you find a working solution\n   - Never settle for partial success - all tests must pass.\n\n4. Implementation Strategy\n   - Break down the changes into logical steps.\n   - Focus on minimal and precise modifications.\n   - Plan verification points throughout the implementation.\n   - Consider potential rollback scenarios.\n   - Choose the best solution that:\n     - Fully addresses the root cause of the issue\n     - Maintains existing functionalities\n     - Does not introduce regressions\n     - Prioritizes correctness and robustness over simplicity when necessary\n\nImportant Guidelines:\n- Base all reasoning on the provided workspace; avoid making assumptions.\n- Only modify files that are opened in the workspace.\n- Deeply understand the context before making any changes.\n- Consider potential side effects of each modification.\n- Check test directories to ensure test paths exist.\n- Append new tests for PR by modifying existing tests files only, but never edit existing testcases.\n- Keep iterating with different approaches until all tests pass.\n- Do not give up if tests fail; always try alternative solutions.\n\nDocument your complete reasoning process by wrapping your analysis in these tags:\n- <PREVIOUS_ATTEMPT_ANALYSIS>: Review previous attempt results, including what worked, what failed, and potential reasons for failure.\n- <OBSERVE_WORKSPACE>: Analyze the current workspace state, listing key files, their purposes, and notable dependencies between them.\n- <REASON>: Detail your step-by-step thinking, including consideration of edge cases and potential side effects.\n- <PROPOSE_SOLUTIONS>: List multiple best approaches, minimal or complex, to solve the problem, including code snippets and analysis.\n- <POSSIBLE_FIX>: Document the selected solution rationale.\n\nImplementation Guidelines:\n- Execute multiple actions as needed.\n- Always run tests after modifications and add new tests to confirm the PR.\n- Wait for action results before proceeding.\n- Modify existing tests only.\n- Use `track_implementation` in <PROPOSE_SOLUTIONS>.\n\nCritical Reminders:\n- Think deeply about each step.\n- Consider all implications before making changes.\n- Document your reasoning thoroughly.\n- Validate your assumptions.\n- Consider long-term maintainability.\n- If tests are not found, examine the relevant `tests` directory to locate correct test paths.\n- Update trial status and notes based on previous attempts.\n- Ensure new tests for this PR are created and executed.\n- Only propose solutions, edit file when all relevant files are already opened in the workspace.\n- Only run tests after having the correct test paths.\n- Use the `<SUBMIT_FINAL_SOLUTION_ONLY_IF_ALL_TESTS_PASS>` tool only when the output of last attempt show all tests pass and you are confident that the issue is fully resolved.\n\nYou will operate autonomously from this point forward.\nBegin your analysis and problem-solving process with the `<PREVIOUS_ATTEMPT_ANALYSIS>` tag, followed by `<OBSERVE_WORKSPACE>`, `<REASON>`, `<PROPOSE_SOLUTIONS>`, and `<POSSIBLE_FIX>` tags to document your thought process. \nFinally, list all actions within the `<EXECUTE_ACTIONS>` tag and await the results. \n\nThink deeply and proceed step-by-step through each stage of the process. Your thinking should be thorough, and it's fine if it's very long.\n"}, {"role": "assistant", "content": "I'll analyze the problem and propose a solution following the systematic approach.\n\n<PREVIOUS_ATTEMPT_ANALYSIS>\nFrom the last attempt, I observe:\n\n1. The implementation focused on improving byte string comparison by:\n   - Adding character representation alongside ASCII values\n   - Using hex format for non-printable characters\n   - Maintaining existing behavior for non-byte types\n\n2. Key failures:\n   - The indentation in the replacement string did not match exactly\n   - The error message shows: \"The string to replace was not found in the file\"\n   - This suggests we need to be extremely careful with indentation in our replacements\n\n3. The approach itself seems correct, but the implementation failed due to technical issues with the edit_file tool\n</PREVIOUS_ATTEMPT_ANALYSIS>\n\n<OBSERVE_WORKSPACE>\nKey files in workspace:\n\n1. /testbed/src/_pytest/assertion/util.py\n   - Contains core assertion comparison logic\n   - Includes _compare_eq_sequence function that needs modification\n   - This is where we need to improve byte string comparison messages\n\n2. /testbed/testing/test_assertion.py\n   - Contains tests for assertion comparison functionality\n   - Shows test failures that need to be addressed\n\nThe PR description highlights confusion with byte string comparisons where:\n- ASCII ordinals are shown without context (e.g., \"52\" for \"4\")\n- The error messages could be more informative by showing both character and ASCII value\n</OBSERVE_WORKSPACE>\n\n<REASON>\n1. Problem Analysis:\n   - Current output shows raw ASCII values without context\n   - Users need to mentally convert numbers like 52 to characters\n   - This makes debugging more difficult than necessary\n\n2. Requirements:\n   - Show both character representation and ASCII value\n   - Handle non-printable characters appropriately\n   - Maintain existing behavior for non-byte types\n   - Keep the diff format consistent\n\n3. Edge Cases to Consider:\n   - Non-printable ASCII characters (0-31, 127)\n   - Extended ASCII characters (128-255)\n   - Empty byte strings\n   - Different length byte strings\n   - Mixed printable/non-printable characters\n\n4. Implementation Considerations:\n   - Need exact indentation matching\n   - Must preserve existing functionality for non-byte types\n   - Should enhance readability without losing information\n</REASON>\n\n<PROPOSE_SOLUTIONS>\n<track_implementation id=\"A\" status=\"implementing with fixed indentation\">\n[Enhanced Byte String Representation with Proper Indentation]\n- Show both character and ASCII value for bytes\n- Use hex for non-printable characters\n- Maintain existing behavior for non-byte types\n- Exact indentation matching\n\nKey improvements:\n1. Better readability by showing character representation\n2. Clear ASCII value context\n3. Hex format for non-printable chars\n4. Preserved existing behavior for other types\n\nCode structure with proper indentation:\n```python\ndef _compare_eq_sequence(left, right, verbose=0):\n    explanation = []\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            if isinstance(left, bytes) and isinstance(right, bytes):\n                left_chr = chr(left[i]) if 32 <= left[i] <= 126 else '\\\\x{:02x}'.format(left[i])\n                right_chr = chr(right[i]) if 32 <= right[i] <= 126 else '\\\\x{:02x}'.format(right[i])\n                explanation += [\n                    \"At index {} diff: b'{}' (ASCII {}) != b'{}' (ASCII {})\".format(\n                        i, left_chr, left[i], right_chr, right[i]\n                    )\n                ]\n            else:\n                explanation += [\n                    \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n                ]\n            break\n```\n\nPros:\n+ Clear representation of both character and value\n+ Consistent formatting throughout\n+ Handles all edge cases\n+ Maintains existing functionality\n+ Proper indentation matching\n+ Improved readability\n\nImplementation notes:\n- Will use exact string matching for replacements\n- Careful attention to indentation\n- Comprehensive test coverage\n</track_implementation>\n\n<track_implementation id=\"B\" status=\"not recommended\">\n[Minimal ASCII Value Approach]\n- Show only ASCII values\n- Simpler implementation but less user-friendly\n- Loses character representation context\n\nCons:\n- Less intuitive for debugging\n- Missing visual character representation\n- Not as helpful for users\n</track_implementation>\n\n<track_implementation id=\"C\" status=\"not recommended\">\n[Hybrid Format Approach]\n- Different formats for printable/non-printable\n- Inconsistent presentation\n- More complex logic\n\nCons:\n- Inconsistent user experience\n- More complex maintenance\n- Potential confusion\n</track_implementation>\n</PROPOSE_SOLUTIONS>\n\n<POSSIBLE_FIX>\nI'll proceed with Implementation A because it:\n1. Provides the most user-friendly output\n2. Maintains consistency in formatting\n3. Handles all edge cases appropriately\n4. Preserves existing behavior for non-byte types\n5. Uses proper indentation matching\n\nThe implementation will:\n1. Detect byte string comparisons\n2. Show both character and ASCII value representations\n3. Use hex format for non-printable characters\n4. Maintain exact indentation\n5. Keep existing behavior for other types\n</POSSIBLE_FIX>\n\n<EXECUTE_ACTIONS>\n1. First, let's edit the file with proper indentation:\n\n<edit_file path=\"/testbed/src/_pytest/assertion/util.py\">\n<replacements>\n<replacement>\n<old_string>    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            explanation += [\n                \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n            ]\n            break</old_string>\n<new_string>    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            if isinstance(left, bytes) and isinstance(right, bytes):\n                left_chr = chr(left[i]) if 32 <= left[i] <= 126 else '\\\\x{:02x}'.format(left[i])\n                right_chr = chr(right[i]) if 32 <= right[i] <= 126 else '\\\\x{:02x}'.format(right[i])\n                explanation += [\n                    \"At index {} diff: b'{}' (ASCII {}) != b'{}' (ASCII {})\".format(\n                        i, left_chr, left[i], right_chr, right[i]\n                    )\n                ]\n            else:\n                explanation += [\n                    \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n                ]\n            break</new_string>\n</replacement>\n<replacement>\n<old_string>            explanation += [\n                \"{} contains one more item: {}\".format(dir_with_more, extra)\n            ]</old_string>\n<new_string>            if isinstance(left, bytes) and isinstance(right, bytes):\n                extra_byte = left[len_right] if len_diff > 0 else right[len_left]\n                extra_chr = chr(extra_byte) if 32 <= extra_byte <= 126 else '\\\\x{:02x}'.format(extra_byte)\n                explanation += [\n                    \"{} contains one more item: b'{}' (ASCII {})\".format(\n                        dir_with_more, extra_chr, extra_byte\n                    )\n                ]\n            else:\n                explanation += [\n                    \"{} contains one more item: {}\".format(dir_with_more, extra)\n                ]</new_string>\n</replacement>\n<replacement>\n<old_string>            explanation += [\n                \"%s contains %d more items, first extra item: %s\"\n                % (dir_with_more, len_diff, extra)\n            ]</old_string>\n<new_string>            if isinstance(left, bytes) and isinstance(right, bytes):\n                extra_byte = left[len_right] if len_diff > 0 else right[len_left]\n                extra_chr = chr(extra_byte) if 32 <= extra_byte <= 126 else '\\\\x{:02x}'.format(extra_byte)\n                explanation += [\n                    \"%s contains %d more items, first extra item: b'%s' (ASCII %d)\"\n                    % (dir_with_more, len_diff, extra_chr, extra_byte)\n                ]\n            else:\n                explanation += [\n                    \"%s contains %d more items, first extra item: %s\"\n                    % (dir_with_more, len_diff, extra)\n                ]</new_string>\n</replacement>\n</replacements>\n</edit_file>\n\n2. Run the tests to verify the changes:\n<run_bash command=\"python -m pytest /testbed/testing/test_assertion.py -v\" />\n\n"}, {"role": "user", "content": "Result for <track_implementation id=\"A\" status=\"implementing with fixed indentation\">:\nImplementation trial 'A' status updated to 'implementing with fixed indentation'."}, {"role": "user", "content": "Result for <track_implementation id=\"A\" status=\"implementing with fixed indentation\">:\nImplementation trial 'B' status updated to 'not recommended'."}, {"role": "user", "content": "Result for <track_implementation id=\"A\" status=\"implementing with fixed indentation\">:\nImplementation trial 'C' status updated to 'not recommended'."}, {"role": "user", "content": "Result for <edit_file path=\"/testbed/src/_pytest/assertion/util.py\">:\nThe string to replace '    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            explanation += [\n                \"At index {} diff: {!r} != {!r}\".format(i, left[i], right[i])\n            ]\n            break' was not found in the file. Please check your old_string: Indentation really matters! When editing a file, make sure to insert appropriate indentation before each line!"}, {"role": "user", "content": "Result for <run_bash command=\"python -m pytest /testbed/testing/test_assertion.py -v\" />:\nCommand executed:\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1 -- /opt/miniconda3/envs/testbed/bin/python\ncachedir: .pytest_cache\nrootdir: /testbed, inifile: tox.ini\ncollecting ... collected 91 items\n\ntesting/test_assertion.py::TestImportHookInstallation::test_register_assert_rewrite_checks_types PASSED [  1%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_different_types PASSED [  2%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_summary PASSED   [  3%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_diff PASSED [  4%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping PASSED [  5%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_text_skipping_verbose PASSED [  6%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_multiline_text_diff PASSED [  7%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list PASSED      [  8%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left0-right0-\\n                Full diff:\\n                - [0, 1]\\n                ?     ^\\n                + [0, 2]\\n                ?     ^\\n            ] PASSED [  9%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left1-right1-\\n                Full diff:\\n                - {0: 1}\\n                ?     ^\\n                + {0: 2}\\n                ?     ^\\n            ] PASSED [ 10%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_iterable_full_diff[left2-right2-\\n                Full diff:\\n                - {0, 1}\\n                ?     ^\\n                + {0, 2}\\n                ?     ^\\n            ] PASSED [ 12%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_different_lengths PASSED [ 13%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict PASSED      [ 14%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting PASSED [ 15%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_1 PASSED [ 16%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_omitting_with_verbosity_2 PASSED [ 17%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_dict_different_items PASSED [ 18%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_sequence_different_items PASSED [ 19%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_set PASSED       [ 20%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_frozenzet PASSED [ 21%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_Sequence PASSED  [ 23%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_tuples PASSED [ 24%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_verbose PASSED [ 25%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_list_bad_repr PASSED [ 26%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_one_repr_empty PASSED [ 27%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_repr_no_exc PASSED [ 28%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_unicode PASSED   [ 29%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_nonascii_text PASSED [ 30%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_format_nonascii_explanation PASSED [ 31%]\ntesting/test_assertion.py::TestAssert_reprcompare::test_mojibake PASSED  [ 32%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs FAILED [ 34%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose FAILED [ 35%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off FAILED [ 36%]\ntesting/test_assertion.py::TestAssert_reprcompare_attrsclass::test_comparing_two_different_attrs_classes PASSED [ 37%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_simple PASSED [ 38%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where PASSED  [ 39%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_and PASSED    [ 40%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_where_nested PASSED [ 41%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline PASSED [ 42%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_escaped PASSED [ 43%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_newline_before_where PASSED [ 45%]\ntesting/test_assertion.py::TestFormatExplanation::test_fmt_multi_newline_before_where PASSED [ 46%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_when_input_is_empty_list PASSED [ 47%]\ntesting/test_assertion.py::TestTruncateExplanation::test_doesnt_truncate_at_when_input_is_5_lines_and_LT_max_chars PASSED [ 48%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_given_list_of_empty_strings PASSED [ 49%]\ntesting/test_assertion.py::TestTruncateExplanation::test_truncates_at_8_lines_when_first_8_lines_are_LT_max_chars PASSED [ 50%]\n\n...LENGTHY OUTPUT TRUNCATED...\n\nty, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite0/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: 'E       AssertionError'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=plain\n     in: /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite0\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite0\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite0/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite0/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite0/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite0/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n______ TestImportHookInstallation.test_installed_plugin_rewrite[rewrite] _______\n\nself = <test_assertion.TestImportHookInstallation object at 0x7ac5d7a98d30>\ntestdir = <Testdir local('/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1')>\nmode = 'rewrite'\nmonkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x7ac5d7aa81c0>\n\n    @pytest.mark.parametrize(\"mode\", [\"plain\", \"rewrite\"])\n    def test_installed_plugin_rewrite(self, testdir, mode, monkeypatch):\n        monkeypatch.delenv(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", raising=False)\n        # Make sure the hook is installed early enough so that plugins\n        # installed via setuptools are rewritten.\n        testdir.tmpdir.join(\"hampkg\").ensure(dir=1)\n        contents = {\n            \"hampkg/__init__.py\": \"\"\"\\\n                import pytest\n    \n                @pytest.fixture\n                def check_first2():\n                    def check(values, value):\n                        assert values.pop(0) == value\n                    return check\n            \"\"\",\n            \"spamplugin.py\": \"\"\"\\\n            import pytest\n            from hampkg import check_first2\n    \n            @pytest.fixture\n            def check_first():\n                def check(values, value):\n                    assert values.pop(0) == value\n                return check\n            \"\"\",\n            \"mainwrapper.py\": \"\"\"\\\n            import pytest, importlib_metadata\n    \n            class DummyEntryPoint(object):\n                name = 'spam'\n                module_name = 'spam.py'\n                group = 'pytest11'\n    \n                def load(self):\n                    import spamplugin\n                    return spamplugin\n    \n            class DummyDistInfo(object):\n                version = '1.0'\n                files = ('spamplugin.py', 'hampkg/__init__.py')\n                entry_points = (DummyEntryPoint(),)\n                metadata = {'name': 'foo'}\n    \n            def distributions():\n                return (DummyDistInfo(),)\n    \n            importlib_metadata.distributions = distributions\n            pytest.main()\n            \"\"\",\n            \"test_foo.py\": \"\"\"\\\n            def test(check_first):\n                check_first([10, 30], 30)\n    \n            def test2(check_first2):\n                check_first([10, 30], 30)\n            \"\"\",\n        }\n        testdir.makepyfile(**contents)\n        result = testdir.run(\n            sys.executable, \"mainwrapper.py\", \"-s\", \"--assert=%s\" % mode\n        )\n        if mode == \"plain\":\n            expected = \"E       AssertionError\"\n        elif mode == \"rewrite\":\n            expected = \"*assert 10 == 30*\"\n        else:\n            assert 0\n>       result.stdout.fnmatch_lines([expected])\nE       Failed: nomatch: '*assert 10 == 30*'\nE           and: '============================= test session starts =============================='\nE           and: 'platform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1'\nE           and: 'rootdir: /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1'\nE           and: 'collected 2 items'\nE           and: ''\nE           and: 'test_foo.py EE'\nE           and: ''\nE           and: '==================================== ERRORS ===================================='\nE           and: '____________________________ ERROR at setup of test ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py, line 1'\nE           and: '  def test(check_first):'\nE           and: \"E       fixture 'check_first' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py:1'\nE           and: '___________________________ ERROR at setup of test2 ____________________________'\nE           and: 'file /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py, line 4'\nE           and: '  def test2(check_first2):'\nE           and: \"E       fixture 'check_first2' not found\"\nE           and: '>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory'\nE           and: \">       use 'pytest --fixtures [testpath]' for help on them.\"\nE           and: ''\nE           and: '/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py:4'\nE           and: '=========================== 2 error in 0.01 seconds ============================'\nE       remains unmatched: '*assert 10 == 30*'\n\n/testbed/testing/test_assertion.py:216: Failed\n----------------------------- Captured stdout call -----------------------------\nrunning: /opt/miniconda3/envs/testbed/bin/python mainwrapper.py -s --assert=rewrite\n     in: /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1\n============================= test session starts ==============================\nplatform linux -- Python 3.9.19, pytest-4.6.1.dev144+g1aefb24b3, py-1.11.0, pluggy-0.13.1\nrootdir: /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1\ncollected 2 items\n\ntest_foo.py EE\n\n==================================== ERRORS ====================================\n____________________________ ERROR at setup of test ____________________________\nfile /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py, line 1\n  def test(check_first):\nE       fixture 'check_first' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py:1\n___________________________ ERROR at setup of test2 ____________________________\nfile /tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py, line 4\n  def test2(check_first2):\nE       fixture 'check_first2' not found\n>       available fixtures: cache, capfd, capfdbinary, caplog, capsys, capsysbinary, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory\n>       use 'pytest --fixtures [testpath]' for help on them.\n\n/tmp/pytest-of-root/pytest-12/test_installed_plugin_rewrite1/test_foo.py:4\n=========================== 2 error in 0.01 seconds ============================\n=========================== short test summary info ============================\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_verbose\nFAILED testing/test_assertion.py::TestAssert_reprcompare_attrsclass::test_attrs_with_attribute_comparison_off\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[plain]\nFAILED testing/test_assertion.py::TestImportHookInstallation::test_installed_plugin_rewrite[rewrite]\n===================== 5 failed, 86 passed in 4.09 seconds ======================"}]}