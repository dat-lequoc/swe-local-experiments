diff --git a/xarray/core/merge.py b/xarray/core/merge.py
index d29a9e1f..e8119374 100644
--- a/xarray/core/merge.py
+++ b/xarray/core/merge.py
@@ -916,6 +916,17 @@ def dataset_update_method(
     """
     from .dataarray import DataArray
     from .dataset import Dataset
+    from .duck_array_ops import is_duck_dask_array
+
+    def _maybe_preserve_chunks(var, data):
+        """Preserve chunks in variable if data is a dask array"""
+        if is_duck_dask_array(data):
+            if hasattr(data, 'chunks'):
+                var.encoding['chunks'] = data.chunks
+                # Ensure the variable data remains dask array
+                if not is_duck_dask_array(var.data):
+                    var.data = data
+        return var
 
     if not isinstance(other, Dataset):
         other = dict(other)
@@ -929,6 +940,14 @@ def dataset_update_method(
                 ]
                 if coord_names:
                     other[key] = value.drop_vars(coord_names)
+                # Preserve chunks if present
+                if is_duck_dask_array(value.data):
+                    other[key] = _maybe_preserve_chunks(other[key], value.data)
+            elif isinstance(value, tuple) and len(value) >= 2:
+                dims, data = value[:2]
+                if is_duck_dask_array(data):
+                    var = as_variable(value)
+                    other[key] = _maybe_preserve_chunks(var, data)
 
     # use ds.coords and not ds.indexes, else str coords are cast to object
     indexes = {key: dataset.coords[key] for key in dataset.indexes.keys()}
@@ -937,4 +956,4 @@ def dataset_update_method(
         priority_arg=1,
         indexes=indexes,
         combine_attrs="override",
-    )
+    )
\ No newline at end of file
diff --git a/xarray/tests/test_dask.py b/xarray/tests/test_dask.py
index 19a61c60..d81d4bae 100644
--- a/xarray/tests/test_dask.py
+++ b/xarray/tests/test_dask.py
@@ -674,6 +674,32 @@ class TestDataArrayAndDataset(DaskTestCase):
         assert not ds1["y"]._in_memory
         assert not ds2["y"]._in_memory
 
+    def test_update_preserve_chunks(self):
+        """Test that update preserves chunks in dask arrays"""
+        import dask.array as da
+        
+        # Create chunked dataset
+        data = da.random.random((4, 4), chunks=(2, 2))
+        ds = Dataset({"foo": (("x", "y"), data)})
+        
+        # Verify initial chunks
+        assert isinstance(ds.foo.data, da.Array)
+        assert ds.foo.chunks == ((2, 2), (2, 2))
+        
+        # Update with sliced data
+        update_data = ds.foo[1:, :]
+        ds.update({"foo": (("x", "y"), update_data)})
+        
+        # Verify chunks are preserved
+        assert isinstance(ds.foo.data, da.Array)
+        assert ds.foo.chunks is not None
+        
+        # Test updating with DataArray
+        ds2 = Dataset({"bar": (("x", "y"), da.ones((4, 4), chunks=(2, 2)))})
+        ds.update({"bar": ds2.bar})
+        assert isinstance(ds.bar.data, da.Array)
+        assert ds.bar.chunks == ((2, 2), (2, 2))
+
     def test_dataarray_getattr(self):
         # ipython/jupyter does a long list of getattr() calls to when trying to
         # represent an object.
@@ -1598,4 +1624,4 @@ def test_optimize():
     a = dask.array.ones((10, 4), chunks=(5, 2))
     arr = xr.DataArray(a).chunk(5)
     (arr2,) = dask.optimize(arr)
-    arr2.compute()
+    arr2.compute()
\ No newline at end of file
